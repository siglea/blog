<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>粉笔灰杂谈</title>
    <description>关于产品、技术、商业的一些见解，顺便记录一下自己的生活感悟和读书笔记。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 01 Jun 2020 15:59:47 +0800</pubDate>
    <lastBuildDate>Mon, 01 Jun 2020 15:59:47 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title> 数据结构 </title>
        <description>&lt;h4 id=&quot;数组&quot;&gt;数组&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;链表&quot;&gt;链表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。&lt;/li&gt;
  &lt;li&gt;这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。&lt;/li&gt;
  &lt;li&gt;一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;跳表&quot;&gt;跳表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从O(n)提升至O(logn)。&lt;/li&gt;
  &lt;li&gt;跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前redis和levelDB都有用到跳表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;栈&quot;&gt;栈&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;后进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;队列&quot;&gt;队列&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;先进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;树&quot;&gt;树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将“链表”竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。&lt;/li&gt;
  &lt;li&gt;树遍历
    &lt;ul&gt;
      &lt;li&gt;前序遍历：根结点 —&amp;gt; 左子树 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;中序遍历：左子树—&amp;gt; 根结点 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;后序遍历：左子树 —&amp;gt; 右子树 —&amp;gt; 根结点&lt;/li&gt;
      &lt;li&gt;层次遍历：仅仅需按层次遍历就可以&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;平衡二叉树&quot;&gt;平衡二叉树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;平衡二叉树又被称为AVL树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;红黑树&quot;&gt;红黑树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;每个结点要么是红的要么是黑的。&lt;/li&gt;
  &lt;li&gt;根结点是黑的。&lt;/li&gt;
  &lt;li&gt;每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。&lt;/li&gt;
  &lt;li&gt;如果一个结点是红的，那么它的两个儿子都是黑的。&lt;/li&gt;
  &lt;li&gt;对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。&lt;/li&gt;
  &lt;li&gt;Map、Set、epoll/select中句柄集&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;堆&quot;&gt;堆&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。&lt;/li&gt;
  &lt;li&gt;堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;散列表-hash&quot;&gt;散列表 Hash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通过某种算法确定唯一（有些算法会出现不同的value算出相同的Hash值）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图&quot;&gt;图&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;多维数据存储,实际应用中是通过图这种模式建立索引与关联关系&lt;/li&gt;
  &lt;li&gt;图数据库？
    &lt;ul&gt;
      &lt;li&gt;图数据库(Graph database)并非指存储图片的数据库，而是以图这种数据结构存储和查询数据。&lt;/li&gt;
      &lt;li&gt;图形数据库是一种在线数据库管理系统，具有处理图形数据模型的创建，读取，更新和删除（CRUD）操作。&lt;/li&gt;
      &lt;li&gt;与其他数据库不同，关系在图数据库中占首要地位。这意味着应用程序不必使用外键或带外处理（如MapReduce）来推断数据连接。&lt;/li&gt;
      &lt;li&gt;与关系数据库或其他NoSQL数据库相比，图数据库的数据模型也更加简单，更具表现力。&lt;/li&gt;
      &lt;li&gt;图形数据库是为与事务（OLTP）系统一起使用而构建的，并且在设计时考虑了事务完整性和操作可用性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&quot;&gt;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>排序算法概述</title>
        <description>&lt;h4 id=&quot;冒泡排序&quot;&gt;冒泡排序&lt;/h4&gt;
&lt;pre&gt;
从左开始比较，大的往右换
或
从右开始比较，小的往左换
重复上一步骤
&lt;/pre&gt;
&lt;h4 id=&quot;鸡尾排序&quot;&gt;鸡尾排序&lt;/h4&gt;
&lt;pre&gt;
也叫双向冒泡或者定向冒泡，
从左开始比较，大的往右换
与
从右开始比较，小的往左换
同时进行
&lt;/pre&gt;
&lt;h4 id=&quot;选择排序&quot;&gt;选择排序&lt;/h4&gt;
&lt;pre&gt;
与冒泡排序相比减少了多余的交换
找出最小的元素放在最左侧，接着找第二小的...直到最后排完(不稳定)
&lt;/pre&gt;
&lt;h4 id=&quot;快速排序&quot;&gt;快速排序&lt;/h4&gt;
&lt;pre&gt;
选中一个基准元素X，小于X放在左侧，大于X放在右侧，分而治之，不断重复
&lt;/pre&gt;
&lt;h4 id=&quot;插入排序&quot;&gt;插入排序&lt;/h4&gt;
&lt;pre&gt;
从左侧开始设定一个有序区，从第二个元素开始去有序找自己的位置插入进去
&lt;/pre&gt;
&lt;h4 id=&quot;希尔排序&quot;&gt;希尔排序&lt;/h4&gt;
&lt;pre&gt;
两两分组，跨度交换，左小右大，逐渐缩小跨度为1，即完成排序
&lt;/pre&gt;
&lt;h4 id=&quot;归并排序比武排序&quot;&gt;归并排序(比武排序)&lt;/h4&gt;
&lt;pre&gt;
由一组数字分为两组，逐渐分为只包含2个元素的小组
开始比较大小，左小右大
比较完毕之后，开始合并，合并的时候按照小大顺序把2个小组合并成1个有序大组，直到最后1个最大有序组
&lt;/pre&gt;
&lt;h4 id=&quot;计数排序&quot;&gt;计数排序&lt;/h4&gt;
&lt;pre&gt;
建立【元素都为0】的空数组，开始遍历待排序数组
如果待排元素值等于空数组的位置角标，则【元素+1】
&lt;/pre&gt;
&lt;h4 id=&quot;桶排序&quot;&gt;桶排序&lt;/h4&gt;
&lt;pre&gt;
计数排序的升级版，计数排序每个索引只能记录一个值，
索引升级为桶（比如桶范围2.0-3.5）
此时，一个桶里就可以放多个数据范围内的数据
&lt;/pre&gt;
&lt;h4 id=&quot;基数排序按位排序&quot;&gt;基数排序（按位排序）&lt;/h4&gt;
&lt;pre&gt;
提取每个元素的最后一位进行计数排序
再提取倒数第二位进行计数排序
直到最前一位
比如：单词排序，长度不一的末尾用0代替
&lt;/pre&gt;
&lt;h4 id=&quot;堆排序&quot;&gt;堆排序&lt;/h4&gt;
&lt;pre&gt;
主要利用二叉堆是完全二叉堆这样的数据结构的特性
把无序数组构建成二叉堆。
循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。
&lt;/pre&gt;

&lt;p&gt;参考 &lt;a href=&quot;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&quot;&gt;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 11:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> kafka activeMQ RabbitMq RocketMQ </title>
        <description>&lt;h4 id=&quot;amqp即advanced-message-queuing-protocolactivemqrabbitmq都支持&quot;&gt;AMQP，即Advanced Message Queuing Protocol（ActiveMQ、RabbitMQ都支持）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ &lt;a href=&quot;https://www.jianshu.com/p/78847c203b76&quot;&gt;https://www.jianshu.com/p/78847c203b76&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;两种消息模型&quot;&gt;两种消息模型：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;点对点（单播），当采用点对点模型时，消息将发送到一个队列，该队列的消息只能被一个消费者消费。&lt;/li&gt;
  &lt;li&gt;publish-subscribe（发布订阅、广播）模型。而采用发布订阅模型时，消息可以被多个消费者消费。
在发布订阅模型中，生产者和消费者完全独立，不需要感知对方的存在。
例如，在用户登录后，各个其他模板更加登录进行不同的处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证可用性&quot;&gt;如何保证可用性&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;主从架构（ActiveMQ、RabbitMQ）&lt;/li&gt;
  &lt;li&gt;分布式架构（RocketMQ、kafka）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消息不被重复消费&quot;&gt;如何保证消息不被重复消费？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分析:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。&lt;/li&gt;
  &lt;li&gt;回答:先来说一下为什么会造成重复消费?
  其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。
  如何解决?这个问题针对业务场景来答分以下几点
  - 比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
    &lt;ul&gt;
      &lt;li&gt;再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
  - 如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&amp;lt;id,message&amp;gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;消费者消费失败如何处理&quot;&gt;消费者消费失败，如何处理？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消费成功时，手动ack，这样队列会再次推送或者再次pull&lt;/li&gt;
  &lt;li&gt;用redis对立的”伪消费队列”最大的问题就是在于消费后没有ACK，发生意外会有很多脏数据&lt;/li&gt;
  &lt;li&gt;也可以用幂等的方式消费者保存业务的进展，用单独程序做补偿消费&lt;/li&gt;
  &lt;li&gt;如果消费者处理一个消息失败了，消息系统一般会把这个消息放回队列，这样其他消费者可以继续处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消费的可靠性传输&quot;&gt;如何保证消费的可靠性传输?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ
    &lt;ul&gt;
      &lt;li&gt;生产者丢数据，可以用事务方式来保证发送成功或回滚，也可以队列接受后异步返回ack或nack来实现&lt;/li&gt;
      &lt;li&gt;消息队列丢数据，可以持久化队列并且配置自动重复参数&lt;/li&gt;
      &lt;li&gt;消费者丢数据，手动ack
        &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rabbitmq-server start
service rabbitmq-server restart
rabbitmqctl status
rabbitmq-plugins &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;rabbitmq_management
rabbitmqctl add_user rabbitmq 123456
rabbitmqctl set_user_tags rabbitmq administrator
rabbitmqctl set_permissions &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; / rabbitmq &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;kafka
    &lt;ul&gt;
      &lt;li&gt;(1)生产者丢数据
在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置
        &lt;ol&gt;
          &lt;li&gt;第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。&lt;/li&gt;
          &lt;li&gt;在producer端设置retries=MAX，一旦写入失败，这无限重试&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消息队列丢数据
针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。
        &lt;ol&gt;
          &lt;li&gt;replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本&lt;/li&gt;
          &lt;li&gt;min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系
这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消费者丢数据
这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的
offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;rocketmq&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# install rocketmq&lt;/span&gt;
unzip rocketmq-all-4.7.0-source-release.zip
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;rocketmq-all-4.7.0/
mvn &lt;span class=&quot;nt&quot;&gt;-Prelease-all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-DskipTests&lt;/span&gt; clean &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-U&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;distribution/target/rocketmq-4.7.0/rocketmq-4.7.0

&lt;span class=&quot;c&quot;&gt;# config JAVA_HOME&lt;/span&gt;
vim ~/.bashrc
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/lib/jvm/jdk-13
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Name Server&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqnamesrv &amp;amp;
&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ~/logs/rocketmqlogs/namesrv.log
&lt;span class=&quot;c&quot;&gt;#The Name Server boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Broker&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &amp;amp;
&lt;span class=&quot;c&quot;&gt;#The broker[%s, 172.30.30.233:10911] boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 外网访问 配置 /etc/hosts&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 相关报错 RemotingTooMuchRequestException: sendDefaultImpl call timeout；&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;# 配置conf/broker.conf &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;brokerIP1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hostname.com
./mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; ../conf/broker.conf &amp;amp;

&lt;span class=&quot;c&quot;&gt;# 相关报错 No route info of this topic&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 保持客户端rocketmq版本号与服务器一致&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 设置该属性 autoCreateTopicEnable=true &lt;/span&gt;
./mqadmin topicList &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;推拉模式&quot;&gt;推拉模式&lt;/h4&gt;
&lt;p&gt;消费模式分为推（push）模式和拉（pull）模式。推模式是指由 Broker 主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。而拉模式是指消费端主动向 Broker 端请求拉取（一般是定时或者定量）消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。&lt;/p&gt;

&lt;h4 id=&quot;关于kafka&quot;&gt;关于kafka&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Apache Kafka不是消息中间件的一种实现。相反，它只是一种分布式流式系统。
不同于基于队列和交换器的RabbitMQ，Kafka的存储层是使用分区事务日志来实现的。&lt;/li&gt;
  &lt;li&gt;过期日志会根据时间或大小，进行清除&lt;/li&gt;
  &lt;li&gt;极好的总结 &lt;a href=&quot;https://segmentfault.com/a/1190000021138998&quot;&gt;https://segmentfault.com/a/1190000021138998&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;zookeeper在kafka中的作用 &lt;a href=&quot;https://www.jianshu.com/p/a036405f989c&quot;&gt;https://www.jianshu.com/p/a036405f989c&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一次事故 &lt;a href=&quot;https://www.jianshu.com/p/72a54f835b6b&quot;&gt;https://www.jianshu.com/p/72a54f835b6b&lt;/a&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#启动zk&lt;/span&gt;
bin/zookeeper-server-start.sh config/zookeeper.properties &amp;amp;
&lt;span class=&quot;c&quot;&gt;#启动kafka&lt;/span&gt;
bin/kafka-server-start.sh config/server.properties
&lt;span class=&quot;c&quot;&gt;# kafka默认只支持本地访问，如果需要外网访问，需要用hostname.com的方式配置&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# hostname.com可以是任意自定义的，不需要备案，只是起到&quot;代名词&quot;作用&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#1、&lt;/span&gt;
config/server.properties
&lt;span class=&quot;nv&quot;&gt;listeners&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;PLAINTEXT://hostname.com:9092
&lt;span class=&quot;c&quot;&gt;#2、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#kafka broker机器配置hosts&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;#3、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#调用端也是是kafka的Client端 的机器配置hosts&lt;/span&gt;
broker机器的外网ip  hostname.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消息队列常见问题
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/williamjie/p/9481780.html&quot;&gt;https://www.cnblogs.com/williamjie/p/9481780.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;优知学院消息队列
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288173&quot;&gt;https://zhuanlan.zhihu.com/p/60288173&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288391&quot;&gt;https://zhuanlan.zhihu.com/p/60288391&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IM系统的MQ消息中间件选型：Kafka还是RabbitMQ？
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37993013&quot;&gt;https://zhuanlan.zhihu.com/p/37993013&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MQ消息队列的12点核心原理总结
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60289322&quot;&gt;https://zhuanlan.zhihu.com/p/60289322&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 22 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</guid>
        
        <category>MQ</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>Netty-Mina</title>
        <description>&lt;h4 id=&quot;从零开发一个im服务端&quot;&gt;从零开发一个IM服务端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通俗易懂 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;基于Netty实现海量接入的推送服务技术要点 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;必读有关为何选择netty的11个疑问及解答&quot;&gt;必读有关“为何选择Netty”的11个疑问及解答&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tcp网关&quot;&gt;TCP网关&lt;/h4&gt;
&lt;p&gt;HAProxy nginx LVS&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;生产环境大部分还是采用通过rest方式获取IpList，然后有客户端直接发起长连接的方式&lt;/li&gt;
  &lt;li&gt;京东京麦的生产级TCP网关技术实践总结 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一套海量在线用户的移动端IM架构设计实践 &lt;a href=&quot;http://www.52im.net/thread-812-1-1.html&quot;&gt;http://www.52im.net/thread-812-1-1.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;reactor-线程模型&quot;&gt;Reactor 线程模型&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Reactor 是反应堆的意思，Reactor 模型是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。
服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式，即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;why-nettyjdk-原生-nio-程序的问题&quot;&gt;Why Netty?JDK 原生 NIO 程序的问题&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;JDK 原生也有一套网络应用程序 API，但是存在一系列问题，主要如下：
    &lt;ol&gt;
      &lt;li&gt;NIO 的类库和 API 繁杂，使用麻烦：你需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。&lt;/li&gt;
      &lt;li&gt;需要具备其他的额外技能做铺垫：例如熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的 NIO 程序。&lt;/li&gt;
      &lt;li&gt;可靠性能力补齐，开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等。NIO 编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大。&lt;/li&gt;
      &lt;li&gt;JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。官方声称在 JDK 1.6 版本的 update 18 修复了该问题，但是直到 JDK 1.7 版本该问题仍旧存在，只不过该 Bug 发生概率降低了一些而已，它并没有被根本解决。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;java-nio-epoll-bug-以及-netty-的解决之道&quot;&gt;Java NIO epoll bug 以及 Netty 的解决之道&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;epoll 空轮询导致 CPU 利用率 100% &lt;a href=&quot;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&quot;&gt;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;netty中的epoll实现&quot;&gt;netty中的epoll实现&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;在java中，IO多路复用的功能通过nio中的Selector提供，在不同的操作系统下jdk会通过spi的方式加载不同的实现，
比如在macos下是KQueueSelectorProvider，KQueueSelectorProvider底层使用了kqueue来进行IO多路复用；
在linux 2.6以后的版本则是EPollSelectorProvider，EPollSelectorProvider底层使用的是epoll。
虽然jdk自身提供了selector的epoll实现，netty仍实现了自己的epoll版本，根据netty开发者在StackOverflow的回答，主要原因有两个：
    &lt;ul&gt;
      &lt;li&gt;支持更多socket option，比如TCP_CORK和SO_REUSEPORT&lt;/li&gt;
      &lt;li&gt;使用了边缘触发（ET）模式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://juejin.im/post/5d46ce64f265da03e05af722&quot;&gt;https://juejin.im/post/5d46ce64f265da03e05af722&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ET和LT的区别在于触发事件的条件不同，LT比较符合编程思维（有满足条件的就触发），ET触发的条件更苛刻一些（仅在发生变化时才触发），对使用者的要求也更高，理论效率更高&lt;/li&gt;
  &lt;li&gt;边缘触发和水平触发&lt;a href=&quot;https://juejin.im/post/5cdaa67f518825691b4a5cc0&quot;&gt;https://juejin.im/post/5cdaa67f518825691b4a5cc0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 18 May 2020 22:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</guid>
        
        <category>Network</category>
        
        <category>Java</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> BigData </title>
        <description>&lt;h4 id=&quot;hdfshive-与-hbasephoenix的区别&quot;&gt;HDFS+Hive 与 HBase+Phoenix的区别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Hive中的表是纯逻辑表，就只是表的定义等，即表的元数据。Hive本身不存储数据，它完全依赖HDFS和MapReduce。这样就可以将结构化的数据文件映射为为一张数据库表，并提供完整的SQL查询功能，并将SQL语句最终转换为MapReduce任务进行运行。 而HBase表是物理表，适合存放非结构化的数据。
    &lt;ol&gt;
      &lt;li&gt;两者分别是什么？
        &lt;ul&gt;
          &lt;li&gt;Apache Hive是数据仓库。通过Hive可以使用HQL语言查询存放在HDFS上的数据。HQL是一种类SQL语言，这种语言最终被转化为Map/Reduce. 虽然Hive提供了SQL查询功能，但是Hive不能够进行交互查询–因为它是基于MapReduce算法。&lt;/li&gt;
          &lt;li&gt;Apache Hbase Key/Value，基础单元是cell，它运行在HDFS之上。和Hive不一样，Hbase的能够在它的数据库上实时运行，而不是运行MapReduce任务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;两者的特点
        &lt;ul&gt;
          &lt;li&gt;Hive帮助熟悉SQL的人运行MapReduce任务。因为它是JDBC兼容的。运行Hive查询会花费很长时间，因为它会默认遍历表中所有的数据。但可以通过Hive的分区来控制。因为这样一来文件大小是固定的，就这么大一块存储空间，从固定空间里查数据是很快的。&lt;/li&gt;
          &lt;li&gt;HBase通过存储key/value来工作。注意版本的功能。你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;限制
        &lt;ul&gt;
          &lt;li&gt;Hive目前不支持更新操作。另外，由于hive在hadoop上运行批量操作，它需要花费很长的时间，通常是几分钟到几个小时才可以获取到查询的结果。Hive必须提供预先定义好的schema将文件和目录映射到列，并且Hive与ACID不兼容。&lt;/li&gt;
          &lt;li&gt;HBase查询是通过特定的语言来编写的，这种语言需要重新学习。类SQL的功能可以通过Apache Phonenix实现，但这是以必须提供schema为代价的。另外，Hbase也并不是兼容所有的ACID特性，虽然它支持某些特性。最后但不是最重要的–为了运行Hbase，Zookeeper是必须的，zookeeper是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;应用场景
        &lt;ul&gt;
          &lt;li&gt;Hive适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。&lt;/li&gt;
          &lt;li&gt;Hbase非常适合用来进行大数据的实时查询。Facebook用Hbase进行消息和实时的分析。它也可以用来统计Facebook的连接数。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;两者关系
        &lt;ul&gt;
          &lt;li&gt;Hive和Pig都可以与HBase组合使用，Hive和Pig还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单&lt;/li&gt;
          &lt;li&gt;Hive与HBase，都是在Hadoop体系使用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;总结
        &lt;ul&gt;
          &lt;li&gt;Hive和Hbase是两种基于Hadoop的不同技术–Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到Hbase，设置再从Hbase写回Hive。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;其他
        &lt;ul&gt;
          &lt;li&gt;Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。近似理解为SQL ON Hadoop&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hadoop--spark--storm&quot;&gt;Hadoop &amp;amp; Spark &amp;amp; Storm&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop，是实现了MapReduce的思想，将数据切片计算来处理大量的离线数据。Hadoop处理的数据必须是已经存放在HDFS上或者类似HBase的数据库中，所以Hadoop实现的时候是通过移动计算到这些存放数据的机器上来提高效率。
适合于离线的批量数据处理适用于对实时性要求极低的场景。&lt;/li&gt;
  &lt;li&gt;Storm，可以用来处理源源不断流进来的消息，处理之后将结果写入到某个存储中去。实时性方面做得极好。(可以脱离Hadoop体系单独使用)&lt;/li&gt;
  &lt;li&gt;Spark，是一个基于内存计算的开源集群计算系统，目的是更快速的进行数据分析。Spark由加州伯克利大学AMP实验室Matei为主的小团队使用Scala开发，类似于Hadoop MapReduce的通用并行计算框架，Spark基于Map Reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的Map Reduce的算法。
(可以简单理解为”另一种形式的MapReduce”或者是第二代”引擎”，需要在Hadoop体系使用)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;搭建单机hadoop&quot;&gt;搭建单机Hadoop&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1. 配置环境变量&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/java/jdk1.8
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/java/jdk1.8/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/lib/dt.jar:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/lib/tools.jar:&lt;span class=&quot;nv&quot;&gt;$JRE_HOME&lt;/span&gt;/lib

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/hadoop/hadoop2.8
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_COMMON_LIB_NATIVE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/lib/native
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-Djava.library.path=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/lib&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 2. 创建目录&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/tmp  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/var  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs/name  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs/data

&lt;span class=&quot;c&quot;&gt;# 3. 修改配置文件&lt;/span&gt;
vim core-site.xml
vim hadoop-env.sh
vim hdfs-site.xml
vim mapred-site.xml

&lt;span class=&quot;c&quot;&gt;# 4. 启动&lt;/span&gt;
bin/hadoop  namenode  &lt;span class=&quot;nt&quot;&gt;-format&lt;/span&gt;
start-dfs.sh
start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;搭建单机hbase&quot;&gt;搭建单机HBase&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1. 搭建好Hadoop&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 2. 创建目录&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase/tmp  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase/pids
&lt;span class=&quot;c&quot;&gt;# 3. 启动&lt;/span&gt;
./start-hbase.sh
&lt;span class=&quot;c&quot;&gt;# 4. 常用命令&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 进入shell&lt;/span&gt;
hbase shell
create &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st2'&lt;/span&gt;
put &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1:age'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'18'&lt;/span&gt;
put &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st2:name'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'zhangsan'&lt;/span&gt;
scan &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 查询该表数据&lt;/span&gt;
describe &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
delete&lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1:age'&lt;/span&gt;
disable &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
drop &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;白话大数据 &lt;a href=&quot;https://www.zhihu.com/question/27974418/answer/156227565&quot;&gt;https://www.zhihu.com/question/27974418/answer/156227565&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一步步搭建Hadoop体系 &lt;a href=&quot;https://blog.csdn.net/qazwsxpcm/article/list/2?t=1&quot;&gt;https://blog.csdn.net/qazwsxpcm/article/list/2?t=1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 01 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/BigData.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/BigData.html</guid>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> Java SPI </title>
        <description>&lt;p&gt;SPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的API，它可以用来启用框架扩展和替换组件。
Java SPI其实内部实现原理还是基于ClassLoader。我们可以自定义ClassLoader，结合SPI技术，就能做到接口和具体实现解耦，还能做到类隔离和对业务代码无感知的升级。
在jar包内 /META-INF/services/java.sql.Driver寻找类名（约束优于配置）。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Iterable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PREFIX&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;META-INF/services/&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ClassLoader&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getContextClassLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ServiceLoader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/sweatOtt/article/details/83055191&quot;&gt;https://blog.csdn.net/sweatOtt/article/details/83055191&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://juejin.im/post/5af952fdf265da0b9e652de3&quot;&gt;https://juejin.im/post/5af952fdf265da0b9e652de3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/46b42f7f593c&quot;&gt;https://www.jianshu.com/p/46b42f7f593c&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/Java-SPI.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/Java-SPI.html</guid>
        
        <category>Java</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> Dubbo </title>
        <description>&lt;h3 id=&quot;dubbo&quot;&gt;Dubbo&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;官网 &lt;a href=&quot;http://dubbo.apache.org/&quot;&gt;http://dubbo.apache.org/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;start &lt;a href=&quot;http://start.dubbo.io/&quot;&gt;http://start.dubbo.io/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Dubbo实践 &lt;a href=&quot;https://www.cnblogs.com/warehouse/tag/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/&quot;&gt;https://www.cnblogs.com/warehouse/tag/%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;通俗易懂的 Dubbo 教程 &lt;a href=&quot;https://blog.csdn.net/Geffin/category_9931110.html&quot;&gt;https://blog.csdn.net/Geffin/category_9931110.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Java RMI &amp;amp; Dubbo &lt;a href=&quot;http://dubbo.apache.org/zh-cn/blog/dubbo-101.html&quot;&gt;http://dubbo.apache.org/zh-cn/blog/dubbo-101.html&lt;/a&gt;
    &lt;h3 id=&quot;dubbo负载均衡&quot;&gt;Dubbo负载均衡&lt;/h3&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://dubbo.apache.org/zh-cn/blog/dubbo-loadbalance.html&quot;&gt;http://dubbo.apache.org/zh-cn/blog/dubbo-loadbalance.html&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;dubbo-内置了四种负载均衡策略分别如下&quot;&gt;Dubbo 内置了四种负载均衡策略，分别如下：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RandomLoadBalance：随机负载均衡&lt;/li&gt;
  &lt;li&gt;RoundRobinLoadBalance：轮询负载均衡&lt;/li&gt;
  &lt;li&gt;LeastActiveLoadBalance：最少活跃调用数负载均衡&lt;/li&gt;
  &lt;li&gt;ConsistentHashLoadBalance：一致性哈希负载均衡&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;随机负载均衡&quot;&gt;随机负载均衡&lt;/h4&gt;
&lt;p&gt;随机负载均衡是 Dubbo 默认的负载均衡策略，顾名思义，就是从多个服务提供者中随机选择一个。
需要注意的是，Dubbo 的随机负载均衡并非是完全的随机，它有一个权重的概念，会按照权重来设置随机概率，举个例子，我们现在有两个服务提供者，一个的权重是100，另一个的权重是300，那么前者被分配的概率就为 25%，后者被分配的概率为 75%。
我们可以对服务提供者设置不同的权重，例如对性能较好的机器设置大权重，对差一点的机器设置小一点的权重。&lt;/p&gt;

&lt;h4 id=&quot;轮询负载均衡&quot;&gt;轮询负载均衡&lt;/h4&gt;
&lt;p&gt;轮询负载均衡，即会轮询每一个服务提供者，依次对其进行调用。
轮询负载均衡也有权重的概念，可以严格按照我们设置的比例进行分配，这个是该算法的优点，不过，该算法的缺点也很明显，可能会存在较慢的机器，那么请求会在这台机器上进行累积，很容易导致整个系统变慢。&lt;/p&gt;

&lt;h4 id=&quot;最少活跃调用数负载均衡&quot;&gt;最少活跃调用数负载均衡&lt;/h4&gt;
&lt;p&gt;最少活跃调用数负载均衡会将请求转发至活跃调用数最少的机器上，如果有两台机器活跃数相同，会采取随机负载均衡的策略。
什么是活跃调用数呢？每个服务维护一个活跃数计数器，该计数器存放机器未处理完的请求。当有请求产生时，会选择活跃数最小的机器去执行。
最少活跃调用数负载均衡可以令慢的机器收到更少的请求。&lt;/p&gt;

&lt;h4 id=&quot;一致性哈希负载均衡&quot;&gt;一致性哈希负载均衡&lt;/h4&gt;
&lt;p&gt;要了解这种负载均衡策略，我们首先得学习一下一致性哈希算法。不会一致性哈希算法的同学可以看一下我之前写的这篇博客，质量保证过硬：一致性哈希算法详解
一致性哈希可以保证相同参数的请求一定会发送到同一台机器上，即使有机器崩溃，由于一致性哈希算法的特性与虚拟节点的存在，发往该机器的请求会被发送到其它机器上，并不会引发剧烈变动。&lt;/p&gt;
&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nd&quot;&gt;@Component&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ChangeServiceImpl&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ChangeService&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Reference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loadbalance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;roundrobin&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;NameService&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nameService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;change&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nameService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;updateName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;dubbo集群容错&quot;&gt;Dubbo集群容错&lt;/h3&gt;
&lt;h4 id=&quot;内置容错策略&quot;&gt;内置容错策略&lt;/h4&gt;
&lt;p&gt;Dubbo默认内置了一些容错策略，如果还不能满足用户需求，我们可以自定义容错策略进行配置。Dubbo 内置了以下几种容错策略：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Failover(失败自动切换)&lt;/li&gt;
  &lt;li&gt;Failsafe(失败安全)&lt;/li&gt;
  &lt;li&gt;Failfast(快速失败)&lt;/li&gt;
  &lt;li&gt;Failback(失败自动恢复)&lt;/li&gt;
  &lt;li&gt;Forking(并行调用)&lt;/li&gt;
  &lt;li&gt;Broadcast(广播调用)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;failover失败自动切换&quot;&gt;Failover(失败自动切换)&lt;/h4&gt;
&lt;p&gt;Failover 是 Dubbo 默认的容错策略。
其实，Failover 是高可用的一个常用概念，服务器通常拥有主备两套机器配置，当主服务器出现故障时，会自动切换到备服务器中，从而保证了整体的高可用性。
当调用失败时，会根据配置的重试次数，自动从其他可用地址中重新选择一个可用的地址进行调用，直到调用成功，或者是达到重试的上限位置。
Failover 会自动对失败进行重试，但它也带来了一些副作用。首先，重试会增加开销，再者，重试会增加调用的响应时间，最后，在某些情况下，重试会造成资源的浪费。&lt;/p&gt;

&lt;h4 id=&quot;failsafe失败安全&quot;&gt;Failsafe(失败安全)&lt;/h4&gt;
&lt;p&gt;Failsafe 在调用失败时，会忽略此错误，并记录一条日志，同时返回一个空结果，在上游看来调用是成功的。
Failsafe 即使失败了也不会影响整个调用流程，它的失败不影响核心业务的正确性，通常用于旁路系统或流程中，一般用于写入审计日志等操作。&lt;/p&gt;

&lt;h4 id=&quot;failfast快速失败&quot;&gt;Failfast(快速失败)&lt;/h4&gt;
&lt;p&gt;有一些业务场景中，其操作是非幂等的，不能重复调用。这种情况下，重试并不是一个好办法，需要用到 Failfast，调用失败立即报错，让调用方来决定下一步的操作并保证业务的幂等性。&lt;/p&gt;

&lt;h4 id=&quot;failback失败自动恢复&quot;&gt;Failback(失败自动恢复)&lt;/h4&gt;
&lt;p&gt;在 Failback 中，如果调用失败，则此次失败相当于 Failsafe，将返回一个空结果，但与 Failsafe 不同的是，Failback 策略会将这次调用加入内存中的失败列表中，对于这个列表中的失败调用，会在另一个线程中进行异步重试，重试如果再发生失败，则会忽略，即使重试调用成功，原来的调用方也感知不到了。因此它通常适合于对于实时性要求不高，且不需要返回值的一些异步操作。&lt;/p&gt;

&lt;h4 id=&quot;forking并行调用&quot;&gt;Forking(并行调用)&lt;/h4&gt;
&lt;p&gt;Forking 在第一次调用就同时发起多个调用，只要其中一个调用成功，就认为成功。在资源充足，且对于失败的容忍度较低的场景下，可以采用此策略。&lt;/p&gt;

&lt;h4 id=&quot;broadcast广播调用&quot;&gt;Broadcast(广播调用)&lt;/h4&gt;
&lt;p&gt;在某些场景下，我们可能需要对所有服务提供者进行操作，我们可以采用广播调用策略，会逐个调用所有提供者，只要任意有一个提供者出错，则认为此次调用出错。通常用于通知所有提供者更新缓存或日志等本地资源信息。&lt;/p&gt;

&lt;h4 id=&quot;降级容错熔断方式&quot;&gt;降级容错熔断方式&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Dubbo服务之Stub和Mock &lt;a href=&quot;https://www.jianshu.com/p/f4255a14e53f&quot;&gt;https://www.jianshu.com/p/f4255a14e53f&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Dubbo服务之RPC扩展和本地Mock &lt;a href=&quot;https://www.cnblogs.com/hyry/p/12067497.html&quot;&gt;https://www.cnblogs.com/hyry/p/12067497.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Dubbo与断路器 Hystrix 的集成 &lt;a href=&quot;https://blog.csdn.net/Geffin/article/details/105808745&quot;&gt;https://blog.csdn.net/Geffin/article/details/105808745&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;dubbo27新特性&quot;&gt;Dubbo2.7新特性&lt;/h4&gt;
&lt;p&gt;异步化改造，三大中心改造，服务治理增强 &lt;a href=&quot;http://dubbo.apache.org/zh-cn/blog/dubbo-27-features.html&quot;&gt;http://dubbo.apache.org/zh-cn/blog/dubbo-27-features.html&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;通过qos对服务进行动态控制&quot;&gt;通过QoS对服务进行动态控制&lt;/h4&gt;
&lt;p&gt;在Dubbo中，QoS Quality of Service 这个概念被用于动态的对服务进行查询和控制。例如对获取当前提供和消费的所有服务，以及对服务进行动态的上下线，即从注册中心上进行注册和反注册操作。
&lt;a href=&quot;http://dubbo.apache.org/zh-cn/blog/introduction-to-dubbo-qos.html&quot;&gt;http://dubbo.apache.org/zh-cn/blog/introduction-to-dubbo-qos.html&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 01 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/Dubbo.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/Dubbo.html</guid>
        
        <category>微服务</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> SpringCloud </title>
        <description>&lt;h3 id=&quot;关于微服务&quot;&gt;关于微服务&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;SOA(ESB)与微服务
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30477325&quot;&gt;https://zhuanlan.zhihu.com/p/30477325&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/guanghe/p/10978349.html&quot;&gt;https://www.cnblogs.com/guanghe/p/10978349.html&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/9YxdCkl98kZq_Bh_DqwCmA&quot;&gt;https://mp.weixin.qq.com/s/9YxdCkl98kZq_Bh_DqwCmA&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;微服务哪些事
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://windmt.com/2018/04/14/spring-cloud-0-microservices/&quot;&gt;https://windmt.com/2018/04/14/spring-cloud-0-microservices/&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://windmt.com/2018/04/14/spring-cloud-1-services-governance/&quot;&gt;https://windmt.com/2018/04/14/spring-cloud-1-services-governance/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SpringCloud &amp;amp; Dubbo
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/qDiSn29uqSpA0yaM07nmbQ&quot;&gt;https://mp.weixin.qq.com/s/qDiSn29uqSpA0yaM07nmbQ&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/GSLXRnl0pg5ynVwbQcon7A&quot;&gt;https://mp.weixin.qq.com/s/GSLXRnl0pg5ynVwbQcon7A&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.ityouknow.com/springcloud/2017/11/20/dubbo-update-again.html&quot;&gt;阿里Dubbo与Spring Cloud&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;RPC之thrift/gRPC
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/kesonyk/article/details/50924489&quot;&gt;https://blog.csdn.net/kesonyk/article/details/50924489&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://developer.51cto.com/art/201908/601617.htm&quot;&gt;https://developer.51cto.com/art/201908/601617.htm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000011478469&quot;&gt;https://segmentfault.com/a/1190000011478469&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/136112210&quot;&gt;https://zhuanlan.zhihu.com/p/136112210&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;RPC与HTTP的关系 &lt;a href=&quot;https://mp.weixin.qq.com/s/0RXTUWHXDmMddsPVWej2Qg&quot;&gt;https://mp.weixin.qq.com/s/0RXTUWHXDmMddsPVWej2Qg&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;快速理解RPC技术——基本概念、原理和用途 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2620&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2620&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;WebService某种程度上也是一种RPC
    &lt;ul&gt;
      &lt;li&gt;WebService的历史 &lt;a href=&quot;https://www.iteye.com/blog/andot-662787&quot;&gt;https://www.iteye.com/blog/andot-662787&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;WebService的demo&lt;a href=&quot;https://blog.csdn.net/weixin_42672054/article/details/81708464&quot;&gt;https://blog.csdn.net/weixin_42672054/article/details/81708464&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;2000年左右出现xml，借此微软等联盟推出了基于XML的SOAP协议，实现各系统之间的通信&lt;/li&gt;
      &lt;li&gt;thrift/webservice等可以生成客户端代码，隐藏了底层通信细节，对象化了数据（否则需要自行解析）&lt;/li&gt;
      &lt;li&gt;thrift、dobbo等方式基于TCP实现，主要是性能方面的考虑吧&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hessian / sofa&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;just-do-springcloud&quot;&gt;Just Do SpringCloud&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;首选 &lt;a href=&quot;https://windmt.com/tags/Spring-Cloud/&quot;&gt;https://windmt.com/tags/Spring-Cloud/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.springcloud.cc/&quot;&gt;springcloud.cc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://springcloud.fun&quot;&gt;springcloud.fun&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/283286745/answer/763040709&quot;&gt;大话SpringCloud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.geekdigging.com&quot;&gt;https://www.geekdigging.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;常见组件&quot;&gt;常见组件&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;服务配置中心（注册发现）：Netflix的Eureka、Apache的zookeeper、Spring家族的Spring Cloud Consul、携程apollo
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/5c5753d2aeb0&quot;&gt;Zookeeper保证的是CP，Eureka保证的是AP&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;客户端负载均衡：Netflix Ribbon (提供云端负载均衡，有多种负载均衡策略可供选择，可配合服务发现和断路器使用。)
    &lt;ul&gt;
      &lt;li&gt;客户端负载均衡(Ribbon)服务实例的清单在客户端，客户端进行负载均衡算法分配。(从上面的知识我们已经知道了：客户端可以从Eureka Server中得到一份服务清单，在发送请求时通过负载均衡算法，在多个服务器之间选择一个进行访问)
Zuul路由的业务，对业务进行了归类，并交给了对应的微服务。&lt;/li&gt;
      &lt;li&gt;服务端负载均衡(Nginx)服务实例的清单在服务端，服务器进行负载均衡算法分配,
Nginx路由请求的压力，对请求进行平均后，交给了服务器处理。&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/kongxianghai/p/8477781.html&quot;&gt;撸一撸Spring Cloud Ribbon的原理-负载均衡策略&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;可以使用Ribbon + resetTemplate 或者直接使用 Feign（已经内置Ribbon）来实现客户端侧的负载均衡&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;熔断器：Netflix Hystrix（Envoy)&lt;/li&gt;
  &lt;li&gt;Spring Cloud Feign：它基于 Netflix Feign 实现，整合了 Spring Cloud Ribbon 与 Spring Cloud Hystrix, 除了整合这两者的强大功能之外，它还提 供了声明式的服务调用(不再通过RestTemplate)。
  生产环境一般使用restTemplate + ribbon&lt;/li&gt;
  &lt;li&gt;服务网关: Netflix Zuul  、 Spring Cloud GateWay
    &lt;ul&gt;
      &lt;li&gt;Zuul相当于一个分布式的大Servlet+Filter入口可进行路由及过滤等&lt;/li&gt;
      &lt;li&gt;Zuul也可以近似的理解为是SOA里的ESB，统一入口调用&lt;/li&gt;
      &lt;li&gt;Zuul也默认集成了Hystrix与Ribbon&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式配置：Spring Cloud Config (Chef)&lt;/li&gt;
  &lt;li&gt;时间消息总线：Spring Cloud Bus&lt;/li&gt;
  &lt;li&gt;链路追踪：Spring Cloud Sleuth 与 Twitter Zipkin&lt;/li&gt;
  &lt;li&gt;数据流：Spring Cloud Stream (数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。)&lt;/li&gt;
  &lt;li&gt;服务监控：Zabbix、Nagios、Metrics、Spectator&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;相关组件&quot;&gt;相关组件&lt;/h3&gt;
&lt;h4 id=&quot;zookeeper&quot;&gt;zookeeper&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;简单理解，zk就是一套简单的文件系统结构，本目录(节点)可以设置value及subNode,
并且该节点可以设置不同的权限（默认/用户名+密码/ip/秘钥，这4种)&lt;/li&gt;
  &lt;li&gt;zk集群简单理解就是，基于ZAB一致性算法的变种keep alived集群&lt;/li&gt;
  &lt;li&gt;zk集群是CP模型，强一致性的，也就是说数据出现了不一致性（通常是节点挂了），整个服务集群就会Hold住等待数据一致，
所以，这个缺点导致zk并不是最佳的注册中心，因为服务注册中心AP模型最好，部分服务有问题并不表示所有服务不可用。&lt;/li&gt;
  &lt;li&gt;zookeeper 命令 &lt;a href=&quot;https://blog.csdn.net/feixiang2039/article/details/79810102&quot;&gt;https://blog.csdn.net/feixiang2039/article/details/79810102&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Curator实现的zk分布式锁 &lt;a href=&quot;https://www.sohu.com/a/341386202_315839&quot;&gt;https://www.sohu.com/a/341386202_315839&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;基于springcloud的开源项目&quot;&gt;基于SpringCloud的开源项目&lt;/h3&gt;

</description>
        <pubDate>Sat, 04 Apr 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/SpringCloud.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/SpringCloud.html</guid>
        
        <category>微服务</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> Nginx </title>
        <description>&lt;h4 id=&quot;location-优先级从高到低&quot;&gt;location 优先级从高到低&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. location &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 精准匹配&lt;/span&gt;
2. location ^~   &lt;span class=&quot;c&quot;&gt;# 带参前缀匹配&lt;/span&gt;
3. location ~    &lt;span class=&quot;c&quot;&gt;# 正则匹配（区分大小写）&lt;/span&gt;
4. location ~&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 正则匹配（不区分大小写）&lt;/span&gt;
5. location /a   &lt;span class=&quot;c&quot;&gt;# 普通前缀匹配，优先级低于带参数前缀匹配。&lt;/span&gt;
6. location /    &lt;span class=&quot;c&quot;&gt;# 任何没有匹配成功的，都会匹配这里处理&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;location-示例&quot;&gt;location 示例&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
location  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; / &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 只精准匹配 / 的查询.&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration A &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 匹配成功： / &lt;/span&gt;

location / &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 匹配任何请求，因为所有请求都是以”/“开始&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 但是更长字符匹配或者正则表达式匹配会优先匹配&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration B &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#匹配成功：/index.html&lt;/span&gt;

location /documents &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索/&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 只有后面的正则表达式没有匹配到时，这一条才会采用这一条/&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration C &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 匹配成功：/documents/document.html&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 匹配成功：/documents/abc&lt;/span&gt;

location ~ /documents/ABC &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 区分大小写的正则匹配&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索/&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 只有后面的正则表达式没有匹配到时，这一条才会采用这一条/&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration CC &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

location ^~ /images/ &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 匹配任何以 /images/ 开头的地址，匹配符合以后，立即停止往下搜索正则，采用这一条。/&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration D &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 成功匹配：/images/a.gif&lt;/span&gt;

location ~&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;gif|jpg|jpeg&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 匹配所有以 .gif、.jpg 或 .jpeg 结尾的请求，不区分大小写&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 然而，所有请求 /images/ 下的图片会被 [ config D ]  处理，因为 ^~ 到达不了这一条正则/&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration E &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 成功匹配：/documents/a.jpg&lt;/span&gt;

location /images/ &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 字符匹配到 /images/，继续往下，会发现 ^~ 存在/&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration F &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

location /images/abc &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在/&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# F与G的放置顺序是没有关系的/&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration G &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

location ~ /images/abc/ &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 只有去掉 [ config D ] 才有效：先最长匹配 [ config G ] 开头的地址，继续往下搜索，匹配到这一条正则，采用/&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; configuration H &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;命名-location&quot;&gt;命名 location&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;location / &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    try_files &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt;/ @custom
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
location @custom &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# ...do something&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;全局变量&quot;&gt;全局变量&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$args&lt;/span&gt; ： &lt;span class=&quot;c&quot;&gt;#这个变量等于请求行中的参数，同$query_string&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$content_length&lt;/span&gt; ： 请求头中的Content-length字段。
&lt;span class=&quot;nv&quot;&gt;$content_type&lt;/span&gt; ： 请求头中的Content-Type字段。
&lt;span class=&quot;nv&quot;&gt;$document_root&lt;/span&gt; ： 当前请求在root指令中指定的值。
&lt;span class=&quot;nv&quot;&gt;$host&lt;/span&gt; ： 请求主机头字段，否则为服务器名称。
&lt;span class=&quot;nv&quot;&gt;$http_user_agent&lt;/span&gt; ： 客户端agent信息
&lt;span class=&quot;nv&quot;&gt;$http_cookie&lt;/span&gt; ： 客户端cookie信息
&lt;span class=&quot;nv&quot;&gt;$limit_rate&lt;/span&gt; ： 这个变量可以限制连接速率。
&lt;span class=&quot;nv&quot;&gt;$request_method&lt;/span&gt; ： 客户端请求的动作，通常为GET或POST。
&lt;span class=&quot;nv&quot;&gt;$remote_addr&lt;/span&gt; ： 客户端的IP地址。
&lt;span class=&quot;nv&quot;&gt;$remote_port&lt;/span&gt; ： 客户端的端口。
&lt;span class=&quot;nv&quot;&gt;$remote_user&lt;/span&gt; ： 已经经过Auth Basic Module验证的用户名。
&lt;span class=&quot;nv&quot;&gt;$request_filename&lt;/span&gt; ： 当前请求的文件路径，由root或alias指令与URI请求生成。
&lt;span class=&quot;nv&quot;&gt;$scheme&lt;/span&gt; ： HTTP方法（如http，https）。
&lt;span class=&quot;nv&quot;&gt;$server_protocol&lt;/span&gt; ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。
&lt;span class=&quot;nv&quot;&gt;$server_addr&lt;/span&gt; ： 服务器地址，在完成一次系统调用后可以确定这个值。
&lt;span class=&quot;nv&quot;&gt;$server_name&lt;/span&gt; ： 服务器名称。
&lt;span class=&quot;nv&quot;&gt;$server_port&lt;/span&gt; ： 请求到达服务器的端口号。
&lt;span class=&quot;nv&quot;&gt;$request_uri&lt;/span&gt; ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;baz”。
&lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt; ： 不带请求参数的当前URI，&lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt;不包含主机名，如”/foo/bar.html”。
&lt;span class=&quot;nv&quot;&gt;$document_uri&lt;/span&gt; ： 与&lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt;相同。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;rewrite规则&quot;&gt;Rewrite规则&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag];&lt;/li&gt;
  &lt;li&gt;如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。&lt;/li&gt;
  &lt;li&gt;表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是：
    &lt;ul&gt;
      &lt;li&gt;执行server块的rewrite指令&lt;/li&gt;
      &lt;li&gt;执行location匹配&lt;/li&gt;
      &lt;li&gt;执行选定的location中的rewrite指令&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;执行搜索
这个规则的目的是为了执行搜索，搜索URL中包含的关键字。
请求的URL //hqidi.com/search/some-search-keywords
重写后URL //hqidi.com/search.php?p&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;some-search-keywords
重写规则         rewrite ^/search/&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;/search.php?p&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;?&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

用户个人资料页面
大多数运行访问者注册的动态网站都提供一个可以查看个人资料的页面，这个页面的URL包含用户的UID和用户名
请求的URL //hqidi.com/user/47/dige
重写后URL //hqidi.com/user.php?id&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;47&amp;amp;name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;dige
重写规则         rewrite ^/user/&lt;span class=&quot;o&quot;&gt;([&lt;/span&gt;0-9]+&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;.+&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;/user.php?id&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;&amp;amp;name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$2&lt;/span&gt;?&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

多个参数
有些网站对字符串参数使用不同的语法，例如 通过斜线“/”来分隔非命名参数
请求的URL //hqidi.com/index.php/param1/param2/param3
重写后URL //hqidi.com/index.php?p1&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;param1&amp;amp;p2&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;param2&amp;amp;p3&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;param3
重写规则         rewrite ^/index.php/&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;.&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;/index.php?p1&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;&amp;amp;p2&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$2&lt;/span&gt;&amp;amp;p3&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$3&lt;/span&gt;?&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;location 配置一 &lt;a href=&quot;https://segmentfault.com/a/1190000022315733&quot;&gt;https://segmentfault.com/a/1190000022315733&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;location 配置二 &lt;a href=&quot;https://segmentfault.com/a/1190000022407797&quot;&gt;https://segmentfault.com/a/1190000022407797&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Nginx 架构原理科普 &lt;a href=&quot;https://mp.weixin.qq.com/s/V09fS0fHq6KJJZ3c1AuEyQ&quot;&gt;https://mp.weixin.qq.com/s/V09fS0fHq6KJJZ3c1AuEyQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;OpenResty 概要及原理科普 &lt;a href=&quot;https://mp.weixin.qq.com/s/rhIXgxuL_w_GvOwGZPGDkw&quot;&gt;https://mp.weixin.qq.com/s/rhIXgxuL_w_GvOwGZPGDkw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;微服务网关 Kong 科普 &lt;a href=&quot;https://mp.weixin.qq.com/s/P7DTKAf8w3DhJJ6ODlRf8g&quot;&gt;https://mp.weixin.qq.com/s/P7DTKAf8w3DhJJ6ODlRf8g&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 04 Apr 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/Nginx.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/Nginx.html</guid>
        
        <category>网络</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> Java ClassLoader </title>
        <description>&lt;h4 id=&quot;类加载器步骤&quot;&gt;类加载器步骤&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;在特定目录找到.class文件，并读取&lt;/li&gt;
  &lt;li&gt;Java是模板系语言，读取.class文件之后，被实例化为对应的Class的对象&lt;/li&gt;
  &lt;li&gt;Class对象=类模板实例化，只有有类模板，新对象才能根据类模板进行实例化&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;3大内置类加载器&quot;&gt;3大内置类加载器&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;启动（Bootstrap）类加载器
启动类加载器主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 &lt;JAVA_HOME&gt;/lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类)。&lt;/JAVA_HOME&gt;&lt;/li&gt;
  &lt;li&gt;扩展（Extension）类加载器
扩展类加载器是指Sun公司(已被Oracle收购)实现的sun.misc.Launcher$ExtClassLoader类，由Java语言实现的，是Launcher的静态内部类，它负责加载&lt;JAVA_HOME&gt;/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。&lt;/JAVA_HOME&gt;&lt;/li&gt;
  &lt;li&gt;系统（System）类加载器
也称应用程序加载器是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;双亲委派模式&quot;&gt;双亲委派模式&lt;/h4&gt;
&lt;p&gt;工作原理的是，如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式&lt;/p&gt;

&lt;h4 id=&quot;双亲委派模式优势&quot;&gt;双亲委派模式优势&lt;/h4&gt;
&lt;p&gt;采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。可能你会想，如果我们在classpath路径下自定义一个名为java.lang.SingleInterge类(该类是胡编的)呢？该类并不存在java.lang中，经过双亲委托模式，传递到启动类加载器中，由于父类加载器路径下并没有该类，所以不会加载，将反向委托给子类加载器加载，最终会通过系统类加载器加载该类。但是这样做是不允许，因为java.lang是核心API包，需要访问权限，强制加载将会报出如下异常&lt;/p&gt;

&lt;h4 id=&quot;其他&quot;&gt;其他&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;不同的加载器加载了同个类，在Jvm中相当于两个不同的Class对象&lt;/li&gt;
  &lt;li&gt;双亲委派模型的破坏者-线程上下文类加载器，在Java应用中存在着很多服务提供者接口（Service Provider Interface，SPI），这些接口允许第三方为它们提供实现，如常见的 SPI 有 JDBC、JNDI等，这些 SPI 的接口属于 Java 核心库，一般存在rt.jar包中，由Bootstrap类加载器加载，而 SPI 的第三方实现代码则是作为Java应用所依赖的 jar 包被存放在classpath路径下，由于SPI接口中的代码经常需要加载具体的第三方实现类并调用其相关方法，但SPI的核心接口类是由引导类加载器来加载的，而Bootstrap类加载器无法直接加载SPI的实现类，同时由于双亲委派模式的存在，Bootstrap类加载器也无法反向委托AppClassLoader加载器SPI的实现类。在这种情况下，我们就需要一种特殊的类加载器来加载第三方的类库，而线程上下文类加载器就是很好的选择。&lt;/li&gt;
  &lt;li&gt;参考&lt;a href=&quot;https://blog.csdn.net/javazejian/article/details/73413292&quot;&gt;https://blog.csdn.net/javazejian/article/details/73413292&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 04 Apr 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/ClassLoader.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/04/04/ClassLoader.html</guid>
        
        <category>Java</category>
        
        
        <category>技术</category>
        
      </item>
    
  </channel>
</rss>
