<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>粉笔灰杂谈</title>
    <description>关于产品、技术、商业的一些见解，顺便记录一下自己的生活感悟和读书笔记。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 16 Jun 2020 23:00:31 +0800</pubDate>
    <lastBuildDate>Tue, 16 Jun 2020 23:00:31 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>DotDot</title>
        <description>&lt;h4 id=&quot;innodb引擎的4大特性&quot;&gt;InnoDB引擎的4大特性&lt;/h4&gt;
&lt;p&gt;https://www.cnblogs.com/zhs0/p/10528520.html&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;插入缓冲（insert buffer)，只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是为了减少随机IO带来性能损耗。&lt;/li&gt;
  &lt;li&gt;二次写(double write)
    &lt;ul&gt;
      &lt;li&gt;InnoDB默认DB page为 16KB，而文件系统、磁盘、扇区对应的page小于该数字，因此，一次DB page可能被多次写入才能真正写入成功&lt;/li&gt;
      &lt;li&gt;在写数据时，会在共享表空间写一份数据，之后再同步到磁盘&lt;/li&gt;
      &lt;li&gt;在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/chenpingzhao/p/4876282.html&quot;&gt;https://www.cnblogs.com/chenpingzhao/p/4876282.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;自适应哈希索引(ahi)，innodb会监控表上多个索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。
  主要是精确等值查找，对范围查找搜索不生效&lt;/li&gt;
  &lt;li&gt;预读(read ahead)，数据预加载&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;共享表空间-独立表空间&quot;&gt;共享表空间 、独立表空间&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;共享表空间： Innodb的所有数据保存在一个单独的表空间里面，而这个表空间可以由很多个文件组成，一个表可以跨多个文件存在，所以其大小限制不再是文件大小的限制，而是其自身的限制。从Innodb的官方文档中可以看到，其表空间的最大限制为64TB，也就是说，Innodb的单表限制基本上也在64TB左右了，当然这个大小是包括这个表的所有索引等其他相关数据。&lt;/li&gt;
  &lt;li&gt;独占表空间:  每一个表都将会生成以独立的文件方式来进行存储，每一个表都有一个.frm表描述文件，还有一个.ibd文件。 其中这个文件包括了单独一个表的数据内容以及索引内容，默认情况下它的存储位置也是在表的位置之中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;聚集索引-与-非聚集索引&quot;&gt;聚集索引 与 非聚集索引&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/riemann_/article/details/90324846&quot;&gt;https://blog.csdn.net/riemann_/article/details/90324846&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tcp&quot;&gt;TCP&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;TCP三要素：ip+端口、序列号（解决乱序）、窗口大小（流量控制）&lt;/li&gt;
  &lt;li&gt;TCP与UDP
    &lt;ul&gt;
      &lt;li&gt;TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。
    UDP 首部只有 8 个字节，并且是固定不变的，开销较小。&lt;/li&gt;
      &lt;li&gt;为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？
  原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。&lt;/li&gt;
      &lt;li&gt;为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？
  TCP数据的长度 = IP总长度-IP首位长度-TCP首部长度。实际上，UDP的长度也可以用这个方式计算，因此UDP包长度有点多余&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP建立连接
    &lt;ul&gt;
      &lt;li&gt;3次握手+4种状态：LISTEN、SYS_SEND、SYN_RCVD、ESTABLISHED。（第三次握手可以携带数据，是因为客户端已经明确知道连接建立了）&lt;/li&gt;
      &lt;li&gt;为什么是三次握手？不是两次、四次？
        &lt;ul&gt;
          &lt;li&gt;三次握手才可以阻止历史重复连接的初始化（主要原因）
            &lt;ul&gt;
              &lt;li&gt;如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：&lt;/li&gt;
              &lt;li&gt;如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接；&lt;/li&gt;
              &lt;li&gt;如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接；&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;三次握手才可以同步双方的初始序列号&lt;/li&gt;
          &lt;li&gt;三次握手才可以避免资源浪费
            &lt;ul&gt;
              &lt;li&gt;如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？&lt;/li&gt;
              &lt;li&gt;如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;什么是 SYN 攻击？
        &lt;ul&gt;
          &lt;li&gt;我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;如何避免 SYN 攻击？
        &lt;ul&gt;
          &lt;li&gt;net.ipv4.tcp_syncookies = 1，同一个客户端发起的和自己的cookie绑到，服务端就不会生成太多的SYN_RECD连接&lt;/li&gt;
          &lt;li&gt;net.ipv4.tcp_max_syn_backlog，设置最大的SYN_REVD数字&lt;/li&gt;
          &lt;li&gt;net.ipv4.tcp_abort_on_overflow ，超出处理能力丢弃&lt;/li&gt;
          &lt;li&gt;net.core.netdev_max_backlog，设置最大队列处理数字&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么客户端和服务端的初始序列号 ISN 是不相同的？
    &lt;ul&gt;
      &lt;li&gt;因为网络中的报文会延迟、会复制重发、也有可能丢失，这样会造成的不同连接之间产生互相影响，所以为了避免互相影响，客户端和服务端的初始序列号是随机且不同的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;初始序列号 ISN 是如何随机产生的？
    &lt;ul&gt;
      &lt;li&gt;起始 ISN 是基于时钟的，每 4 毫秒 + 1，转一圈要 4.55 个小时。&lt;/li&gt;
      &lt;li&gt;RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。&lt;/li&gt;
      &lt;li&gt;ISN = M + F (localhost, localport, remotehost, remoteport)
        &lt;ul&gt;
          &lt;li&gt;M 是一个计时器，这个计时器每隔 4 毫秒加 1。&lt;/li&gt;
          &lt;li&gt;F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
    &lt;ul&gt;
      &lt;li&gt;MTU：一个网络包的最大长度，以太网中一般为 1500 字节；&lt;/li&gt;
      &lt;li&gt;MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；&lt;/li&gt;
      &lt;li&gt;如果TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？&lt;/li&gt;
      &lt;li&gt;当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，在交给上一层 TCP 传输层。&lt;/li&gt;
      &lt;li&gt;这看起来井然有序，但这存在隐患的，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。&lt;/li&gt;
      &lt;li&gt;因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。&lt;/li&gt;
      &lt;li&gt;当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。&lt;/li&gt;
      &lt;li&gt;因此，可以得知由 IP 层进行分片传输，是非常没有效率的。&lt;/li&gt;
      &lt;li&gt;所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。&lt;/li&gt;
      &lt;li&gt;握手阶段协商 MSS，经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP断开连接
    &lt;ul&gt;
      &lt;li&gt;4次握手和6种状态，客户端FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT，服务端CLOSED_WAIT、LAST_ACK，CLOSE&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么 TIME_WAIT 等待的时间是 2MSL？
    &lt;ul&gt;
      &lt;li&gt;MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。&lt;/li&gt;
      &lt;li&gt;TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。&lt;/li&gt;
      &lt;li&gt;在LAST-ACK状态，如果一直没有收到ACK，会发起重发。&lt;/li&gt;
      &lt;li&gt;TIME_WAIT太短会造成，服务端则会一直处在 LASE-ACK 状态。当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么需要 TIME_WAIT 状态？
    &lt;ul&gt;
      &lt;li&gt;防止具有相同「四元组」的「旧」数据包被收到；&lt;/li&gt;
      &lt;li&gt;保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TIME_WAIT 过多有什么危害？
    &lt;ul&gt;
      &lt;li&gt;第一是内存资源占用；&lt;/li&gt;
      &lt;li&gt;第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如何优化 TIME_WAIT？
    &lt;ul&gt;
      &lt;li&gt;net.ipv4.tcp_tw_reuse = 1 ; net.ipv4.tcp_timstamps=1;这个时间戳的字段是在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。
  由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。
  温馨提醒：net.ipv4.tcp_tw_reuse要慎用，因为使用了它就必然要打开时间戳的支持 net.ipv4.tcp_timestamps，当客户端与服务端主机时间不同步时，客户端的发送的消息会被直接拒绝掉。小林在工作中就遇到过。。。排查了非常的久&lt;/li&gt;
      &lt;li&gt;net.ipv4.tcp_max_tw_buckets ; 这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。&lt;/li&gt;
      &lt;li&gt;程序中使用 SO_LINGER ,如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;保活机制
    &lt;ul&gt;
      &lt;li&gt;tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制&lt;/li&gt;
      &lt;li&gt;tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；&lt;/li&gt;
      &lt;li&gt;tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。&lt;/li&gt;
      &lt;li&gt;高效保活长连接：手把手教你实现 自适应的心跳保活机制 &lt;a href=&quot;https://mp.weixin.qq.com/s/BsLAXegZOE6B9CzW31xIdA&quot;&gt;https://mp.weixin.qq.com/s/BsLAXegZOE6B9CzW31xIdA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;聊聊 TCP 长连接和心跳那些事 &lt;a href=&quot;https://mp.weixin.qq.com/s/cwqAMPku-LwXAGM3Cqztig&quot;&gt;https://mp.weixin.qq.com/s/cwqAMPku-LwXAGM3Cqztig&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;listen 时候参数 backlog 的意义？
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int listen &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;int socketfd, int backlog&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
参数一 socketfd 为 socketfd 文件描述符
参数二 backlog，这参数在历史有一定的变化
在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。
在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，所以现在通常认为 backlog 是 accept 队列。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;粘包拆包，应用层拆包？
    &lt;ul&gt;
      &lt;li&gt;如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这就是TCP协议中经常会遇到的粘包以及拆包的问题。
我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能&lt;/li&gt;
      &lt;li&gt;SO_TCPNODELAY:NAGLE 算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量 小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法。&lt;/li&gt;
      &lt;li&gt;拆包方案
        &lt;ul&gt;
          &lt;li&gt;客户端在发送数据包的时候，每个包都固定长度，比如1024个字节大小，如果客户端发送的数据长度不足1024个字节，则通过补充空格的方式补全到指定长度；&lt;/li&gt;
          &lt;li&gt;客户端在每个包的末尾使用固定的分隔符，例如\r\n，如果一个包被拆分了，则等待下一个包发送过来之后找到其中的\r\n，然后对其拆分后的头部部分与前一个包的剩余部分进行合并，这样就得到了一个完整的包；&lt;/li&gt;
          &lt;li&gt;将消息分为头部和消息体，在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息；&lt;/li&gt;
          &lt;li&gt;通过自定义协议进行粘包和拆包的处理。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用了哪些算法？
    &lt;ul&gt;
      &lt;li&gt;重传算法&lt;/li&gt;
      &lt;li&gt;RTO计算&lt;/li&gt;
      &lt;li&gt;Nagle算法，累计够数据再发送&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;netty
    &lt;ul&gt;
      &lt;li&gt;无锁设计、线程绑定，类似偏向锁读写操作会判断是否是之前绑定的线程&lt;/li&gt;
      &lt;li&gt;netty + protobuf ???&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;reactor和proactor模型
    &lt;ul&gt;
      &lt;li&gt;reactor：基于NIO技术，可读可写时通知应用；await阻塞等待&lt;/li&gt;
      &lt;li&gt;proactor：基于AIO技术，读完成时通知应用，写操作应用通知内核。真正的异步。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Java nio 空轮询bug到底是什么，异常情况导致的fd集合为空时，selector仍然会轮训 &lt;a href=&quot;https://mp.weixin.qq.com/s/-SoUVFB5DhaUZg_novolkg&quot;&gt;https://mp.weixin.qq.com/s/-SoUVFB5DhaUZg_novolkg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;zookeeper的observer&quot;&gt;ZooKeeper的observer&lt;/h4&gt;
&lt;p&gt;当ZooKeeper集群中follower的数量很多时，投票过程会成为一个性能瓶颈，为了解决投票造成的压力，于是出现了observer角色。
observer角色不参与投票，它只是投票结果的”听众”，除此之外，它和follower完全一样，例如能接受读、写请求。就这一个特点，让整个ZooKeeper集群性能大大改善。
和follower一样，当observer收到客户端的读请求时，会直接从内存数据库中取出数据返回给客户端。
对于写请求，当写请求发送到某server上后，无论这个节点是follower还是observer，都会将它发送给leader。然后leader组织投票过程，所有server都收到这个proposal(包括observer，因为proposal是广播出去的)，但是leader和follower以及observer通过配置文件，都知道自己是不是observer以及谁是observer。自己是observer的server不参与投票。当leader收集完投票后，将那些observer的server去掉，在剩下的server中计算大多数，如果投票结果达到了大多数，这次写事务就成功，于是leader通知所有的节点(包括observer)，让它们将事务写入事务日志，并提交。&lt;/p&gt;

&lt;p&gt;Pojo(plian ordinary普通的; 平常的; java object)&lt;/p&gt;

&lt;h4 id=&quot;jvm&quot;&gt;JVM&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-Xms2g&lt;/span&gt;：初始化推大小为 2g；
&lt;span class=&quot;nt&quot;&gt;-Xmx2g&lt;/span&gt;：堆最大内存为 2g；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:NewRatio&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4：设置年轻的和老年代的内存比例为 1:4；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:SurvivorRatio&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8：设置新生代 Eden 和 Survivor 比例为 8:2；
–XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+PrintGC：开启打印 gc 信息；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+PrintGCDetails：打印 gc 详细信息。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;分代垃圾回收器是怎么工作的&quot;&gt;分代垃圾回收器是怎么工作的？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。&lt;/li&gt;
  &lt;li&gt;新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是  8:1:1，它的执行流程如下：&lt;/li&gt;
  &lt;li&gt;把 Eden + From Survivor 存活的对象放入 To Survivor 区；
清空 Eden 和 From Survivor 分区；
From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。
每次在 From Survivor 到 To Survivor 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。&lt;/li&gt;
  &lt;li&gt;老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;垃圾回收器&quot;&gt;垃圾回收器&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；&lt;/li&gt;
  &lt;li&gt;ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现；&lt;/li&gt;
  &lt;li&gt;Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景；&lt;/li&gt;
  &lt;li&gt;Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；&lt;/li&gt;
  &lt;li&gt;Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本；&lt;/li&gt;
  &lt;li&gt;CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。&lt;/li&gt;
  &lt;li&gt;G1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bionioaio-有什么区别&quot;&gt;BIO,NIO,AIO 有什么区别?&lt;/h4&gt;
&lt;p&gt;BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。
NIO：Non IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。
AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。&lt;/p&gt;

&lt;p&gt;BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。
NIO (New I/O): NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发
AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。&lt;/p&gt;

&lt;h4 id=&quot;kafka数据存储&quot;&gt;kafka数据存储&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kafka和RocketMQ存储区别 &lt;a href=&quot;https://mp.weixin.qq.com/s/_hJcEqTMASpeDkavcdtDsw&quot;&gt;https://mp.weixin.qq.com/s/_hJcEqTMASpeDkavcdtDsw&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;partition：topic 的分区，一个 topic 可以包含多个 partition，topic 消息保存在各个partition 上
    &lt;ul&gt;
      &lt;li&gt;每个partition是一个有序的队列也是一个目录。&lt;/li&gt;
      &lt;li&gt;partition 内消息是有序的，Consumer 通过 pull 方式消费消息。Kafka 不删除已消费的消息.。对于 partition，顺序读写磁盘数据，以时间复杂度 O(1)方式提供消息持久化能力。&lt;/li&gt;
      &lt;li&gt;每个partition(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;segment：partition物理上由多个segment文件组成，每个segment大小相等，顺序读写。
    &lt;ul&gt;
      &lt;li&gt;每个 segment 数据文件以该段中最小的 offset 命名，文件扩展名为.log。这样在查找指定 offset 的 Message 的 时候，用二分查找就可以定位到该 Message 在哪个 segment 数据文件中。&lt;/li&gt;
      &lt;li&gt;segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kafka 为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩 展名为.index。index 文件中并没有为数据文件中的每条 Message 建立索引，而是采用了稀疏存 储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以 将索引文件保留在内存中。&lt;/li&gt;
  &lt;li&gt;由于消息 topic 由多个 partition 组成，且 partition 会均衡分布到不同 broker 上，因此，为了有 效利用 broker 集群的性能，提高消息的吞吐量，producer 可以通过随机或者 hash 等方式，将消 息平均发送到多个 partition 上，以实现负载均衡。&lt;/li&gt;
  &lt;li&gt;是提高消息吞吐量重要的方式，Producer 端可以在内存中合并多条消息后，以一次请求的方式发 送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响 了消息的实时性，相当于以时延代价，换取更好的吞吐量。&lt;/li&gt;
  &lt;li&gt;Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在 Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大 数据处理上，瓶颈往往体现在网络上而不是 CPU(压缩和解压会耗掉部分 CPU 资源)。&lt;/li&gt;
  &lt;li&gt;Current Offset是针对Consumer的poll过程的，它可以保证每次poll都返回不重复的消息；而Committed Offset是用于Consumer Rebalance过程的，它能够保证新的Consumer能够从正确的位置开始消费一个partition，从而避免重复消费。&lt;/li&gt;
  &lt;li&gt;Zookeeper：保存着集群 broker、topic、partition 等 meta 数据;另外，还负责 broker 故障发现，partition leader 选举，负载均衡等功能。&lt;/li&gt;
  &lt;li&gt;auto.offset.reset表示如果Kafka中没有存储对应的offset信息的话（有可能offset信息被删除），消费者从何处开始消费消息。它拥有三个可选值：earliest：从最早的offset开始消费、latest：从最后的offset开始消费、none：直接抛出exception给consumer&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hashmap-为啥size是2的倍数18比17做了哪些优化&quot;&gt;HashMap 为啥size是2的倍数，1.8比1.7做了哪些优化？&lt;/h4&gt;
&lt;p&gt;JDK1.7 VS JDK1.8 比较
JDK1.8主要解决或优化了一下问题：
resize 扩容优化
引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考
解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。&lt;/p&gt;

&lt;h4 id=&quot;spring&quot;&gt;Spring&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；&lt;/li&gt;
  &lt;li&gt;Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；&lt;/li&gt;
  &lt;li&gt;Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；&lt;/li&gt;
  &lt;li&gt;Feign：基于Ribbon和Hystrix的声明式服务调用组件；&lt;/li&gt;
  &lt;li&gt;Zuul：API网关组件，对请求提供路由及过滤功能。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Bus
用于传播集群状态变化的消息总线，使用轻量级消息代理链接分布式系统中的节点，可以用来动态刷新集群中的服务配置。
Spring Cloud Bus 提供了跨多个实例刷新配置的功能。因此，在上面的示例中，如果我们刷新 Employee Producer1，则会自动刷新所有其他必需的模块。如果我们有多个微服务启动并运行，这特别有用。这是通过将所有微服务连接到单个消息代理来实现的。无论何时刷新实例，此事件都会订阅到侦听此代理的所有微服务，并且它们也会刷新。可以通过使用端点/总线/刷新来实现对任何单个实例的刷新。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Consul
基于Hashicorp Consul的服务治理组件。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Security
安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Sleuth
Spring Cloud应用程序的分布式请求链路跟踪，支持使用Zipkin、HTrace和基于日志（例如ELK）的跟踪。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Stream
轻量级事件驱动微服务框架，可以使用简单的声明式模型来发送及接收消息，主要实现为Apache Kafka及RabbitMQ。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Task
用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Zookeeper
基于Apache Zookeeper的服务治理组件。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Gateway
API网关组件，对请求提供路由及过滤功能。Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul网关。网关作为流量的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。
使用了一个RouteLocatorBuilder的bean去创建路由，除了创建路由RouteLocatorBuilder可以让你添加各种predicates和filters，predicates断言的意思，顾名思义就是根据具体的请求的规则，由具体的route去处理，filters是各种过滤器，用来对请求做各种判断和修改。&lt;/li&gt;
  &lt;li&gt;Spring Cloud OpenFeign
基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。&lt;/li&gt;
  &lt;li&gt;什么是Spring Cloud Config?
在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。
使用：（1）添加pom依赖（2）配置文件添加相关配置（3）启动类添加注解@EnableConfigServer&lt;/li&gt;
  &lt;li&gt;Spring中使用@Autowired注解静态实例对象 &lt;a href=&quot;https://blog.csdn.net/RogueFist/article/details/79575665&quot;&gt;https://blog.csdn.net/RogueFist/article/details/79575665&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多个ApplicationRunner，可以用@Order指定优先级串行执行的，如果优先级高的block了，后面的需要等着&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;protocol-buffer-的序列化--反序列化简单--速度快的原因是&quot;&gt;Protocol Buffer 的序列化 &amp;amp; 反序列化简单 &amp;amp; 速度快的原因是:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;编码 / 解码 方式简单(只需要简单的数学运算 = 位移等等)&lt;/li&gt;
  &lt;li&gt;采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;protocol-buffer-的数据压缩效果好即序列化后的数据量体积小的原因是&quot;&gt;Protocol Buffer 的数据压缩效果好(即序列化后的数据量体积小)的原因是:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;a. 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等&lt;/li&gt;
  &lt;li&gt;b. 采用 T - L - V 的数据存储方式:减少了分隔符的使用 &amp;amp; 数据存储得紧凑&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;hbase-cassandra-mongodb&quot;&gt;HBase Cassandra MongoDB&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;存储结构
    &lt;ul&gt;
      &lt;li&gt;MongoDB：GridFS、JSON/BSON&lt;/li&gt;
      &lt;li&gt;HBase：HRegionServer：【HLog、HRegion：【Store MemStore、StoreFile、HFile】】、HDFS&lt;/li&gt;
      &lt;li&gt;Cassandra：LSM、HashNode、CommitLog、memtable、SSTable&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;存储形式
    &lt;ul&gt;
      &lt;li&gt;MongoDB：Collection JSON&lt;/li&gt;
      &lt;li&gt;Cassandra：Column family ，Row，Name/Value/Timestamp&lt;/li&gt;
      &lt;li&gt;HBase：put ‘t_user’,’1001’,’st1:age’,’18’&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;数据类型
    &lt;ul&gt;
      &lt;li&gt;MongoDB丰富，类似SQL&lt;/li&gt;
      &lt;li&gt;HBase只支持字符串&lt;/li&gt;
      &lt;li&gt;Cassandra多种&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;索引、二级索引、辅助索引
    &lt;ul&gt;
      &lt;li&gt;MongoDB：支持全索引，实现高性能。单一索引、复合、哈希、地址位置、文本等索引。BTree&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;事务
    &lt;ul&gt;
      &lt;li&gt;HBase的事务是行级事务，可以保证行级数据的原子性、一致性、隔离性以及持久性&lt;/li&gt;
      &lt;li&gt;MongoDB不支持事务&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;一致性和CAP
    &lt;ul&gt;
      &lt;li&gt;MongoDB、HBase强一致性，CP&lt;/li&gt;
      &lt;li&gt;Cassandra最终一致性（可调一致性），AP&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Join支持
    &lt;ul&gt;
      &lt;li&gt;MongoDB不支持多表连接
  = Cassandra不支持多表连接，用数据冗余解决问题hotels_by_poi&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;范围查询
    &lt;ul&gt;
      &lt;li&gt;MongoDB：利用skip().limit()实现&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;读写
    &lt;ul&gt;
      &lt;li&gt;HBase快速读取和写入，具有可扩展性&lt;/li&gt;
      &lt;li&gt;Cassandra快速随机性读取/写入，写多读少&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://blog.csdn.net/aa5305123/article/details/83142514
https://www.cnblogs.com/yanduanduan/p/10563678.html  &lt;br /&gt;
1.强一致性的读写：HBase不是一个最终一致性的存储。
2.自动sharding：HBase的table在集群种被分布在各个region，region可以做自动切分。
3.regionserver的failover；
4.Hadoop/HDFS的集成；
5.MapReduce：支持大数据的并行处理；
6.JAVA Client 以及Thrift/RESR API 访问；
7.Block Cache 以及Bloom filter；
8.操作管理。&lt;/p&gt;

&lt;p&gt;1.C&lt;em&gt;借鉴Dynamo的架构思想，把自己叫做一个最终一致性的系统，如果使用至少是QUORUM 读写，还算是一个强一致的系统。
2.C&lt;/em&gt;的sharding方式：一致性hash，有2种：
（1）人为配置好initial_token；
2.使用vnode，集群初始化以及节点bootstrap的时候会计算token，基于这些token做数据sharding。
3.可以容忍：replicator_number - (read/write level sufficient nodes)个节点挂了，比如3个副本，读写级别QUORUM（sufficient nodes是2），能容忍1节点挂；
4.支持MapReduce;
5.Thrift、CQL访问;
6.大数据处理的bloom filter 必备；
7.自己有jmx等常见管理，且datastax 公司有提供ops center；&lt;/p&gt;

&lt;h4 id=&quot;seata-的-demo&quot;&gt;seata 的 Demo&lt;/h4&gt;
&lt;h4 id=&quot;hive--mysql数据互导&quot;&gt;Hive &amp;amp; Mysql数据互导&lt;/h4&gt;
&lt;h4 id=&quot;tweproxy&quot;&gt;tweproxy&lt;/h4&gt;
</description>
        <pubDate>Tue, 16 Jun 2020 12:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/16/DotDot.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/16/DotDot.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>经典算法思想</title>
        <description>&lt;p&gt;数据结构算法，问题TOP10 &lt;a href=&quot;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&quot;&gt;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;贪心算法&quot;&gt;贪心算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;贪心的意思在于在作出选择时，每次都要选择对自身最为有利的结果，保证自身利益的最大化。贪心算法就是利用这种贪心思想而得出一种算法。&lt;/li&gt;
  &lt;li&gt;例：小明手中有 1，5，10，50，100 五种面额的纸币，每种纸币对应张数分别为 5，2，2，3，5 张。若小明需要支付 456 元，则需要多少张纸币？&lt;/li&gt;
  &lt;li&gt;最小生成树 Kruskal算法&lt;/li&gt;
  &lt;li&gt;最小生成树 prim算法&lt;/li&gt;
  &lt;li&gt;分发饼干、跳跃游戏、无重叠区间、摆动序列 &lt;a href=&quot;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&quot;&gt;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;分糖果、无重叠区间 &lt;a href=&quot;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&quot;&gt;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分治算法&quot;&gt;分治算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;快速排序算法、大整数乘法、残缺棋盘游戏 &lt;a href=&quot;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&quot;&gt;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;汉诺塔、快速排序、归并排序 &lt;a href=&quot;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&quot;&gt;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;动态规划算法-dynamic-programming&quot;&gt;动态规划算法 Dynamic Programming&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 2&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;+F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;（n&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3）

F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;9&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;8&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#最优子结构&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#边界&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#状态转移方程&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;斐波那契 &lt;a href=&quot;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&quot;&gt;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;上台阶与挖黄金 &lt;a href=&quot;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&quot;&gt;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;高楼扔鸡蛋 &lt;a href=&quot;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&quot;&gt;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;回溯法&quot;&gt;回溯法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&quot;&gt;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题 &lt;a href=&quot;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&quot;&gt;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题与数独 &lt;a href=&quot;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&quot;&gt;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;A*寻路算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分支定界法&quot;&gt;分支定界法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;广度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&quot;&gt;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;字符串匹配算法&quot;&gt;字符串匹配算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;BF算法，是Brute Force（暴力算法，按位比较 O(m*n)）&lt;a href=&quot;https://mp.weixin.qq.com/s/2RlyDBo-Ql-1Ofh8tMyikg&quot;&gt;https://mp.weixin.qq.com/s/2RlyDBo-Ql-1Ofh8tMyikg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;RK算法，是Rabin-Karp (计算hash值进行比较 O(n)) &lt;a href=&quot;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&quot;&gt;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Knuth-Morris-Pratt算法（简称KMP）是最常用的之一 &lt;a href=&quot;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&quot;&gt;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;字符串匹配算法综述:BF、RK、KMP、BM、Sunday &lt;a href=&quot;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&quot;&gt;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;小灰算法2017 &lt;a href=&quot;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&quot;&gt;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2018 &lt;a href=&quot;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&quot;&gt;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2019 &lt;a href=&quot;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&quot;&gt;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2020 &lt;a href=&quot;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&quot;&gt;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;二十世纪最伟大的10大算法 &lt;a href=&quot;https://blog.csdn.net/v_JULY_v/article/details/6127953&quot;&gt;https://blog.csdn.net/v_JULY_v/article/details/6127953&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>BitMap-BloomFilter</title>
        <description>&lt;h4 id=&quot;bitmap&quot;&gt;BitMap&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;近似的理解为用一个大数组的索引来表示数字本身，用0或1表示该数字是否存在&lt;/li&gt;
  &lt;li&gt;一个32位的int，只用一个标志位来表示是否存在&lt;/li&gt;
  &lt;li&gt;但是数字如果重复只会保留一个，主要用于去重类似的场景&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bloomfilter&quot;&gt;BloomFilter&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;判断短连接是否重复、垃圾邮件等场景&lt;/li&gt;
  &lt;li&gt;把url，3次不同hash，得到3个不同的hashcode，存入bitmap&lt;/li&gt;
  &lt;li&gt;多次hash是为了降低hash重复的概率&lt;/li&gt;
  &lt;li&gt;由于以上特性，bloomFilter算法计算出不存在的一定就是不存在，如果计算出来存在有一定几率重复（因为hash的特性）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考链接&quot;&gt;参考链接&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Bitmap算法 整合版 &lt;a href=&quot;https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg&quot;&gt;https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;什么是布隆算法？&lt;a href=&quot;https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ&quot;&gt;https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>大数据常用算法概述</title>
        <description>&lt;h4 id=&quot;决策树算法&quot;&gt;决策树算法&lt;/h4&gt;
&lt;h4 id=&quot;回归算法&quot;&gt;回归算法&lt;/h4&gt;
&lt;h4 id=&quot;朴素贝叶斯算法&quot;&gt;朴素贝叶斯算法&lt;/h4&gt;
&lt;h4 id=&quot;聚类-knn算法&quot;&gt;聚类-KNN算法&lt;/h4&gt;
&lt;h4 id=&quot;svm支持向量机&quot;&gt;SVM支持向量机&lt;/h4&gt;
&lt;h4 id=&quot;推荐算法&quot;&gt;推荐算法&lt;/h4&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 12:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>ZooKeeper</title>
        <description>&lt;h4 id=&quot;使用场景&quot;&gt;使用场景&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;注册中心&lt;/li&gt;
  &lt;li&gt;配置中心&lt;/li&gt;
  &lt;li&gt;HBase之MetaData存储&lt;/li&gt;
  &lt;li&gt;分布式锁&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;常用命令&quot;&gt;常用命令&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./zkServer.sh start | stop 
./zkServer.sh status
./zkCli.sh 

&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;stat&lt;/span&gt; /
ls2 /

create /node1 /node1-content
create &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; /node1-temp /node1-content-temp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/dandandeshangni/article/details/80558383&quot;&gt;https://blog.csdn.net/dandandeshangni/article/details/80558383&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;阿里为什么不用-zookeeper-做服务发现&quot;&gt;阿里为什么不用 ZooKeeper 做服务发现？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;基于CP而非AP&lt;/li&gt;
  &lt;li&gt;自身仅仅是主从的集群，而非分布式集群&lt;/li&gt;
  &lt;li&gt;The King Of Coordination for Big Data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&quot;&gt;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 12:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</guid>
        
        <category>微服务</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>'图'相关算法</title>
        <description>&lt;h4 id=&quot;什么时图&quot;&gt;什么时”图”&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;可以简单理解我存储关系的数据结构，比如好友关系&lt;/li&gt;
  &lt;li&gt;分为有向图、无向图&lt;/li&gt;
  &lt;li&gt;存储结构
    &lt;ul&gt;
      &lt;li&gt;邻接矩阵（类似多维数组）&lt;/li&gt;
      &lt;li&gt;邻接表  （类似”正”索引）&lt;/li&gt;
      &lt;li&gt;逆邻接表 （类似倒排索引）&lt;/li&gt;
      &lt;li&gt;十字链表  （正倒索引联合）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;深度优先遍历-和-广度优先遍历&quot;&gt;深度优先遍历 和 广度优先遍历&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历，沿着当前分支，直到最后一个节点，然后遍历相邻节点（二叉树的前中后序遍历就是深度优先遍历），重点在回溯&lt;/li&gt;
  &lt;li&gt;广度优先遍历，遍历完当前节点的所有子节点，然后切换到下级节点（类似二叉树的层级遍历），重点在重放&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图的-最短路径&quot;&gt;图的 “最短路径”&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;迪杰斯特拉算法 Dijkstra，解决带权重的A-&amp;gt;G最短路径 &lt;a href=&quot;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&quot;&gt;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，解决多个带权重节点间的最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;路径规划之 A* 算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;最小生成树&quot;&gt;最小生成树&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;把所有点在没有回路的情况下，连接起来，并且权重相加最小（权重可以理解为城市见的距离）&lt;/li&gt;
  &lt;li&gt;Kruskal算法，克鲁斯卡尔算法的基本思想是以边为主导地位，始终选择当前可用的最小边权的边（可以直接快排或者algorithm的sort）。每次选择边权最小的边链接两个端点是kruskal的规则，并实时判断两个点之间有没有间接联通。
（也算是贪心算法思想）&lt;a href=&quot;https://blog.csdn.net/qq_41754350/article/details/81460643&quot;&gt;https://blog.csdn.net/qq_41754350/article/details/81460643&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;prim算法，这个算法是以图的顶点为基础，从一个初始顶点开始，寻找触达其他顶点权值最小的边，并把该顶点加入到已触达顶点的集合中。当全部顶点都加入到集合时，算法的工作就完成了。Prim算法的本质，是基于贪心算法。
&lt;a href=&quot;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&quot;&gt;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ford-fulkerson-最大流算法&quot;&gt;Ford-Fulkerson 最大流算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;解决的问题：在一个流里，有着每条边的运载能力限制，我最多能从源头运输多少数量到目的地。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/DarrenChan/p/9563511.html&quot;&gt;https://www.cnblogs.com/DarrenChan/p/9563511.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/sinat_41613352/article/details/84481115&quot;&gt;https://blog.csdn.net/sinat_41613352/article/details/84481115&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sat, 06 Jun 2020 09:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> 数据结构 </title>
        <description>&lt;h4 id=&quot;数组&quot;&gt;数组&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;链表&quot;&gt;链表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。&lt;/li&gt;
  &lt;li&gt;这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。&lt;/li&gt;
  &lt;li&gt;一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;跳表&quot;&gt;跳表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从O(n)提升至O(logn)。&lt;/li&gt;
  &lt;li&gt;跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前redis和levelDB都有用到跳表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;栈&quot;&gt;栈&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;后进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;队列&quot;&gt;队列&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;先进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;树&quot;&gt;树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将“链表”竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。&lt;/li&gt;
  &lt;li&gt;树遍历
    &lt;ul&gt;
      &lt;li&gt;前序遍历：根结点 —&amp;gt; 左子树 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;中序遍历：左子树—&amp;gt; 根结点 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;后序遍历：左子树 —&amp;gt; 右子树 —&amp;gt; 根结点&lt;/li&gt;
      &lt;li&gt;层次遍历：仅仅需按层次遍历就可以&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;平衡二叉树&quot;&gt;平衡二叉树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;平衡二叉树又被称为AVL树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;红黑树&quot;&gt;红黑树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;每个结点要么是红的要么是黑的。&lt;/li&gt;
  &lt;li&gt;根结点是黑的。&lt;/li&gt;
  &lt;li&gt;每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。&lt;/li&gt;
  &lt;li&gt;如果一个结点是红的，那么它的两个儿子都是黑的。&lt;/li&gt;
  &lt;li&gt;对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。&lt;/li&gt;
  &lt;li&gt;Map、Set、epoll/select中句柄集&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;堆&quot;&gt;堆&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。&lt;/li&gt;
  &lt;li&gt;堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;散列表-hash&quot;&gt;散列表 Hash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通过某种算法确定唯一（有些算法会出现不同的value算出相同的Hash值）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图&quot;&gt;图&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;多维数据存储,实际应用中是通过图这种模式建立索引与关联关系&lt;/li&gt;
  &lt;li&gt;图数据库？
    &lt;ul&gt;
      &lt;li&gt;图数据库(Graph database)并非指存储图片的数据库，而是以图这种数据结构存储和查询数据。&lt;/li&gt;
      &lt;li&gt;图形数据库是一种在线数据库管理系统，具有处理图形数据模型的创建，读取，更新和删除（CRUD）操作。&lt;/li&gt;
      &lt;li&gt;与其他数据库不同，关系在图数据库中占首要地位。这意味着应用程序不必使用外键或带外处理（如MapReduce）来推断数据连接。&lt;/li&gt;
      &lt;li&gt;与关系数据库或其他NoSQL数据库相比，图数据库的数据模型也更加简单，更具表现力。&lt;/li&gt;
      &lt;li&gt;图形数据库是为与事务（OLTP）系统一起使用而构建的，并且在设计时考虑了事务完整性和操作可用性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&quot;&gt;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>排序算法概述</title>
        <description>&lt;h4 id=&quot;冒泡排序&quot;&gt;冒泡排序&lt;/h4&gt;
&lt;pre&gt;
从左开始比较，大的往右换
或
从右开始比较，小的往左换
重复上一步骤
&lt;/pre&gt;
&lt;h4 id=&quot;鸡尾排序&quot;&gt;鸡尾排序&lt;/h4&gt;
&lt;pre&gt;
也叫双向冒泡或者定向冒泡，
从左开始比较，大的往右换
与
从右开始比较，小的往左换
同时进行
&lt;/pre&gt;
&lt;h4 id=&quot;选择排序&quot;&gt;选择排序&lt;/h4&gt;
&lt;pre&gt;
与冒泡排序相比减少了多余的交换
找出最小的元素放在最左侧，接着找第二小的...直到最后排完(不稳定)
&lt;/pre&gt;
&lt;h4 id=&quot;快速排序&quot;&gt;快速排序&lt;/h4&gt;
&lt;pre&gt;
选中一个基准元素X，小于X放在左侧，大于X放在右侧，分而治之，不断重复
&lt;/pre&gt;
&lt;h4 id=&quot;插入排序&quot;&gt;插入排序&lt;/h4&gt;
&lt;pre&gt;
从左侧开始设定一个有序区，从第二个元素开始去有序找自己的位置插入进去
&lt;/pre&gt;
&lt;h4 id=&quot;希尔排序&quot;&gt;希尔排序&lt;/h4&gt;
&lt;pre&gt;
两两分组，跨度交换，左小右大，逐渐缩小跨度为1，即完成&lt;/pre&gt;
&lt;h4 id=&quot;归并排序比武排序&quot;&gt;归并排序(比武排序)&lt;/h4&gt;
&lt;pre&gt;
由一组数字分为两组，逐渐分为只包含2个元素的小组
开始比较大小，左小右大
比较完毕之后，开始合并，合并的时候按照小大顺序把2个小组合并成1个有序大组，直到最后1个最大有序组
&lt;/pre&gt;
&lt;h4 id=&quot;计数排序&quot;&gt;计数排序&lt;/h4&gt;
&lt;pre&gt;
建立【元素都为0】的空数组，开始遍历待排序数组
如果待排元素值等于空数组的位置角标，则【元素+1】
&lt;/pre&gt;
&lt;h4 id=&quot;桶排序&quot;&gt;桶排序&lt;/h4&gt;
&lt;pre&gt;
计数排序的升级版，计数排序每个索引只能记录一个值，
索引升级为桶（比如桶范围2.0-3.5）
此时，一个桶里就可以放多个数据范围内的数据
&lt;/pre&gt;
&lt;h4 id=&quot;基数排序按位排序&quot;&gt;基数排序（按位排序）&lt;/h4&gt;
&lt;pre&gt;
提取每个元素的最后一位进行计数排序
再提取倒数第二位进行计数排序
直到最前一位
比如：单词排序，长度不一的末尾用0代替
&lt;/pre&gt;
&lt;h4 id=&quot;堆排序&quot;&gt;堆排序&lt;/h4&gt;
&lt;pre&gt;
主要利用二叉堆是完全二叉堆这样的数据结构的特性
把无序数组构建成二叉堆。
循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。

二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。
利用大顶堆，删除顶点放于数组未部，此后二叉堆自我调整选出新的堆顶
&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/cq2EhVtOTzTVpNpLDXfeJg&quot;&gt;https://mp.weixin.qq.com/s/cq2EhVtOTzTVpNpLDXfeJg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考-httpsmpweixinqqcomsteogqlslb6ap4aqrx7ttza&quot;&gt;参考 &lt;a href=&quot;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&quot;&gt;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&lt;/a&gt;&lt;/h4&gt;
</description>
        <pubDate>Sun, 31 May 2020 11:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> kafka activeMQ RabbitMq RocketMQ </title>
        <description>&lt;h4 id=&quot;amqp即advanced-message-queuing-protocolactivemqrabbitmq都支持&quot;&gt;AMQP，即Advanced Message Queuing Protocol（ActiveMQ、RabbitMQ都支持）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ &lt;a href=&quot;https://www.jianshu.com/p/78847c203b76&quot;&gt;https://www.jianshu.com/p/78847c203b76&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;两种消息模型&quot;&gt;两种消息模型：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;点对点（单播），当采用点对点模型时，消息将发送到一个队列，该队列的消息只能被一个消费者消费。&lt;/li&gt;
  &lt;li&gt;publish-subscribe（发布订阅、广播）模型。而采用发布订阅模型时，消息可以被多个消费者消费。
在发布订阅模型中，生产者和消费者完全独立，不需要感知对方的存在。
例如，在用户登录后，各个其他模板更加登录进行不同的处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证可用性&quot;&gt;如何保证可用性&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;主从架构（ActiveMQ、RabbitMQ、RocketMQ）&lt;/li&gt;
  &lt;li&gt;分布式架构（kafka）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消息不被重复消费&quot;&gt;如何保证消息不被重复消费？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分析:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。&lt;/li&gt;
  &lt;li&gt;回答:先来说一下为什么会造成重复消费?
  其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。
  如何解决?这个问题针对业务场景来答分以下几点
  - 比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
    &lt;ul&gt;
      &lt;li&gt;再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
  - 如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&amp;lt;id,message&amp;gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;消费者消费失败如何处理&quot;&gt;消费者消费失败，如何处理？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消费成功时，手动ack，这样队列会再次推送或者再次pull&lt;/li&gt;
  &lt;li&gt;用redis对立的”伪消费队列”最大的问题就是在于消费后没有ACK，发生意外会有很多脏数据&lt;/li&gt;
  &lt;li&gt;也可以用幂等的方式消费者保存业务的进展，用单独程序做补偿消费&lt;/li&gt;
  &lt;li&gt;如果消费者处理一个消息失败了，消息系统一般会把这个消息放回队列，这样其他消费者可以继续处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消费的可靠性传输&quot;&gt;如何保证消费的可靠性传输?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ
    &lt;ul&gt;
      &lt;li&gt;生产者丢数据，可以用事务方式来保证发送成功或回滚，也可以队列接受后异步返回ack或nack来实现&lt;/li&gt;
      &lt;li&gt;消息队列丢数据，可以持久化队列并且配置自动重复参数&lt;/li&gt;
      &lt;li&gt;消费者丢数据，手动ack
        &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rabbitmq-server start
service rabbitmq-server restart
rabbitmqctl status
rabbitmq-plugins &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;rabbitmq_management
rabbitmqctl add_user rabbitmq 123456
rabbitmqctl set_user_tags rabbitmq administrator
rabbitmqctl set_permissions &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; / rabbitmq &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;kafka
    &lt;ul&gt;
      &lt;li&gt;(1)生产者丢数据
在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置
        &lt;ol&gt;
          &lt;li&gt;第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。&lt;/li&gt;
          &lt;li&gt;在producer端设置retries=MAX，一旦写入失败，这无限重试&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消息队列丢数据
针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。
        &lt;ol&gt;
          &lt;li&gt;replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本&lt;/li&gt;
          &lt;li&gt;min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系
这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消费者丢数据
这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的
offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;rocketmq&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# install rocketmq&lt;/span&gt;
unzip rocketmq-all-4.7.0-source-release.zip
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;rocketmq-all-4.7.0/
mvn &lt;span class=&quot;nt&quot;&gt;-Prelease-all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-DskipTests&lt;/span&gt; clean &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-U&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;distribution/target/rocketmq-4.7.0/rocketmq-4.7.0

&lt;span class=&quot;c&quot;&gt;# config JAVA_HOME&lt;/span&gt;
vim ~/.bashrc
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/lib/jvm/jdk-13
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Name Server&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqnamesrv &amp;amp;
&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ~/logs/rocketmqlogs/namesrv.log
&lt;span class=&quot;c&quot;&gt;#The Name Server boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Broker&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &amp;amp;
&lt;span class=&quot;c&quot;&gt;#The broker[%s, 172.30.30.233:10911] boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 外网访问 配置 /etc/hosts&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 相关报错 RemotingTooMuchRequestException: sendDefaultImpl call timeout；&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;# 配置conf/broker.conf &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;brokerIP1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hostname.com
./mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; ../conf/broker.conf &amp;amp;

&lt;span class=&quot;c&quot;&gt;# 相关报错 No route info of this topic&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 保持客户端rocketmq版本号与服务器一致&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 设置该属性 autoCreateTopicEnable=true &lt;/span&gt;
./mqadmin topicList &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;rocketmq为什么使用nameserver而不使用ZooKeeper？&lt;a href=&quot;https://blog.csdn.net/earthhour/article/details/78718064&quot;&gt;https://blog.csdn.net/earthhour/article/details/78718064&lt;/a&gt;
    &lt;h4 id=&quot;推拉模式&quot;&gt;推拉模式&lt;/h4&gt;
    &lt;p&gt;消费模式分为推（push）模式和拉（pull）模式。推模式是指由 Broker 主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。而拉模式是指消费端主动向 Broker 端请求拉取（一般是定时或者定量）消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;关于kafka&quot;&gt;关于kafka&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Apache Kafka不是消息中间件的一种实现。相反，它只是一种分布式流式系统。
不同于基于队列和交换器的RabbitMQ，Kafka的存储层是使用分区事务日志来实现的。&lt;/li&gt;
  &lt;li&gt;过期日志会根据时间或大小，进行清除&lt;/li&gt;
  &lt;li&gt;极好的总结 &lt;a href=&quot;https://segmentfault.com/a/1190000021138998&quot;&gt;https://segmentfault.com/a/1190000021138998&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;zookeeper在kafka中的作用 &lt;a href=&quot;https://www.jianshu.com/p/a036405f989c&quot;&gt;https://www.jianshu.com/p/a036405f989c&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一次事故 &lt;a href=&quot;https://www.jianshu.com/p/72a54f835b6b&quot;&gt;https://www.jianshu.com/p/72a54f835b6b&lt;/a&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#启动zk&lt;/span&gt;
bin/zookeeper-server-start.sh config/zookeeper.properties &amp;amp;
&lt;span class=&quot;c&quot;&gt;#启动kafka&lt;/span&gt;
bin/kafka-server-start.sh config/server.properties
&lt;span class=&quot;c&quot;&gt;# kafka默认只支持本地访问，如果需要外网访问，需要用hostname.com的方式配置&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# hostname.com可以是任意自定义的，不需要备案，只是起到&quot;代名词&quot;作用&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#1、&lt;/span&gt;
config/server.properties
&lt;span class=&quot;nv&quot;&gt;listeners&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;PLAINTEXT://hostname.com:9092
&lt;span class=&quot;c&quot;&gt;#2、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#kafka broker机器配置hosts&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;#3、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#调用端也是是kafka的Client端 的机器配置hosts&lt;/span&gt;
broker机器的外网ip  hostname.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消息队列常见问题
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/williamjie/p/9481780.html&quot;&gt;https://www.cnblogs.com/williamjie/p/9481780.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;优知学院消息队列
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288173&quot;&gt;https://zhuanlan.zhihu.com/p/60288173&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288391&quot;&gt;https://zhuanlan.zhihu.com/p/60288391&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IM系统的MQ消息中间件选型：Kafka还是RabbitMQ？
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37993013&quot;&gt;https://zhuanlan.zhihu.com/p/37993013&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MQ消息队列的12点核心原理总结
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60289322&quot;&gt;https://zhuanlan.zhihu.com/p/60289322&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 22 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</guid>
        
        <category>MQ</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>Netty-Mina</title>
        <description>&lt;h4 id=&quot;从零开发一个im服务端&quot;&gt;从零开发一个IM服务端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通俗易懂 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;基于Netty实现海量接入的推送服务技术要点 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;必读有关为何选择netty的11个疑问及解答&quot;&gt;必读有关“为何选择Netty”的11个疑问及解答&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tcp网关&quot;&gt;TCP网关&lt;/h4&gt;
&lt;p&gt;HAProxy nginx LVS&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;生产环境大部分还是采用通过rest方式获取IpList，然后有客户端直接发起长连接的方式&lt;/li&gt;
  &lt;li&gt;京东京麦的生产级TCP网关技术实践总结 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一套海量在线用户的移动端IM架构设计实践 &lt;a href=&quot;http://www.52im.net/thread-812-1-1.html&quot;&gt;http://www.52im.net/thread-812-1-1.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;reactor-线程模型&quot;&gt;Reactor 线程模型&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Reactor 是反应堆的意思，Reactor 模型是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。
服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式，即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;why-nettyjdk-原生-nio-程序的问题&quot;&gt;Why Netty?JDK 原生 NIO 程序的问题&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;JDK 原生也有一套网络应用程序 API，但是存在一系列问题，主要如下：
    &lt;ol&gt;
      &lt;li&gt;NIO 的类库和 API 繁杂，使用麻烦：你需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。&lt;/li&gt;
      &lt;li&gt;需要具备其他的额外技能做铺垫：例如熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的 NIO 程序。&lt;/li&gt;
      &lt;li&gt;可靠性能力补齐，开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等。NIO 编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大。&lt;/li&gt;
      &lt;li&gt;JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。官方声称在 JDK 1.6 版本的 update 18 修复了该问题，但是直到 JDK 1.7 版本该问题仍旧存在，只不过该 Bug 发生概率降低了一些而已，它并没有被根本解决。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;java-nio-epoll-bug-以及-netty-的解决之道&quot;&gt;Java NIO epoll bug 以及 Netty 的解决之道&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;epoll 空轮询导致 CPU 利用率 100% &lt;a href=&quot;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&quot;&gt;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;netty中的epoll实现&quot;&gt;netty中的epoll实现&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;在java中，IO多路复用的功能通过nio中的Selector提供，在不同的操作系统下jdk会通过spi的方式加载不同的实现，
比如在macos下是KQueueSelectorProvider，KQueueSelectorProvider底层使用了kqueue来进行IO多路复用；
在linux 2.6以后的版本则是EPollSelectorProvider，EPollSelectorProvider底层使用的是epoll。
虽然jdk自身提供了selector的epoll实现，netty仍实现了自己的epoll版本，根据netty开发者在StackOverflow的回答，主要原因有两个：
    &lt;ul&gt;
      &lt;li&gt;支持更多socket option，比如TCP_CORK和SO_REUSEPORT&lt;/li&gt;
      &lt;li&gt;使用了边缘触发（ET）模式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://juejin.im/post/5d46ce64f265da03e05af722&quot;&gt;https://juejin.im/post/5d46ce64f265da03e05af722&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ET和LT的区别在于触发事件的条件不同，LT比较符合编程思维（有满足条件的就触发），ET触发的条件更苛刻一些（仅在发生变化时才触发），对使用者的要求也更高，理论效率更高&lt;/li&gt;
  &lt;li&gt;边缘触发和水平触发&lt;a href=&quot;https://juejin.im/post/5cdaa67f518825691b4a5cc0&quot;&gt;https://juejin.im/post/5cdaa67f518825691b4a5cc0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 18 May 2020 22:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</guid>
        
        <category>网络</category>
        
        <category>Java</category>
        
        
        <category>技术</category>
        
      </item>
    
  </channel>
</rss>
