<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>粉笔灰杂谈</title>
    <description>关于产品、技术、商业的一些见解，顺便记录一下自己的生活感悟和读书笔记。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 10 Jun 2020 11:30:50 +0800</pubDate>
    <lastBuildDate>Wed, 10 Jun 2020 11:30:50 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>经典算法思想</title>
        <description>&lt;p&gt;数据结构算法，问题TOP10 &lt;a href=&quot;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&quot;&gt;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;贪心算法&quot;&gt;贪心算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;贪心的意思在于在作出选择时，每次都要选择对自身最为有利的结果，保证自身利益的最大化。贪心算法就是利用这种贪心思想而得出一种算法。&lt;/li&gt;
  &lt;li&gt;例：小明手中有 1，5，10，50，100 五种面额的纸币，每种纸币对应张数分别为 5，2，2，3，5 张。若小明需要支付 456 元，则需要多少张纸币？&lt;/li&gt;
  &lt;li&gt;最小生成树 Kruskal算法&lt;/li&gt;
  &lt;li&gt;最小生成树 prim算法&lt;/li&gt;
  &lt;li&gt;分发饼干、跳跃游戏、无重叠区间、摆动序列 &lt;a href=&quot;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&quot;&gt;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;分糖果、无重叠区间 &lt;a href=&quot;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&quot;&gt;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分治算法&quot;&gt;分治算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;快速排序算法、大整数乘法、残缺棋盘游戏 &lt;a href=&quot;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&quot;&gt;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;汉诺塔、快速排序、归并排序 &lt;a href=&quot;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&quot;&gt;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;动态规划算法-dynamic-programming&quot;&gt;动态规划算法 Dynamic Programming&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 2&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;+F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;（n&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3）

F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;9&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;8&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#最优子结构&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#边界&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#状态转移方程&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;斐波那契 &lt;a href=&quot;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&quot;&gt;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;上台阶与挖黄金 &lt;a href=&quot;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&quot;&gt;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;高楼扔鸡蛋 &lt;a href=&quot;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&quot;&gt;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;回溯法&quot;&gt;回溯法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&quot;&gt;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题 &lt;a href=&quot;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&quot;&gt;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题与数独 &lt;a href=&quot;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&quot;&gt;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;A*寻路算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分支定界法&quot;&gt;分支定界法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;广度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&quot;&gt;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;字符串匹配算法&quot;&gt;字符串匹配算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;BF算法，是Brute Force（暴力算法，按位比较 O(m*n)）&lt;/li&gt;
  &lt;li&gt;RK算法，是Rabin-Karp (计算hash值进行比较 O(n)) &lt;a href=&quot;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&quot;&gt;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Knuth-Morris-Pratt算法（简称KMP）是最常用的之一 &lt;a href=&quot;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&quot;&gt;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;字符串匹配算法综述:BF、RK、KMP、BM、Sunday &lt;a href=&quot;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&quot;&gt;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;小灰算法2017 &lt;a href=&quot;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&quot;&gt;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2018 &lt;a href=&quot;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&quot;&gt;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2019 &lt;a href=&quot;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&quot;&gt;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2020 &lt;a href=&quot;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&quot;&gt;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;二十世纪最伟大的10大算法 &lt;a href=&quot;https://blog.csdn.net/v_JULY_v/article/details/6127953&quot;&gt;https://blog.csdn.net/v_JULY_v/article/details/6127953&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>BitMap-BloomFilter</title>
        <description>
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>大数据常用算法概述</title>
        <description>&lt;h4 id=&quot;决策树算法&quot;&gt;决策树算法&lt;/h4&gt;
&lt;h4 id=&quot;回归算法&quot;&gt;回归算法&lt;/h4&gt;
&lt;h4 id=&quot;朴素贝叶斯算法&quot;&gt;朴素贝叶斯算法&lt;/h4&gt;
&lt;h4 id=&quot;聚类-knn算法&quot;&gt;聚类-KNN算法&lt;/h4&gt;
&lt;h4 id=&quot;svm支持向量机&quot;&gt;SVM支持向量机&lt;/h4&gt;
&lt;h4 id=&quot;推荐算法&quot;&gt;推荐算法&lt;/h4&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 12:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>ZooKeeper</title>
        <description>&lt;h4 id=&quot;使用场景&quot;&gt;使用场景&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;注册中心&lt;/li&gt;
  &lt;li&gt;配置中心&lt;/li&gt;
  &lt;li&gt;HBase之MetaData存储&lt;/li&gt;
  &lt;li&gt;分布式锁&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;常用命令&quot;&gt;常用命令&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./zkServer.sh start | stop 
./zkServer.sh status
./zkCli.sh 

&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;stat&lt;/span&gt; /
ls2 /

create /node1 /node1-content
create &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; /node1-temp /node1-content-temp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/dandandeshangni/article/details/80558383&quot;&gt;https://blog.csdn.net/dandandeshangni/article/details/80558383&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;阿里为什么不用-zookeeper-做服务发现&quot;&gt;阿里为什么不用 ZooKeeper 做服务发现？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;基于CP而非AP&lt;/li&gt;
  &lt;li&gt;自身仅仅是主从的集群，而非分布式集群&lt;/li&gt;
  &lt;li&gt;The King Of Coordination for Big Data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&quot;&gt;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 12:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</guid>
        
        <category>微服务</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>'图'相关算法</title>
        <description>&lt;h4 id=&quot;什么时图&quot;&gt;什么时”图”&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;可以简单理解我存储关系的数据结构，比如好友关系&lt;/li&gt;
  &lt;li&gt;分为有向图、无向图&lt;/li&gt;
  &lt;li&gt;存储结构
    &lt;ul&gt;
      &lt;li&gt;邻接矩阵（类似多维数组）&lt;/li&gt;
      &lt;li&gt;邻接表  （类似”正”索引）&lt;/li&gt;
      &lt;li&gt;逆邻接表 （类似倒排索引）&lt;/li&gt;
      &lt;li&gt;十字链表  （正倒索引联合）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;深度优先遍历-和-广度优先遍历&quot;&gt;深度优先遍历 和 广度优先遍历&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历，沿着当前分支，直到最后一个节点，然后遍历相邻节点（二叉树的前中后序遍历就是深度优先遍历），重点在回溯&lt;/li&gt;
  &lt;li&gt;广度优先遍历，遍历完当前节点的所有子节点，然后切换到下级节点（类似二叉树的层级遍历），重点在重放&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图的-最短路径&quot;&gt;图的 “最短路径”（&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;迪杰斯特拉算法 Dijkstra，解决带权重的A-&amp;gt;G最短路径 &lt;a href=&quot;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&quot;&gt;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，解决多个带权重节点间的最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;路径规划之 A* 算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ford-fulkerson-最大流算法&quot;&gt;Ford-Fulkerson 最大流算法&lt;/h4&gt;

&lt;h4 id=&quot;最小生成树&quot;&gt;最小生成树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Kruskal算法 &lt;a href=&quot;https://blog.csdn.net/qq_41754350/article/details/81460643&quot;&gt;https://blog.csdn.net/qq_41754350/article/details/81460643&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;prim算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&quot;&gt;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 09:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> 数据结构 </title>
        <description>&lt;h4 id=&quot;数组&quot;&gt;数组&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;链表&quot;&gt;链表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。&lt;/li&gt;
  &lt;li&gt;这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。&lt;/li&gt;
  &lt;li&gt;一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;跳表&quot;&gt;跳表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从O(n)提升至O(logn)。&lt;/li&gt;
  &lt;li&gt;跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前redis和levelDB都有用到跳表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;栈&quot;&gt;栈&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;后进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;队列&quot;&gt;队列&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;先进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;树&quot;&gt;树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将“链表”竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。&lt;/li&gt;
  &lt;li&gt;树遍历
    &lt;ul&gt;
      &lt;li&gt;前序遍历：根结点 —&amp;gt; 左子树 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;中序遍历：左子树—&amp;gt; 根结点 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;后序遍历：左子树 —&amp;gt; 右子树 —&amp;gt; 根结点&lt;/li&gt;
      &lt;li&gt;层次遍历：仅仅需按层次遍历就可以&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;平衡二叉树&quot;&gt;平衡二叉树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;平衡二叉树又被称为AVL树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;红黑树&quot;&gt;红黑树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;每个结点要么是红的要么是黑的。&lt;/li&gt;
  &lt;li&gt;根结点是黑的。&lt;/li&gt;
  &lt;li&gt;每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。&lt;/li&gt;
  &lt;li&gt;如果一个结点是红的，那么它的两个儿子都是黑的。&lt;/li&gt;
  &lt;li&gt;对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。&lt;/li&gt;
  &lt;li&gt;Map、Set、epoll/select中句柄集&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;堆&quot;&gt;堆&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。&lt;/li&gt;
  &lt;li&gt;堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;散列表-hash&quot;&gt;散列表 Hash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通过某种算法确定唯一（有些算法会出现不同的value算出相同的Hash值）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图&quot;&gt;图&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;多维数据存储,实际应用中是通过图这种模式建立索引与关联关系&lt;/li&gt;
  &lt;li&gt;图数据库？
    &lt;ul&gt;
      &lt;li&gt;图数据库(Graph database)并非指存储图片的数据库，而是以图这种数据结构存储和查询数据。&lt;/li&gt;
      &lt;li&gt;图形数据库是一种在线数据库管理系统，具有处理图形数据模型的创建，读取，更新和删除（CRUD）操作。&lt;/li&gt;
      &lt;li&gt;与其他数据库不同，关系在图数据库中占首要地位。这意味着应用程序不必使用外键或带外处理（如MapReduce）来推断数据连接。&lt;/li&gt;
      &lt;li&gt;与关系数据库或其他NoSQL数据库相比，图数据库的数据模型也更加简单，更具表现力。&lt;/li&gt;
      &lt;li&gt;图形数据库是为与事务（OLTP）系统一起使用而构建的，并且在设计时考虑了事务完整性和操作可用性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&quot;&gt;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>排序算法概述</title>
        <description>&lt;h4 id=&quot;冒泡排序&quot;&gt;冒泡排序&lt;/h4&gt;
&lt;pre&gt;
从左开始比较，大的往右换
或
从右开始比较，小的往左换
重复上一步骤
&lt;/pre&gt;
&lt;h4 id=&quot;鸡尾排序&quot;&gt;鸡尾排序&lt;/h4&gt;
&lt;pre&gt;
也叫双向冒泡或者定向冒泡，
从左开始比较，大的往右换
与
从右开始比较，小的往左换
同时进行
&lt;/pre&gt;
&lt;h4 id=&quot;选择排序&quot;&gt;选择排序&lt;/h4&gt;
&lt;pre&gt;
与冒泡排序相比减少了多余的交换
找出最小的元素放在最左侧，接着找第二小的...直到最后排完(不稳定)
&lt;/pre&gt;
&lt;h4 id=&quot;快速排序&quot;&gt;快速排序&lt;/h4&gt;
&lt;pre&gt;
选中一个基准元素X，小于X放在左侧，大于X放在右侧，分而治之，不断重复
&lt;/pre&gt;
&lt;h4 id=&quot;插入排序&quot;&gt;插入排序&lt;/h4&gt;
&lt;pre&gt;
从左侧开始设定一个有序区，从第二个元素开始去有序找自己的位置插入进去
&lt;/pre&gt;
&lt;h4 id=&quot;希尔排序&quot;&gt;希尔排序&lt;/h4&gt;
&lt;pre&gt;
两两分组，跨度交换，左小右大，逐渐缩小跨度为1，即完成&lt;/pre&gt;
&lt;h4 id=&quot;归并排序比武排序&quot;&gt;归并排序(比武排序)&lt;/h4&gt;
&lt;pre&gt;
由一组数字分为两组，逐渐分为只包含2个元素的小组
开始比较大小，左小右大
比较完毕之后，开始合并，合并的时候按照小大顺序把2个小组合并成1个有序大组，直到最后1个最大有序组
&lt;/pre&gt;
&lt;h4 id=&quot;计数排序&quot;&gt;计数排序&lt;/h4&gt;
&lt;pre&gt;
建立【元素都为0】的空数组，开始遍历待排序数组
如果待排元素值等于空数组的位置角标，则【元素+1】
&lt;/pre&gt;
&lt;h4 id=&quot;桶排序&quot;&gt;桶排序&lt;/h4&gt;
&lt;pre&gt;
计数排序的升级版，计数排序每个索引只能记录一个值，
索引升级为桶（比如桶范围2.0-3.5）
此时，一个桶里就可以放多个数据范围内的数据
&lt;/pre&gt;
&lt;h4 id=&quot;基数排序按位排序&quot;&gt;基数排序（按位排序）&lt;/h4&gt;
&lt;pre&gt;
提取每个元素的最后一位进行计数排序
再提取倒数第二位进行计数排序
直到最前一位
比如：单词排序，长度不一的末尾用0代替
&lt;/pre&gt;
&lt;h4 id=&quot;堆排序&quot;&gt;堆排序&lt;/h4&gt;
&lt;pre&gt;
主要利用二叉堆是完全二叉堆这样的数据结构的特性
把无序数组构建成二叉堆。
循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。

二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。
利用大顶堆，删除顶点放于数组未部，此后二叉堆自我调整选出新的堆顶
&lt;/pre&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/cq2EhVtOTzTVpNpLDXfeJg&quot;&gt;https://mp.weixin.qq.com/s/cq2EhVtOTzTVpNpLDXfeJg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考-httpsmpweixinqqcomsteogqlslb6ap4aqrx7ttza&quot;&gt;参考 &lt;a href=&quot;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&quot;&gt;https://mp.weixin.qq.com/s/teOGQlslb6aP4AQrx7TTzA&lt;/a&gt;&lt;/h4&gt;
</description>
        <pubDate>Sun, 31 May 2020 11:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/SortAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> kafka activeMQ RabbitMq RocketMQ </title>
        <description>&lt;h4 id=&quot;amqp即advanced-message-queuing-protocolactivemqrabbitmq都支持&quot;&gt;AMQP，即Advanced Message Queuing Protocol（ActiveMQ、RabbitMQ都支持）&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ &lt;a href=&quot;https://www.jianshu.com/p/78847c203b76&quot;&gt;https://www.jianshu.com/p/78847c203b76&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;两种消息模型&quot;&gt;两种消息模型：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;点对点（单播），当采用点对点模型时，消息将发送到一个队列，该队列的消息只能被一个消费者消费。&lt;/li&gt;
  &lt;li&gt;publish-subscribe（发布订阅、广播）模型。而采用发布订阅模型时，消息可以被多个消费者消费。
在发布订阅模型中，生产者和消费者完全独立，不需要感知对方的存在。
例如，在用户登录后，各个其他模板更加登录进行不同的处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证可用性&quot;&gt;如何保证可用性&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;主从架构（ActiveMQ、RabbitMQ、RocketMQ）&lt;/li&gt;
  &lt;li&gt;分布式架构（kafka）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消息不被重复消费&quot;&gt;如何保证消息不被重复消费？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分析:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。&lt;/li&gt;
  &lt;li&gt;回答:先来说一下为什么会造成重复消费?
  其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。
  如何解决?这个问题针对业务场景来答分以下几点
  - 比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
    &lt;ul&gt;
      &lt;li&gt;再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
  - 如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&amp;lt;id,message&amp;gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;消费者消费失败如何处理&quot;&gt;消费者消费失败，如何处理？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消费成功时，手动ack，这样队列会再次推送或者再次pull&lt;/li&gt;
  &lt;li&gt;用redis对立的”伪消费队列”最大的问题就是在于消费后没有ACK，发生意外会有很多脏数据&lt;/li&gt;
  &lt;li&gt;也可以用幂等的方式消费者保存业务的进展，用单独程序做补偿消费&lt;/li&gt;
  &lt;li&gt;如果消费者处理一个消息失败了，消息系统一般会把这个消息放回队列，这样其他消费者可以继续处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何保证消费的可靠性传输&quot;&gt;如何保证消费的可靠性传输?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;RabbitMQ
    &lt;ul&gt;
      &lt;li&gt;生产者丢数据，可以用事务方式来保证发送成功或回滚，也可以队列接受后异步返回ack或nack来实现&lt;/li&gt;
      &lt;li&gt;消息队列丢数据，可以持久化队列并且配置自动重复参数&lt;/li&gt;
      &lt;li&gt;消费者丢数据，手动ack
        &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rabbitmq-server start
service rabbitmq-server restart
rabbitmqctl status
rabbitmq-plugins &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;rabbitmq_management
rabbitmqctl add_user rabbitmq 123456
rabbitmqctl set_user_tags rabbitmq administrator
rabbitmqctl set_permissions &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; / rabbitmq &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;.*&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;kafka
    &lt;ul&gt;
      &lt;li&gt;(1)生产者丢数据
在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置
        &lt;ol&gt;
          &lt;li&gt;第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。&lt;/li&gt;
          &lt;li&gt;在producer端设置retries=MAX，一旦写入失败，这无限重试&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消息队列丢数据
针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。
        &lt;ol&gt;
          &lt;li&gt;replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本&lt;/li&gt;
          &lt;li&gt;min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系
这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;消费者丢数据
这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的
offset：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;rocketmq&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# install rocketmq&lt;/span&gt;
unzip rocketmq-all-4.7.0-source-release.zip
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;rocketmq-all-4.7.0/
mvn &lt;span class=&quot;nt&quot;&gt;-Prelease-all&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-DskipTests&lt;/span&gt; clean &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-U&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;distribution/target/rocketmq-4.7.0/rocketmq-4.7.0

&lt;span class=&quot;c&quot;&gt;# config JAVA_HOME&lt;/span&gt;
vim ~/.bashrc
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/lib/jvm/jdk-13
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/lib
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Name Server&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqnamesrv &amp;amp;
&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; ~/logs/rocketmqlogs/namesrv.log
&lt;span class=&quot;c&quot;&gt;#The Name Server boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Start Broker&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;nohup &lt;/span&gt;sh bin/mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &amp;amp;
&lt;span class=&quot;c&quot;&gt;#The broker[%s, 172.30.30.233:10911] boot success...&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 外网访问 配置 /etc/hosts&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 相关报错 RemotingTooMuchRequestException: sendDefaultImpl call timeout；&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;# 配置conf/broker.conf &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;brokerIP1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;hostname.com
./mqbroker &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; ../conf/broker.conf &amp;amp;

&lt;span class=&quot;c&quot;&gt;# 相关报错 No route info of this topic&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 保持客户端rocketmq版本号与服务器一致&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 设置该属性 autoCreateTopicEnable=true &lt;/span&gt;
./mqadmin topicList &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; localhost:9876

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;rocketmq为什么使用nameserver而不使用ZooKeeper？&lt;a href=&quot;https://blog.csdn.net/earthhour/article/details/78718064&quot;&gt;https://blog.csdn.net/earthhour/article/details/78718064&lt;/a&gt;
    &lt;h4 id=&quot;推拉模式&quot;&gt;推拉模式&lt;/h4&gt;
    &lt;p&gt;消费模式分为推（push）模式和拉（pull）模式。推模式是指由 Broker 主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。而拉模式是指消费端主动向 Broker 端请求拉取（一般是定时或者定量）消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;关于kafka&quot;&gt;关于kafka&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Apache Kafka不是消息中间件的一种实现。相反，它只是一种分布式流式系统。
不同于基于队列和交换器的RabbitMQ，Kafka的存储层是使用分区事务日志来实现的。&lt;/li&gt;
  &lt;li&gt;过期日志会根据时间或大小，进行清除&lt;/li&gt;
  &lt;li&gt;极好的总结 &lt;a href=&quot;https://segmentfault.com/a/1190000021138998&quot;&gt;https://segmentfault.com/a/1190000021138998&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;zookeeper在kafka中的作用 &lt;a href=&quot;https://www.jianshu.com/p/a036405f989c&quot;&gt;https://www.jianshu.com/p/a036405f989c&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一次事故 &lt;a href=&quot;https://www.jianshu.com/p/72a54f835b6b&quot;&gt;https://www.jianshu.com/p/72a54f835b6b&lt;/a&gt;
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#启动zk&lt;/span&gt;
bin/zookeeper-server-start.sh config/zookeeper.properties &amp;amp;
&lt;span class=&quot;c&quot;&gt;#启动kafka&lt;/span&gt;
bin/kafka-server-start.sh config/server.properties
&lt;span class=&quot;c&quot;&gt;# kafka默认只支持本地访问，如果需要外网访问，需要用hostname.com的方式配置&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# hostname.com可以是任意自定义的，不需要备案，只是起到&quot;代名词&quot;作用&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#1、&lt;/span&gt;
config/server.properties
&lt;span class=&quot;nv&quot;&gt;listeners&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;PLAINTEXT://hostname.com:9092
&lt;span class=&quot;c&quot;&gt;#2、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#kafka broker机器配置hosts&lt;/span&gt;
broker机器的内网ip  hostname.com
&lt;span class=&quot;c&quot;&gt;#3、&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#调用端也是是kafka的Client端 的机器配置hosts&lt;/span&gt;
broker机器的外网ip  hostname.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;消息队列常见问题
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/williamjie/p/9481780.html&quot;&gt;https://www.cnblogs.com/williamjie/p/9481780.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;优知学院消息队列
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288173&quot;&gt;https://zhuanlan.zhihu.com/p/60288173&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60288391&quot;&gt;https://zhuanlan.zhihu.com/p/60288391&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IM系统的MQ消息中间件选型：Kafka还是RabbitMQ？
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37993013&quot;&gt;https://zhuanlan.zhihu.com/p/37993013&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MQ消息队列的12点核心原理总结
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60289322&quot;&gt;https://zhuanlan.zhihu.com/p/60289322&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 22 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/22/MessageQueue.html</guid>
        
        <category>MQ</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>Netty-Mina</title>
        <description>&lt;h4 id=&quot;从零开发一个im服务端&quot;&gt;从零开发一个IM服务端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通俗易懂 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2768&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;基于Netty实现海量接入的推送服务技术要点 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=166&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;必读有关为何选择netty的11个疑问及解答&quot;&gt;必读有关“为何选择Netty”的11个疑问及解答&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=163&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tcp网关&quot;&gt;TCP网关&lt;/h4&gt;
&lt;p&gt;HAProxy nginx LVS&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;生产环境大部分还是采用通过rest方式获取IpList，然后有客户端直接发起长连接的方式&lt;/li&gt;
  &lt;li&gt;京东京麦的生产级TCP网关技术实践总结 &lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=1243&amp;amp;highlight=netty&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一套海量在线用户的移动端IM架构设计实践 &lt;a href=&quot;http://www.52im.net/thread-812-1-1.html&quot;&gt;http://www.52im.net/thread-812-1-1.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;reactor-线程模型&quot;&gt;Reactor 线程模型&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Reactor 是反应堆的意思，Reactor 模型是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。
服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式，即 I/O 多了复用统一监听事件，收到事件后分发(Dispatch 给某进程)，是编写高性能网络服务器的必备技术之一。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&quot;&gt;http://www.52im.net/forum.php?mod=viewthread&amp;amp;tid=2043&amp;amp;highlight=netty&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;why-nettyjdk-原生-nio-程序的问题&quot;&gt;Why Netty?JDK 原生 NIO 程序的问题&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;JDK 原生也有一套网络应用程序 API，但是存在一系列问题，主要如下：
    &lt;ol&gt;
      &lt;li&gt;NIO 的类库和 API 繁杂，使用麻烦：你需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer 等。&lt;/li&gt;
      &lt;li&gt;需要具备其他的额外技能做铺垫：例如熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的 NIO 程序。&lt;/li&gt;
      &lt;li&gt;可靠性能力补齐，开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等等。NIO 编程的特点是功能开发相对容易，但是可靠性能力补齐工作量和难度都非常大。&lt;/li&gt;
      &lt;li&gt;JDK NIO 的 Bug：例如臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%。官方声称在 JDK 1.6 版本的 update 18 修复了该问题，但是直到 JDK 1.7 版本该问题仍旧存在，只不过该 Bug 发生概率降低了一些而已，它并没有被根本解决。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;java-nio-epoll-bug-以及-netty-的解决之道&quot;&gt;Java NIO epoll bug 以及 Netty 的解决之道&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;epoll 空轮询导致 CPU 利用率 100% &lt;a href=&quot;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&quot;&gt;http://songkun.me/2019/07/26/2019-07-26-java-nio-epoll-bug-and-netty-solution/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;netty中的epoll实现&quot;&gt;netty中的epoll实现&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;在java中，IO多路复用的功能通过nio中的Selector提供，在不同的操作系统下jdk会通过spi的方式加载不同的实现，
比如在macos下是KQueueSelectorProvider，KQueueSelectorProvider底层使用了kqueue来进行IO多路复用；
在linux 2.6以后的版本则是EPollSelectorProvider，EPollSelectorProvider底层使用的是epoll。
虽然jdk自身提供了selector的epoll实现，netty仍实现了自己的epoll版本，根据netty开发者在StackOverflow的回答，主要原因有两个：
    &lt;ul&gt;
      &lt;li&gt;支持更多socket option，比如TCP_CORK和SO_REUSEPORT&lt;/li&gt;
      &lt;li&gt;使用了边缘触发（ET）模式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://juejin.im/post/5d46ce64f265da03e05af722&quot;&gt;https://juejin.im/post/5d46ce64f265da03e05af722&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ET和LT的区别在于触发事件的条件不同，LT比较符合编程思维（有满足条件的就触发），ET触发的条件更苛刻一些（仅在发生变化时才触发），对使用者的要求也更高，理论效率更高&lt;/li&gt;
  &lt;li&gt;边缘触发和水平触发&lt;a href=&quot;https://juejin.im/post/5cdaa67f518825691b4a5cc0&quot;&gt;https://juejin.im/post/5cdaa67f518825691b4a5cc0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 18 May 2020 22:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/18/Netty-Mina.html</guid>
        
        <category>网络</category>
        
        <category>Java</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> BigData </title>
        <description>&lt;h4 id=&quot;hdfshive-与-hbasephoenix的区别&quot;&gt;HDFS+Hive 与 HBase+Phoenix的区别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Hive中的表是纯逻辑表，就只是表的定义等，即表的元数据。Hive本身不存储数据，它完全依赖HDFS和MapReduce。这样就可以将结构化的数据文件映射为为一张数据库表，并提供完整的SQL查询功能，并将SQL语句最终转换为MapReduce任务进行运行。 而HBase表是物理表，适合存放非结构化的数据。
    &lt;ol&gt;
      &lt;li&gt;两者分别是什么？
        &lt;ul&gt;
          &lt;li&gt;Apache Hive是数据仓库。通过Hive可以使用HQL语言查询存放在HDFS上的数据。HQL是一种类SQL语言，这种语言最终被转化为Map/Reduce. 虽然Hive提供了SQL查询功能，但是Hive不能够进行交互查询–因为它是基于MapReduce算法。&lt;/li&gt;
          &lt;li&gt;Apache Hbase Key/Value，基础单元是cell，它运行在HDFS之上。和Hive不一样，Hbase的能够在它的数据库上实时运行，而不是运行MapReduce任务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;两者的特点
        &lt;ul&gt;
          &lt;li&gt;Hive帮助熟悉SQL的人运行MapReduce任务。因为它是JDBC兼容的。运行Hive查询会花费很长时间，因为它会默认遍历表中所有的数据。但可以通过Hive的分区来控制。因为这样一来文件大小是固定的，就这么大一块存储空间，从固定空间里查数据是很快的。&lt;/li&gt;
          &lt;li&gt;HBase通过存储key/value来工作。注意版本的功能。你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;限制
        &lt;ul&gt;
          &lt;li&gt;Hive目前不支持更新操作。另外，由于hive在hadoop上运行批量操作，它需要花费很长的时间，通常是几分钟到几个小时才可以获取到查询的结果。Hive必须提供预先定义好的schema将文件和目录映射到列，并且Hive与ACID不兼容。&lt;/li&gt;
          &lt;li&gt;HBase查询是通过特定的语言来编写的，这种语言需要重新学习。类SQL的功能可以通过Apache Phonenix实现，但这是以必须提供schema为代价的。另外，Hbase也并不是兼容所有的ACID特性，虽然它支持某些特性。最后但不是最重要的–为了运行Hbase，Zookeeper是必须的，zookeeper是一个用来进行分布式协调的服务，这些服务包括配置服务，维护元信息和命名空间服务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;应用场景
        &lt;ul&gt;
          &lt;li&gt;Hive适合用来对一段时间内的数据进行分析查询，例如，用来计算趋势或者网站的日志。Hive不应该用来进行实时的查询。因为它需要很长时间才可以返回结果。&lt;/li&gt;
          &lt;li&gt;Hbase非常适合用来进行大数据的实时查询。Facebook用Hbase进行消息和实时的分析。它也可以用来统计Facebook的连接数。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;两者关系
        &lt;ul&gt;
          &lt;li&gt;Hive和Pig都可以与HBase组合使用，Hive和Pig还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单&lt;/li&gt;
          &lt;li&gt;Hive与HBase，都是在Hadoop体系使用&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;总结
        &lt;ul&gt;
          &lt;li&gt;Hive和Hbase是两种基于Hadoop的不同技术–Hive是一种类SQL的引擎，并且运行MapReduce任务，Hbase是一种在Hadoop之上的NoSQL 的Key/vale数据库。当然，这两种工具是可以同时使用的。就像用Google来搜索，用FaceBook进行社交一样，Hive可以用来进行统计查询，HBase可以用来进行实时查询，数据也可以从Hive写到Hbase，设置再从Hbase写回Hive。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;其他
        &lt;ul&gt;
          &lt;li&gt;Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。近似理解为SQL ON Hadoop&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hadoop--spark--storm&quot;&gt;Hadoop &amp;amp; Spark &amp;amp; Storm&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Hadoop，是实现了MapReduce的思想，将数据切片计算来处理大量的离线数据。Hadoop处理的数据必须是已经存放在HDFS上或者类似HBase的数据库中，所以Hadoop实现的时候是通过移动计算到这些存放数据的机器上来提高效率。
适合于离线的批量数据处理适用于对实时性要求极低的场景。&lt;/li&gt;
  &lt;li&gt;Storm，可以用来处理源源不断流进来的消息，处理之后将结果写入到某个存储中去。实时性方面做得极好。(可以脱离Hadoop体系单独使用)&lt;/li&gt;
  &lt;li&gt;Spark，是一个基于内存计算的开源集群计算系统，目的是更快速的进行数据分析。Spark由加州伯克利大学AMP实验室Matei为主的小团队使用Scala开发，类似于Hadoop MapReduce的通用并行计算框架，Spark基于Map Reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的Map Reduce的算法。
(可以简单理解为”另一种形式的MapReduce”或者是第二代”引擎”，需要在Hadoop体系使用)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;flume--kafka--storm&quot;&gt;flume &amp;amp; kafka &amp;amp; storm&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;flume收集日志，推到kafka缓冲一下，storm消费计算，最终结果存储&lt;/li&gt;
  &lt;li&gt;基于Flume的美团日志收集系统 &lt;a href=&quot;https://tech.meituan.com/2013/12/09/meituan-flume-log-system-architecture-and-design.html&quot;&gt;https://tech.meituan.com/2013/12/09/meituan-flume-log-system-architecture-and-design.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;流式数据采集和计算 &lt;a href=&quot;https://blog.csdn.net/yezonggang/article/details/85034069&quot;&gt;https://blog.csdn.net/yezonggang/article/details/85034069&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Flume+Kafka+Storm+Redis构建大数据实时处理系统：实时统计网站PV、UV+展示 &lt;a href=&quot;https://blog.51cto.com/xpleaf/2104160&quot;&gt;https://blog.51cto.com/xpleaf/2104160&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;搭建单机hadoop&quot;&gt;搭建单机Hadoop&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1. 配置环境变量&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/java/jdk1.8
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JRE_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/java/jdk1.8/jre
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CLASSPATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/lib/dt.jar:&lt;span class=&quot;nv&quot;&gt;$JAVA_HOME&lt;/span&gt;/lib/tools.jar:&lt;span class=&quot;nv&quot;&gt;$JRE_HOME&lt;/span&gt;/lib

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/home/hadoop/hadoop2.8
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_COMMON_LIB_NATIVE_DIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;/lib/native
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;-Djava.library.path=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/lib&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;.:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;JAVA_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;HADOOP_HOME&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/bin:&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 2. 创建目录&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/tmp  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/var  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs/name  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hadoop/dfs/data

&lt;span class=&quot;c&quot;&gt;# 3. 修改配置文件&lt;/span&gt;
vim core-site.xml
vim hadoop-env.sh
vim hdfs-site.xml
vim mapred-site.xml

&lt;span class=&quot;c&quot;&gt;# 4. 启动&lt;/span&gt;
bin/hadoop  namenode  &lt;span class=&quot;nt&quot;&gt;-format&lt;/span&gt;
start-dfs.sh
start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;搭建单机hbase&quot;&gt;搭建单机HBase&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 1. 搭建好Hadoop&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 2. 创建目录&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase/tmp  
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt;  /root/hbase/pids
&lt;span class=&quot;c&quot;&gt;# 3. 启动&lt;/span&gt;
./start-hbase.sh
&lt;span class=&quot;c&quot;&gt;# 4. 常用命令&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 进入shell&lt;/span&gt;
hbase shell
create &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st2'&lt;/span&gt;
put &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1:age'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'18'&lt;/span&gt;
put &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st2:name'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'zhangsan'&lt;/span&gt;
scan &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 查询该表数据&lt;/span&gt;
describe &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
delete&lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'1001'&lt;/span&gt;,&lt;span class=&quot;s1&quot;&gt;'st1:age'&lt;/span&gt;
disable &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
drop &lt;span class=&quot;s1&quot;&gt;'t_user'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;用HBase实现亿级Feed &lt;a href=&quot;https://mp.weixin.qq.com/s/kY2hYTuE1tR6HmgdfnmyiQ&quot;&gt;https://mp.weixin.qq.com/s/kY2hYTuE1tR6HmgdfnmyiQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;HBase案例 &lt;a href=&quot;https://mp.weixin.qq.com/s/ieGZq3rZ-guIsm4hIRtHDw&quot;&gt;https://mp.weixin.qq.com/s/ieGZq3rZ-guIsm4hIRtHDw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;HBase面试题 &lt;a href=&quot;https://www.jianshu.com/p/9ecd4367e6d0&quot;&gt;https://www.jianshu.com/p/9ecd4367e6d0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;es结合Hbase &lt;a href=&quot;https://zhuanlan.zhihu.com/p/87563468&quot;&gt;https://zhuanlan.zhihu.com/p/87563468&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Hbase和Cassandra比较 &lt;a href=&quot;https://blog.csdn.net/aa5305123/article/details/83142514&quot;&gt;https://blog.csdn.net/aa5305123/article/details/83142514&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;白话大数据 &lt;a href=&quot;https://www.zhihu.com/question/27974418/answer/156227565&quot;&gt;https://www.zhihu.com/question/27974418/answer/156227565&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;一步步搭建Hadoop体系 &lt;a href=&quot;https://blog.csdn.net/qazwsxpcm/article/list/2?t=1&quot;&gt;https://blog.csdn.net/qazwsxpcm/article/list/2?t=1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 01 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/BigData.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/01/BigData.html</guid>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
  </channel>
</rss>
