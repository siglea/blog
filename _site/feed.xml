<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>粉笔灰杂谈</title>
    <description>关于产品、技术、商业的一些见解，顺便记录一下自己的生活感悟和读书笔记。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 22 Jun 2020 23:35:12 +0800</pubDate>
    <lastBuildDate>Mon, 22 Jun 2020 23:35:12 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>SaaS业务分析</title>
        <description>&lt;h4 id=&quot;中国saas的增长困境&quot;&gt;中国SaaS的增长困境&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;SaaS的收入模式是订阅模式，而订阅收入的衡量指标是所谓的NDR（Net Dollar Retention），也就是收入的净留存。
  NDR的计算公式为：NDR=(beginningrevenue+upgrades-downgrades-churn)/beginning revenue&lt;/li&gt;
  &lt;li&gt;SaaS销售员的首要任务不是成交，而是找到可合作的优质客户，其次的责任才是成交。&lt;/li&gt;
  &lt;li&gt;销售员这个角色，在SaaS公司应该被定义为播种者，而非收割者。
改变培训导向和调整提成制度。引导价值成交，树立SaaS的销售业绩导向。&lt;/li&gt;
  &lt;li&gt;ARR是annual recurring revenue的缩写&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.futunn.com/market/125247&quot;&gt;https://news.futunn.com/market/125247&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/101133113&quot;&gt;https://zhuanlan.zhihu.com/p/101133113&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 22 Jun 2020 21:58:00 +0800</pubDate>
        <link>http://localhost:4000/%E4%BA%A7%E5%93%81%E5%95%86%E4%B8%9A/2020/06/22/SaaS%E4%B8%9A%E5%8A%A1.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E4%BA%A7%E5%93%81%E5%95%86%E4%B8%9A/2020/06/22/SaaS%E4%B8%9A%E5%8A%A1.html</guid>
        
        <category>toB</category>
        
        
        <category>产品商业</category>
        
      </item>
    
      <item>
        <title>用户画像</title>
        <description>&lt;h4 id=&quot;核心&quot;&gt;核心&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;用户画像体系，有这一篇就够了 &lt;a href=&quot;https://mp.weixin.qq.com/s/WbBUX2g_XhGXrH9xtv0i2Q&quot;&gt;https://mp.weixin.qq.com/s/WbBUX2g_XhGXrH9xtv0i2Q&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;用户画像原理、技术选型及架构实现 &lt;a href=&quot;https://blog.csdn.net/SecondLieutenant/article/details/81153565&quot;&gt;https://blog.csdn.net/SecondLieutenant/article/details/81153565&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;用户画像概述&quot;&gt;用户画像概述&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;用户画像根本目的就是寻找目标客户、优化产品设计，指导运营策略，分析业务场景和完善业务形态。&lt;/li&gt;
  &lt;li&gt;不同的企业做用户画像有不同的战略目的，广告公司做用户画像是为精准广告服务，电商做用户画像是为用户购买更多商品，内容平台做用户画像是推荐用户更感兴趣的内容提升流量再变现，金融行业做用户画像是为了寻找到目标客户的同时做好风险的控制。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;画像维度&quot;&gt;画像维度&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;特征：
    &lt;ul&gt;
      &lt;li&gt;人口统计：性别、年龄、教育&lt;/li&gt;
      &lt;li&gt;社会属性：家庭、社交、职业&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;行为：
    &lt;ul&gt;
      &lt;li&gt;使用行为：手机使用、电脑类型、套餐使用、套餐余额&lt;/li&gt;
      &lt;li&gt;消费行为：购买力、购买频次、购买渠道、额度、信用等级&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;需求
    &lt;ul&gt;
      &lt;li&gt;偏好属性：兴趣爱好、品牌爱好、产品爱好、网购偏好、支付偏好、价格偏好&lt;/li&gt;
      &lt;li&gt;潜在需求：&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;画像之静态标签动态标签&quot;&gt;画像之静态标签、动态标签&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;静态画像：实时性弱、覆盖广、粒度粗&lt;/li&gt;
  &lt;li&gt;动态画像：
    &lt;ul&gt;
      &lt;li&gt;一般建立兴趣模型，更加实时并且动态&lt;/li&gt;
      &lt;li&gt;用户行为可疑结构为5W（What/Who/When/Where/Why)&lt;/li&gt;
      &lt;li&gt;时效性非常敏感&lt;/li&gt;
      &lt;li&gt;在空间上，不同应用领域侧重点不同，营销领域更侧重消费习惯，推荐领域更侧重喜好&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;画像之标签结构化程度&quot;&gt;画像之标签结构化程度&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;结构化标签体系，定向广告平台采用的结构化标签体系&lt;/li&gt;
  &lt;li&gt;半结构化标签体系，在用于效果广告时，标签设计的灵活性大大提高了。标签体系是不是规整，就不那么重要了，只要有效果就行。&lt;/li&gt;
  &lt;li&gt;非结构化标签体系，非结构化，就是各个标签就事论事，各自反应各自的用户兴趣，彼此之间并无层级关系，也很难组织成规整的树状结构。非结构化标签的典型例子，是搜索广告里用的关键词。还有Facebook用的用户兴趣词&lt;/li&gt;
  &lt;li&gt;例如
    &lt;ul&gt;
      &lt;li&gt;汽车行业的标签体系大体应该是：价格—&amp;gt;车型—&amp;gt;品牌&lt;/li&gt;
      &lt;li&gt;游戏行业：按照类别、游戏素材、游戏厂商等等。游戏的用户决策过程总体上令人难以捉摸，这是因为它有点儿电影、音乐一样的艺术性特质。而人们对艺术的喜爱，并不是理性的，也就难以总结规律。&lt;/li&gt;
      &lt;li&gt;电商行业的实际做法大家都看到了，基本上不依靠分类，完全以“单品+个性化推荐”的方法构建和使用标签体系。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;画像之应用&quot;&gt;画像之应用&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;精准营销：根据历史用户特征，分析产品的潜在用户和用户的潜在需求，针对特定群体，利用短信、邮件等方式进行营销。&lt;/li&gt;
  &lt;li&gt;用户统计：根据用户的属性、行为特征对用户进行分类后，统计不同特征下的用户数量、分布；分析不同用户画像群体的分布特征。&lt;/li&gt;
  &lt;li&gt;数据挖掘：以用户画像为基础构建推荐系统、搜索引擎、广告投放系统，提升服务精准度。&lt;/li&gt;
  &lt;li&gt;服务产品：对产品进行用户画像，对产品进行受众分析，更透彻地理解用户使用产品的心理动机和行为习惯，完善产品运营，提升服务质量。&lt;/li&gt;
  &lt;li&gt;行业报告&amp;amp;用户研究：通过用户画像分析可以了解行业动态，比如人群消费习惯、消费偏好分析、不同地域品类消费差异分析&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;画像之reachctr曲线&quot;&gt;画像之reach/CTR曲线&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;reach：该标签占总用户比例&lt;/li&gt;
  &lt;li&gt;CTR：点击率&lt;/li&gt;
  &lt;li&gt;reach越大，一般情况CTR会小&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;用户画像架构图&quot;&gt;用户画像架构图&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/img/user_profile.jpg&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;会员理论模型&quot;&gt;会员理论模型&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;会员体系模型：AIPL
    &lt;ul&gt;
      &lt;li&gt;Awareness潜客：内容运营、宣传吸引、新手任务、了解产品&lt;/li&gt;
      &lt;li&gt;Interest粉丝：社会新闻、热点话题、习惯养成、积分积累&lt;/li&gt;
      &lt;li&gt;Purchase会员：日常任务、促销活动、品牌影响力、共同利益&lt;/li&gt;
      &lt;li&gt;Loyalty超级会员：专属特权、心理诉求、社群活动、1V1维护&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;会员体系模型：RFM
    &lt;ul&gt;
      &lt;li&gt;R(Recency)近度：距某节点最近的一次消费&lt;/li&gt;
      &lt;li&gt;F(Frequency)频度：消费频次&lt;/li&gt;
      &lt;li&gt;M (Monetary)额度：消费金额&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;会员体系模型：AARRR
    &lt;ul&gt;
      &lt;li&gt;Acquisition（获取用户）：关注PV、UV、CPC、点击转化率、注册量、注册率、获客成本CAC&lt;/li&gt;
      &lt;li&gt;Activation（提高活跃度）：关注登陆量、激活转化率、活跃度指标&lt;/li&gt;
      &lt;li&gt;Retention（提高留存率）：关注留存率、复购率、人均购买次数、召回率&lt;/li&gt;
      &lt;li&gt;Revenue（获取收入）：关注获客成本、顾客终身价值、营销ROI&lt;/li&gt;
      &lt;li&gt;Referral（传播）：关注邀请量、激活量、邀请激活率、传播系数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;鱼塘理论
    &lt;ul&gt;
      &lt;li&gt;养鱼、抓潜、成交、追销、形成自己的鱼塘&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hook模型概念
    &lt;ul&gt;
      &lt;li&gt;触发Trigger：即诱发用户采取行动，进入系统的契机。这是上瘾模型的第一步，也是最关键一步，如果这步不能引起用户的兴趣，后续就无从谈起。&lt;/li&gt;
      &lt;li&gt;行动Action：按照斯坦福大学B.J.Fogg博士的Behavior Model理论，B=MAT，即行动（Behavior）=动机（Motivation）+能力（Ability）+触发器（Trigger）。&lt;/li&gt;
      &lt;li&gt;多变的酬赏Variable Reward：当行为被触发之后，接下来就需要给用户一些酬赏进行持续刺激，以培养对他们对产品的使用习惯。酬赏简单来说就是产品带给用户的满足感，但为什么要强调“多变”呢？
  据行为学研究，人们对产品的满足感会随着时间的推移逐渐降低，即使现阶段用户因为产品解决了某方面问题而产生依赖，但市面上的新产品层出不穷，要想不被淘汰，“无穷的多变性”是保持产品神秘感和吸引力，维持用户长期兴趣的关键。&lt;/li&gt;
      &lt;li&gt;投入Investment：有研究表明，用户对某个产品投入时间精力的多寡与对这个产品的依赖程度成正比，就像免费东西你不会珍惜，而氪过金的游戏或服务反而会不断充值一样。已经享受酬赏的用户，想要他们对你的产品彻底“上瘾”，最后一步就是要让他们有所投入。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;《疯传》STEPPS原则
    &lt;ul&gt;
      &lt;li&gt;社交货币（Social Currency）：我们会共享那些能让我们显得更优秀的事情&lt;/li&gt;
      &lt;li&gt;诱因（Triggers）：顶尖的记忆，风口浪尖的提醒&lt;/li&gt;
      &lt;li&gt;情绪（Emotion）：当我们关心时，我们回去分享&lt;/li&gt;
      &lt;li&gt;公共性（Public）：构建可视的、正面的事物&lt;/li&gt;
      &lt;li&gt;实用价值（Practical Value）：如果有用，人们会情不自禁地分享&lt;/li&gt;
      &lt;li&gt;故事（Stories）：好故事就意味着成功了一般，好故事都有翅膀&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;用户研究：如何做用户画像分析 &lt;a href=&quot;https://www.jianshu.com/p/440c30383bec&quot;&gt;https://www.jianshu.com/p/440c30383bec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;什么是用户画像和标签？ &lt;a href=&quot;http://www.woshipm.com/user-research/1083807.html&quot;&gt;http://www.woshipm.com/user-research/1083807.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;结构化标签、非结构化标签及reach/CTR曲线 &lt;a href=&quot;http://www.woshipm.com/user-research/436269.html&quot;&gt;http://www.woshipm.com/user-research/436269.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;电商案例、金融案例（用户画像标签体系——从零开始搭建实时用户画像） &lt;a href=&quot;https://cloud.tencent.com/developer/column/79937&quot;&gt;https://cloud.tencent.com/developer/column/79937&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;航空公司案例、证券案例、打车公司案例 &lt;a href=&quot;https://www.zhihu.com/question/302695500&quot;&gt;https://www.zhihu.com/question/302695500&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;从阿里会员解读会员体系建设 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/88738148&quot;&gt;https://zhuanlan.zhihu.com/p/88738148&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;用户画像10大误区 &lt;a href=&quot;https://mp.weixin.qq.com/s/Nzxa7stwvLhDvfSzqkCeAA&quot;&gt;https://mp.weixin.qq.com/s/Nzxa7stwvLhDvfSzqkCeAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;1号店案例 &lt;a href=&quot;https://mp.weixin.qq.com/s/gtwdjTS9x_0xGKWEgo1zxg&quot;&gt;https://mp.weixin.qq.com/s/gtwdjTS9x_0xGKWEgo1zxg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Qunar用户画像构建策略及应用实践 &lt;a href=&quot;https://blog.csdn.net/xiaoshunzi111/article/details/53170658&quot;&gt;https://blog.csdn.net/xiaoshunzi111/article/details/53170658&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;携程&lt;/td&gt;
          &lt;td&gt;手把手教你用大数据打造用户画像 &lt;a href=&quot;https://blog.csdn.net/chenjunji123456/article/details/54966633&quot;&gt;https://blog.csdn.net/chenjunji123456/article/details/54966633&lt;/a&gt;&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 22 Jun 2020 10:08:00 +0800</pubDate>
        <link>http://localhost:4000/%E4%BA%A7%E5%93%81%E5%95%86%E4%B8%9A/2020/06/22/UserProfile.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E4%BA%A7%E5%93%81%E5%95%86%E4%B8%9A/2020/06/22/UserProfile.html</guid>
        
        <category>用户</category>
        
        
        <category>产品商业</category>
        
      </item>
    
      <item>
        <title>DotDot2</title>
        <description>&lt;h4 id=&quot;基础&quot;&gt;基础&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线
程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入(CAS)的开销，看起
来让这个线程得到了偏护。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级
锁执行路径，因为轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换
ThreadID 的时候依赖一次 CAS 原子指令(由于一旦出现多线程竞争的情况就必须撤销偏向锁，所
以偏向锁的撤销操作的性能损耗必须小于节省下来的 CAS 原子指令的性能消耗)。上面说过，轻
量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进
一步提高性能。&lt;/li&gt;
  &lt;li&gt;很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要
在子线程结束后再结束，这时候就要用到 join() 方法。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;spring&quot;&gt;Spring&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;ApplicationContext
    &lt;ol&gt;
      &lt;li&gt;BeanFactory 是 Spring 框架的基础设施，面向 Spring 本身;ApplicationContext 面向使用 Spring 框架的开发者，几乎所有的应用场合我们都直接使用 ApplicationContext 而非底层 的 BeanFactory。&lt;/li&gt;
      &lt;li&gt;HierarchicalBeanFactory 父子级联，父子级联 IoC 容器的接口，子容器可以通过接口方法访问父容器; 通过 HierarchicalBeanFactory 接口， Spring 的 IoC 容器可以建立父子层级关联的容器体系，子 容器可以访问父容器中的 Bean，但父容器不能访问子容器的 Bean。Spring 使用父子容器实 现了很多功能，比如在 Spring MVC 中，展现层 Bean 位于一个子容器中，而业务层和持久 层的 Bean 位于父容器中。这样，展现层 Bean 就可以引用业务层和持久层的 Bean，而业务 层和持久层的 Bean 则看不到展现层的 Bean。&lt;/li&gt;
      &lt;li&gt;ClassPathXmlApplicationContext -&amp;gt; ApplicationContext -&amp;gt; HierarchicalBeanFactory/ListableBeanFactory&lt;/li&gt;
      &lt;li&gt;ConfigurableApplicationContext 扩展于 ApplicationContext，它新增加了两个主要 的方法: refresh()和 close()，让 ApplicationContext 具有启动、刷新和关闭应用上下 文的能力。在应用上下文关闭的情况下调用 refresh()即可启动应用上下文，在已经启动 的状态下，调用 refresh()则清除缓存并重新装载配置信息，而调用 close()则可关闭应用 上下文。&lt;/li&gt;
      &lt;li&gt;WebApplicationContext 是专门为 Web 应用准备的，它允许从相对于 Web 根目录的 路径中装载配置文件完成初始化工作。从 WebApplicationContext 中可以获得 ServletContext 的引用，整个 Web 应用上下文对象将作为属性放置到 ServletContext 中，以便 Web 应用环境可以访问 Spring 应用上下文。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Bean的Scope
    &lt;ol&gt;
      &lt;li&gt;singleton&lt;/li&gt;
      &lt;li&gt;prototype，每次都创建（对有状态的 bean 使用 prototype 作用域，而对无状态的 bean 使用 singleton 作用域。）&lt;/li&gt;
      &lt;li&gt;request：一次request一个实例&lt;/li&gt;
      &lt;li&gt;session：一个session一个实例&lt;/li&gt;
      &lt;li&gt;global Session:在一个全局的 Http Session 中，容器会返回该 Bean 的同一个实例，仅在 使用 portlet context 时有效。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Bean的生命周期
    &lt;ol&gt;
      &lt;li&gt;根据scope，实例化&lt;/li&gt;
      &lt;li&gt;设置熟悉&lt;/li&gt;
      &lt;li&gt;postProcessBeforeInitialization&lt;/li&gt;
      &lt;li&gt;afterPropertiesSet&lt;/li&gt;
      &lt;li&gt;postProcessAfterInitialization&lt;/li&gt;
      &lt;li&gt;Done
```xml&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;bean class=&quot;&quot; init-method=&quot;初始化方法&quot; destroy-method=&quot;销毁方法&quot; /&gt;

&lt;p&gt;```&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;依赖注入
    &lt;ul&gt;
      &lt;li&gt;构造器注入&lt;/li&gt;
      &lt;li&gt;setter 方法注入&lt;/li&gt;
      &lt;li&gt;接口注入&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;IOC:把对象的创建、初始化、销毁交给 spring 来管理，而不是由开发者控制，实现控制反转。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;5 种不同方式的自动装配
    &lt;ul&gt;
      &lt;li&gt;no:默认的方式是不进行自动装配，通过显式设置 ref 属性来进行装配。&lt;/li&gt;
      &lt;li&gt;byName:通过参数名 自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byname，之后容器试图匹配、装配和该 bean 的属性具有相同名字的 bean。&lt;/li&gt;
      &lt;li&gt;byType:通过参数类型自动装配，Spring 容器在配置文件中发现 bean 的 autowire 属性被 设置成 byType，之后容器试图匹配、装配和该 bean 的属性具有相同类型的 bean。如果有多个 bean 符合条件，则抛出错误。&lt;/li&gt;
      &lt;li&gt;constructor:这个方式类似于 byType， 但是要提供给构造器参数，如果没有确定的带参数的构造器参数类型，将会抛出异常。&lt;/li&gt;
      &lt;li&gt;autodetect:首先尝试使用 constructor 来自动装配，如果无法工作，则使用 byType 方式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AOP 核心概念
    &lt;ul&gt;
      &lt;li&gt;切面(aspect):类是对物体特征的抽象，切面就是对横切关注点的抽象&lt;/li&gt;
      &lt;li&gt;横切关注点:对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点。&lt;/li&gt;
      &lt;li&gt;连接点(joinpoint):被拦截到的点，因为 Spring 只支持方法类型的连接点，所以在 Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器。&lt;/li&gt;
      &lt;li&gt;切入点(pointcut):对连接点进行拦截的定义&lt;/li&gt;
      &lt;li&gt;通知(advice):所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、 异常、最终、环绕通知五类。&lt;/li&gt;
      &lt;li&gt;目标对象:代理的目标对象&lt;/li&gt;
      &lt;li&gt;织入(weave):将切面应用到目标对象并导致代理对象创建的过程&lt;/li&gt;
      &lt;li&gt;引入(introduction):在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法 或字段。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MyBatis缓存
    &lt;ul&gt;
      &lt;li&gt;Mybatis 中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存 是指 SqlSession 级别的缓存，当在同一个 SqlSession 中进行相同的 SQL 语句查询时，第二次以 后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存 1024 条 SQL。二级缓存 是指可以跨 SqlSession 的缓存。是 mapper 级别的缓存，对于 mapper 级别的缓存不同的 sqlsession 是可以共享的。&lt;/li&gt;
      &lt;li&gt;如果两次中间出现 commit 操作 (修改、添加、删除)，本 sqlsession 中的一级缓存区域全部清空，下次再去缓存中查询不到所 以要从数据库查询，从数据库查询到再写入缓存。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Slf4j
slf4j 的全称是 Simple Loging Facade For Java，即它仅仅是一个为 Java 程序提供日志输出的统一接 口，并不是一个具体的日志实现方案，就比如 JDBC 一样，只是一种规则而已。所以单独的 slf4j 是不 能工作的，必须搭配其他具体的日志实现方案，比如 apache 的 org.apache.log4j.Logger，jdk 自带 的 java.util.logging.Logger 等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;redis分布式锁与zk分布式锁&quot;&gt;redis分布式锁与zk分布式锁&lt;/h4&gt;

&lt;h4 id=&quot;zab协议4阶段&quot;&gt;ZAB协议4阶段&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Leader election(选举阶段):节点在一开始都处于选举阶段，只要有一个节点得到超半数 节点的票数，它就可以当选准 leader。只有到达 广播阶段(broadcast) 准 leader 才会成 为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。&lt;/li&gt;
  &lt;li&gt;Discovery(发现阶段-接受提议、生成 epoch、接受 epoch):在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且 准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch
 一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f 在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。&lt;/li&gt;
  &lt;li&gt;Synchronization(同步阶段):同步阶段主要是利用 leader 前一阶段获得的最新提议历史， 同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。 follower 只会接收 zxid 比自己的 lastZxid 大的提议。&lt;/li&gt;
  &lt;li&gt;Broadcast(广播阶段-leader 消息广播) Broadcast(广播阶段):到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，
    &lt;ul&gt;
      &lt;li&gt;两大阶段：让大家投票，告诉大家投票结果&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;rabbitmq-4种分发策略&quot;&gt;RabbitMq 4种分发策略&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Direct : 单Queue&lt;/li&gt;
  &lt;li&gt;Fanout : 类似redis pub/sub&lt;/li&gt;
  &lt;li&gt;Topic : 模糊匹配&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hadoop-region寻址方式通过zookeepermeta&quot;&gt;Hadoop Region寻址方式(通过zookeeper.META)&lt;/h4&gt;
&lt;p&gt;第 1 步:Client 请求 ZK 获取.META.所在的 RegionServer 的地址。
第 2 步:Client 请求.META.所在的 RegionServer 获取访问数据所在的 RegionServer 地 址，client 会将.META.的相关信息 cache 下来，以便下一次快速访问。
第 3 步:Client 请求数据所在的 RegionServer，获取所需要的数据。&lt;/p&gt;

&lt;h4 id=&quot;hbase的写入流程&quot;&gt;HBase的写入流程&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;获取 RegionServer
第 1 步:Client 获取数据写入的 Region 所在的 RegionServer
请求写 Hlog&lt;/li&gt;
  &lt;li&gt;第 2 步:请求写 Hlog, Hlog 存储在 HDFS，当 RegionServer 出现异常，需要使用 Hlog 来
恢复数据。
请求写 MemStore&lt;/li&gt;
  &lt;li&gt;第 3 步:请求写 MemStore,只有当写 Hlog 和写 MemStore 都成功了才算请求写入完成。
MemStore 后续会逐渐刷到 HDFS 中。 14.1.5.2. MemStore刷盘
为了提高 Hbase 的写入性能，当写请求写入 MemStore 后，不会立即刷盘。而是会等到一 定的时候进行刷盘的操作。具体是哪些场景会触发刷盘的操作呢?总结成如下的几个场景:&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hbase全局内存控制&quot;&gt;HBase全局内存控制&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;这个全局的参数是控制内存整体的使用情况，当所有 memstore 占整个 heap 的最大比 例的时候，会触发刷盘的操作。这个参数是 hbase.regionserver.global.memstore.upperLimit，默认为整个 heap 内存的 40%。 但这并不意味着全局内存触发的刷盘操作会将所有的 MemStore 都进行输盘，而是通过 另外一个参数 hbase.regionserver.global.memstore.lowerLimit 来控制，默认是整个 heap 内存的 35%。当 flush 到所有 memstore 占整个 heap 内存的比率为 35%的时 候，就停止刷盘。这么做主要是为了减少刷盘对业务带来的影响，实现平滑系统负载的 目的。
MemStore 达到上限&lt;/li&gt;
  &lt;li&gt;当 MemStore 的大小达到 hbase.hregion.memstore.flush.size 大小的时候会触发刷
盘，默认 128M 大小
RegionServer 的 Hlog 数量达到上限&lt;/li&gt;
  &lt;li&gt;前面说到 Hlog 为了保证 Hbase 数据的一致性，那么如果 Hlog 太多的话，会导致故障 恢复的时间太长，因此 Hbase 会对 Hlog 的最大个数做限制。当达到 Hlog 的最大个数 的时候，会强制刷盘。这个参数是 hase.regionserver.max.logs，默认是 32 个。
手工触发&lt;/li&gt;
  &lt;li&gt;可以通过 hbase shell 或者 java api 手工触发 flush 的操作。
关闭 RegionServer 触发&lt;/li&gt;
  &lt;li&gt;在正常关闭 RegionServer 会触发刷盘的操作，全部数据刷盘后就不需要再使用 Hlog 恢
复数据。
Region 使用 HLOG 恢复完数据后触发&lt;/li&gt;
  &lt;li&gt;:当 RegionServer 出现故障的时候，其上面的 Region 会迁移到其他正常的 RegionServer 上，在恢复完 Region 的数据后，会触发刷盘，当刷盘完成后才会提供给 业务访问。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;mongodb的mapreduce&quot;&gt;MongoDB的Map/Reduce&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Mongodb 中的 Map/reduce 主要是用来对数据进行批量处理和聚合操作。&lt;/li&gt;
  &lt;li&gt;Map 和 Reduce。Map 函数调用 emit(key,value)遍历集合中所有的记录，将 key 与 value 传 给 Reduce 函数进行处理。&lt;/li&gt;
  &lt;li&gt;Map 函数和 Reduce 函数是使用 Javascript 编写的，并可以通过 db.runCommand 或 mapre duce 命令来执行 MapReduce 操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;raft-协议和-zab-协议区别&quot;&gt;raft 协议和 zab 协议区别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;相同点
    &lt;ul&gt;
      &lt;li&gt;采用quorum来确定整个系统的一致性,这个quorum一般实现是集群中半数以上的服务器,  zookeeper里还提供了带权重的quorum实现.&lt;/li&gt;
      &lt;li&gt;都由leader来发起写操作.&lt;/li&gt;
      &lt;li&gt;都采用心跳检测存活性&lt;/li&gt;
      &lt;li&gt;leader election都采用先到先得的投票方式&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;不同点
    &lt;ul&gt;
      &lt;li&gt;zab用的是epoch和count的组合来唯一表示一个值,而raft用的是term和index&lt;/li&gt;
      &lt;li&gt;zab的follower在投票给一个leader之前必须和leader的日志达成一致,而raft的follower则简单地说是谁的 term 高就投票给谁&lt;/li&gt;
      &lt;li&gt;raft协议的心跳是从leader到follower,而zab协议则相反&lt;/li&gt;
      &lt;li&gt;raft协议数据只有单向地从leader到follower(成为leader的条件之一就是拥有最新的log),
  而 zab 协议在 discovery 阶段, 一个 prospective leader 需要将自己的 log 更新为 quorum 里面 最新的 log,然后才好在 synchronization 阶段将 quorum 里的其他机器的 log 都同步到一致.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cyclicbarriercountdownlatchsemaphore-的用法&quot;&gt;CyclicBarrier、CountDownLatch、Semaphore 的用法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CountDownLatch，等多搞一&lt;/li&gt;
  &lt;li&gt;CyclicBarrier，等多搞多&lt;/li&gt;
  &lt;li&gt;Semaphore，8个工人5台机器&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;throwable-是-java-语言中所有错误或异常的超类下一层分为-error-和-exception&quot;&gt;Throwable 是 Java 语言中所有错误或异常的超类。下一层分为 Error 和 Exception&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Error 类是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。&lt;/li&gt;
  &lt;li&gt;Exception 又有两个分支，一个是运行时异常 RuntimeException，一个是CheckedException。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;序列化-id&quot;&gt;序列化 ID&lt;/h4&gt;
&lt;p&gt;Java 平台允许我们在内存中创建可复用的 Java 对象，但一般情况下，只有当 JVM 处于运行时，
这些对象才可能存在，即，这些对象的生命周期不会比 JVM 的生命周期更长。但在现实应用中，
就可能要求在 JVM 停止运行之后能够保存(持久化)指定的对象，并在将来重新读取被保存的对象。
Java 对象序列化就能够帮助我们实现该功能。
 使用 Java 对象序列化，在保存对象时，会把其状态保存为一组字节，在未来，再将这些字节组装
 成对象。必须注意地是，对象序列化保存的是对象的”状态”，即它的成员变量。由此可知，对
 象序列化不会关注类中的静态变量。
 除了在持久化对象时会用到对象序列化之外，当使用 RMI(远程方法调用)，或在网络中传递对象时，
 都会用到对象序列化。Java 序列化 API 为处理对象序列化提供了一个标准机制，该 API 简单易用。
 虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个
 类的序列化 ID 是否一致(就是 private static final long serialVersionUID)&lt;/p&gt;

&lt;h4 id=&quot;springboot-starter&quot;&gt;SpringBoot Starter&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;其实是Java的SPI的全名为Service Provider Interfac的一种实现&lt;/li&gt;
  &lt;li&gt;EnableAutoConfiguration 导入 @Import({AutoConfigurationImportSelector.class})&lt;/li&gt;
  &lt;li&gt;AutoConfigurationImportSelector 从classpath中搜寻所有的META-INF/spring.factories配置文件&lt;/li&gt;
  &lt;li&gt;找到org.springframework.boot.autoconfigure.EnableAutoConfiguration该key对应的其他自动配置className&lt;/li&gt;
  &lt;li&gt;通过反射按照相关Conditional进行实例化&lt;/li&gt;
  &lt;li&gt;如关闭数据源自动配置功能: @SpringBootApplication(exclude ={ DataSourceAutoConfiguration.class })。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;如何在-spring-boot-启动的时候运行一些特定的代码&quot;&gt;如何在 Spring Boot 启动的时候运行一些特定的代码?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;可以实现接口 ApplicationRunner 或者 CommandLineRunner，这两个接口实现方式一 样，它们都只提供了一个 run 方法。&lt;/li&gt;
  &lt;li&gt;Spring Boot 可以通过 @PropertySource,@Value,@Environment&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;es-bulk-一次最大处理多少数据量&quot;&gt;Es Bulk 一次最大处理多少数据量???&lt;/h4&gt;
&lt;p&gt;bulk 会把将要处理的数据载入内存中，所以数据量是有限制的 最佳的数据量不是一个确定的数值，它取决于你的硬件，你的文档大小以及复杂性，你的索
引以及搜索的负载。
一般建议是 1000-5000 个文档，如果你的文档很大，可以适当减少队列,大小建议是 5-15MB，
默认不能超过 100M，可以在 es 的配置文件中修改这个值 http.max_content_length: 100mb&lt;/p&gt;

&lt;h4 id=&quot;es-在高并发的情况下如何保证数据线程安全问题&quot;&gt;ES 在高并发的情况下如何保证数据线程安全问题?&lt;/h4&gt;
&lt;p&gt;在读数据与写数据之间如果有其他线程进行写操作，就会出问题，es 使用版本控制才避免 这种问题
在修改数据的时候指定版本号，操作一次版本号加 1&lt;/p&gt;

&lt;h4 id=&quot;es-管理的工具有哪些&quot;&gt;ES 管理的工具有哪些?&lt;/h4&gt;
&lt;p&gt;BigDesk Plugin、Elasticsearch Head Plugin 、Kibana&lt;/p&gt;

&lt;h4 id=&quot;dubbo-服务上线怎么兼容旧版本&quot;&gt;Dubbo 服务上线怎么兼容旧版本?&lt;/h4&gt;
&lt;p&gt;可以用版本号(version)过渡，多个不同版本的服务注册到注册中心，版本号不同的服务 相互间不引用。这个和服务分组的概念有一点类似。&lt;/p&gt;

&lt;h4 id=&quot;dubbo-可以使用-pinpoint-和-apache-skywalkingincubator-实现分布式服务追踪-当然还有其他很多方案&quot;&gt;Dubbo 可以使用 Pinpoint 和 Apache Skywalking(Incubator) 实现分布式服务追踪， 当然还有其他很多方案。&lt;/h4&gt;

&lt;h4 id=&quot;kafka-数据传输的事物定义有哪三种&quot;&gt;Kafka 数据传输的事物定义有哪三种?&lt;/h4&gt;
&lt;p&gt;数据传输的事务定义通常有以下三种级别:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输&lt;/li&gt;
  &lt;li&gt;最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.&lt;/li&gt;
  &lt;li&gt;精确的一次(Exactly once): 不会漏传输也不会重复传输,每个消息都传输被一次而且 仅仅被传输一次，这是大家所期望的&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;kafka-收到消息的-ack-机制&quot;&gt;kafka 收到消息的 ack 机制&lt;/h4&gt;
&lt;p&gt;request.required.acks 有三个值 0 1 -1
0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就 会丢数据
1:服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他不 确保是否复制完成新 leader 也会导致数据丢失
-1:同样在 1 的基础上 服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出 的 ack，这样数据不会丢失&lt;/p&gt;

&lt;h4 id=&quot;kafka-more&quot;&gt;Kafka More&lt;/h4&gt;
&lt;p&gt;15.消费者负载均衡策略 ，一个消费者组中的一个分片对应一个消费者成员，他能保证每个消费者成员都能访问，如果 组中成员太多会有空闲的成员
16.数据有序 ，一个消费者组里它的内部是有序的 消费者组与消费者组之间是无序的
17.kafaka ，生产数据时数据的分组策略 生产者决定数据产生到集群的哪个 partition 中 每一条消息都是以(key，value)格式Key 是由生产者发送数据传入&lt;/p&gt;

&lt;h4 id=&quot;线程间共享&quot;&gt;线程间共享&lt;/h4&gt;
&lt;p&gt;线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤: 1. 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;iterater-和-listiterator-之间有什么区别&quot;&gt;Iterater 和 ListIterator 之间有什么区别?&lt;/h4&gt;
&lt;p&gt;(1)我们可以使用 Iterator 来遍历 Set 和 List 集合，而 ListIterator 只能遍历 List。 (2)Iterator 只可以向前遍历，而 LIstIterator 可以双向遍历。
(3)ListIterator 从 Iterator 接口继承，然后添加了一些额外的功能，比如添加一个元素、替 换一个元素、获取前面或后面元素的索引位置。&lt;/p&gt;

&lt;h4 id=&quot;什么是-java-内存模型&quot;&gt;什么是 Java 内存模型&lt;/h4&gt;
&lt;p&gt;Java 内存模型定义了一种多线程访问 Java 内存的规范。Java 内存模型要完 整讲不是这里几句话能说清楚的，我简单总结一下 Java 内存模型的几部分内 容:
 1)Java 内存模型将内存分为了主内存和工作内存。类的状态，也就是类之间 共享的变量，是存储在主内存中的，每次 Java 线程用到这些主内存中的变量 的时候，会读一次主内存中的变量，并让这些内存在自己的工作内存中有一份
 拷贝，运行自己线程代码的时候，用到这些变量，操作的都是自己工作内存中 的那一份。在线程代码执行完毕之后，会将最新的值更新到主内存中去 2)定义了几个原子操作，用于操作主内存和工作内存中的变量
 3)定义了 volatile 变量的使用规则 4)happens-before，即先行发生原则，定义了操作 A 必然先行发生于操作 B 的一些规则，比如在同一个线程内控制流前面的代码一定先行发生于控制流 后面的代码、一个释放锁 unlock 的动作一定先行发生于后面对于同一个锁进 行锁定 lock 的动作等等，只要符合这些规则，则不需要额外做同步措施，如 果某段代码不符合所有的 happens-before 规则，则这段代码一定是线程非 安全的&lt;/p&gt;

&lt;h4 id=&quot;mybatis-和的区别是什么&quot;&gt;myBatis #{}和${}的区别是什么?&lt;/h4&gt;
&lt;p&gt;1)#{}是预编译处理，${}是字符串替换。
2)Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值;
3)Mybatis 在处理${}时，就是把${}替换成变量的值。 4)使用#{}可以有效的防止 SQL 注入，提高系统安全性。&lt;/p&gt;

&lt;h4 id=&quot;35ibatis-和-mybatis-区别&quot;&gt;35、IBatis 和 MyBatis 区别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;IBatis 里面的核心处理类交 SqlMapClient,MyBatis 里面的核心处理类叫做 SqlSession。&lt;/li&gt;
  &lt;li&gt;在 sql 里面变量命名有原来的#变量# 变成了#{变量}&lt;/li&gt;
  &lt;li&gt;原来的$变量$变成了${变量}&lt;/li&gt;
  &lt;li&gt;原来在 sql 节点里面的 class 都换名字交 type&lt;/li&gt;
  &lt;li&gt;原来的 queryForObject queryForList 变成了 selectOne selectList5)原来的别名设置在映射 文件里面放在了核心配置文件里。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;apache-shiro&quot;&gt;Apache Shiro&lt;/h4&gt;
&lt;p&gt;Apache Shiro 是 Java 的一个安全框架。使用 shiro 可以非常容易的开发出足够好的应用，其不仅可以用在 JavaSE 环境，也可以用在 JavaEE 环境。Shiro 可以帮助我们完成:认证、授权、加密、会话管理、与 Web 集成、缓存等。
三个核心组件:Subject, SecurityManager 和 Realms.
Subject:即“当前操作用户”。但是，在 Shiro 中，Subject 这一概念并不仅仅指人，也可以是第三方进程、后台帐 户(Daemon Account)或其他类似事物。它仅仅意味着“当前跟软件交互的东西”。但考虑到大多数目的和用途， 你可以把它认为是 Shiro 的“用户”概念。
Subject 代表了当前用户的安全操作，SecurityManager 则管理所有用户的安全操作。
SecurityManager:它是 Shiro 框架的核心，典型的 Facade 模式，Shiro 通过 SecurityManager 来管理内部组 件实例，并通过它来提供安全管理的各种服务。
Realm: Realm 充当了 Shiro 与应用安全数据间的“桥梁”或者“连接器”。也就是说，当对用户执行认证(登 录)和授权(访问控制)验证时，Shiro 会从应用配置的 Realm 中查找用户及其权限信息。&lt;/p&gt;

&lt;h4 id=&quot;使用-redis-如何设计分布式锁说一下实现思路使用-zk-可以吗如何实现这两种有什-么区别&quot;&gt;使用 redis 如何设计分布式锁?说一下实现思路?使用 zk 可以吗?如何实现?这两种有什 么区别?&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;redis:
    &lt;ol&gt;
      &lt;li&gt;线程 A setnx(上锁的对象,超时时的时间戳 t1)，如果返回 true，获得锁。&lt;/li&gt;
      &lt;li&gt;线程 B 用 get 获取 t1,与当前时间戳比较,判断是是否超时,没超时 false,若超时执行第 3 步; 3.计算新的超时时间 t2,使用 getset 命令返回 t3(该值可能其他线程已经修改过),如果 t1==t3，获得锁，如果 t1!=t3 说明锁被其他线程获取了。 4.获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时， 不用处理(防止删除其他线程的锁)。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;zk:
    &lt;ol&gt;
      &lt;li&gt;客户端对某个方法加锁时，在 zk 上的与该方法对应的指定节点的目录下，生成一个唯一 的瞬时有序节点 node1; 2.客户端获取该路径下所有已经创建的子节点，如果发现自己创建的 node1 的序号是最小 的，就认为这个客户端获得了锁。&lt;/li&gt;
      &lt;li&gt;如果发现 node1 不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待。&lt;/li&gt;
      &lt;li&gt;获取锁后，处理完逻辑，删除自己创建的 node1 即可。 区别:zk 性能差一些，开销大，实现简单。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 17 Jun 2020 20:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/17/DotDot2.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/17/DotDot2.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>DotDot</title>
        <description>&lt;h3 id=&quot;存储精华&quot;&gt;存储精华&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;说到存储，其实效率才是最主要的，容量不是我们关心的，但是说到存储，不只是mq，所有需要高效率的存储其实最后利用的核心都是一样的。
    &lt;ol&gt;
      &lt;li&gt;随机写转换成顺序写：现在主流的硬盘是机械硬盘，
 机械硬盘的机械结构一次读写时间 = 寻道时间 + 旋转延迟 + 读取数据时间，
 那么寻道时间比较长，如果是顺序写，只需要一次寻道时间，关于机械硬盘整个过程，读者可自行google。&lt;/li&gt;
      &lt;li&gt;集中刷盘：
 因为每次刷盘都会进行系统调用，第二还是跟硬盘的本身属性有关，无论是机械硬盘还是ssd按照一定块刷盘会比小数据刷盘效率更好&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;对于存储系统而言，原本存储在一台机器上的数据，现在要存放在多台机器上。此时必须解决两个问题：分片，复制。
    &lt;ul&gt;
      &lt;li&gt;数据分片(sharding)，又称分区(partition)，将数据集“合理的”拆分成多个分片，每台机器负责其中若干个分片。以此来突破单机容量的限制，同时也提升了整体的访问能力。另外，分片也降低了单个分片故障的影响范围。&lt;/li&gt;
      &lt;li&gt;数据复制(replica)，也叫“副本”。分片无法解决单机故障丢数据的问题，所以，必然要通过冗余来解决系统高可用的问题。同时，副本机制也是提升系统吞吐、解决热点问题的重要手段。&lt;/li&gt;
      &lt;li&gt;分片和副本是正交的，这意味着我们可以只使用其中一种或都使用，但通常都是同时使用的。因为分片解决的是规模和扩展性的问题，副本解决可靠、可用性的问题。对于一个生产可用的系统，二者必须同时具备。&lt;/li&gt;
      &lt;li&gt;从使用者/客户端的角度看，分片和副本可以归结为同一个问题：请求路由，即请求应该发送给哪台机器来处理。&lt;/li&gt;
      &lt;li&gt;读数据时，能通过某种机制来确保有一个合适的分片/副本来提供服务&lt;/li&gt;
      &lt;li&gt;写数据时，能通过同样的机制来确保写到一个合适的地方，并确保副本的一致性&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;innodb引擎的4大特性&quot;&gt;InnoDB引擎的4大特性&lt;/h4&gt;
&lt;p&gt;https://www.cnblogs.com/zhs0/p/10528520.html&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;插入缓冲（insert buffer)，只对于非聚集索引（非唯一）的插入和更新有效，对于每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是为了减少随机IO带来性能损耗。&lt;/li&gt;
  &lt;li&gt;二次写(double write)
    &lt;ul&gt;
      &lt;li&gt;InnoDB默认DB page为 16KB，而文件系统、磁盘、扇区对应的page小于该数字，因此，一次DB page可能被多次写入才能真正写入成功&lt;/li&gt;
      &lt;li&gt;在写数据时，会在共享表空间写一份数据，之后再同步到磁盘&lt;/li&gt;
      &lt;li&gt;在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/chenpingzhao/p/4876282.html&quot;&gt;https://www.cnblogs.com/chenpingzhao/p/4876282.html&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;自适应哈希索引(ahi)，innodb会监控表上多个索引页的查询。如果观察到建立哈希索引可以带来速度提升，则自动建立哈希索引，称之为自适应哈希索引（Adaptive Hash Index，AHI）。
  主要是精确等值查找，对范围查找搜索不生效&lt;/li&gt;
  &lt;li&gt;预读(read ahead)，数据预加载&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;共享表空间-独立表空间&quot;&gt;共享表空间 、独立表空间&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;共享表空间： Innodb的所有数据保存在一个单独的表空间里面，而这个表空间可以由很多个文件组成，一个表可以跨多个文件存在，所以其大小限制不再是文件大小的限制，而是其自身的限制。从Innodb的官方文档中可以看到，其表空间的最大限制为64TB，也就是说，Innodb的单表限制基本上也在64TB左右了，当然这个大小是包括这个表的所有索引等其他相关数据。&lt;/li&gt;
  &lt;li&gt;独占表空间:  每一个表都将会生成以独立的文件方式来进行存储，每一个表都有一个.frm表描述文件，还有一个.ibd文件。 其中这个文件包括了单独一个表的数据内容以及索引内容，默认情况下它的存储位置也是在表的位置之中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;聚集索引-与-非聚集索引&quot;&gt;聚集索引 与 非聚集索引&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/riemann_/article/details/90324846&quot;&gt;https://blog.csdn.net/riemann_/article/details/90324846&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tcp&quot;&gt;TCP&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;TCP三要素：ip+端口、序列号（解决乱序）、窗口大小（流量控制）&lt;/li&gt;
  &lt;li&gt;TCP与UDP
    &lt;ul&gt;
      &lt;li&gt;TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节（5个32位），如果使用了「选项」字段则会变长的。
    UDP 首部只有 8 个字节，并且是固定不变的，开销较小。&lt;/li&gt;
      &lt;li&gt;为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？
  原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。&lt;/li&gt;
      &lt;li&gt;为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？
  TCP数据的长度 = IP总长度-IP首位长度-TCP首部长度。实际上，UDP的长度也可以用这个方式计算，因此UDP包长度有点多余&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP建立连接
    &lt;ul&gt;
      &lt;li&gt;3次握手+4种状态：LISTEN、SYS_SEND、SYN_RCVD、ESTABLISHED。（第三次握手可以携带数据，是因为客户端已经明确知道连接建立了）&lt;/li&gt;
      &lt;li&gt;为什么是三次握手？不是两次、四次？
        &lt;ul&gt;
          &lt;li&gt;三次握手才可以阻止历史重复连接的初始化（主要原因）
            &lt;ul&gt;
              &lt;li&gt;如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接：&lt;/li&gt;
              &lt;li&gt;如果是历史连接（序列号过期或超时），则第三次握手发送的报文是 RST 报文，以此中止历史连接；&lt;/li&gt;
              &lt;li&gt;如果不是历史连接，则第三次发送的报文是 ACK 报文，通信双方就会成功建立连接；&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;三次握手才可以同步双方的初始序列号&lt;/li&gt;
          &lt;li&gt;三次握手才可以避免资源浪费
            &lt;ul&gt;
              &lt;li&gt;如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？&lt;/li&gt;
              &lt;li&gt;如果客户端的 SYN 阻塞了，重复发送多次 SYN 报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;什么是 SYN 攻击？
        &lt;ul&gt;
          &lt;li&gt;我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;如何避免 SYN 攻击？
        &lt;ul&gt;
          &lt;li&gt;net.ipv4.tcp_syncookies = 1，同一个客户端发起的和自己的cookie绑到，服务端就不会生成太多的SYN_RECD连接&lt;/li&gt;
          &lt;li&gt;net.ipv4.tcp_max_syn_backlog，设置最大的SYN_REVD数字&lt;/li&gt;
          &lt;li&gt;net.ipv4.tcp_abort_on_overflow ，超出处理能力丢弃&lt;/li&gt;
          &lt;li&gt;net.core.netdev_max_backlog，设置最大队列处理数字&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么客户端和服务端的初始序列号 ISN 是不相同的？
    &lt;ul&gt;
      &lt;li&gt;因为网络中的报文会延迟、会复制重发、也有可能丢失，这样会造成的不同连接之间产生互相影响，所以为了避免互相影响，客户端和服务端的初始序列号是随机且不同的。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;初始序列号 ISN 是如何随机产生的？
    &lt;ul&gt;
      &lt;li&gt;起始 ISN 是基于时钟的，每 4 毫秒 + 1，转一圈要 4.55 个小时。&lt;/li&gt;
      &lt;li&gt;RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。&lt;/li&gt;
      &lt;li&gt;ISN = M + F (localhost, localport, remotehost, remoteport)
        &lt;ul&gt;
          &lt;li&gt;M 是一个计时器，这个计时器每隔 4 毫秒加 1。&lt;/li&gt;
          &lt;li&gt;F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？
    &lt;ul&gt;
      &lt;li&gt;MTU：一个网络包的最大长度，以太网中一般为 1500 字节；&lt;/li&gt;
      &lt;li&gt;MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；&lt;/li&gt;
      &lt;li&gt;如果TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？&lt;/li&gt;
      &lt;li&gt;当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，在交给上一层 TCP 传输层。&lt;/li&gt;
      &lt;li&gt;这看起来井然有序，但这存在隐患的，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。&lt;/li&gt;
      &lt;li&gt;因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。&lt;/li&gt;
      &lt;li&gt;当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。&lt;/li&gt;
      &lt;li&gt;因此，可以得知由 IP 层进行分片传输，是非常没有效率的。&lt;/li&gt;
      &lt;li&gt;所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。&lt;/li&gt;
      &lt;li&gt;握手阶段协商 MSS，经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP断开连接
    &lt;ul&gt;
      &lt;li&gt;4次握手和6种状态，客户端FIN_WAIT_1、FIN_WAIT_2、TIME_WAIT，服务端CLOSED_WAIT、LAST_ACK，CLOSE&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么 TIME_WAIT 等待的时间是 2MSL？
    &lt;ul&gt;
      &lt;li&gt;MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。&lt;/li&gt;
      &lt;li&gt;TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。&lt;/li&gt;
      &lt;li&gt;在LAST-ACK状态，如果一直没有收到ACK，会发起重发。&lt;/li&gt;
      &lt;li&gt;TIME_WAIT太短会造成，服务端则会一直处在 LASE-ACK 状态。当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为什么需要 TIME_WAIT 状态？
    &lt;ul&gt;
      &lt;li&gt;防止具有相同「四元组」的「旧」数据包被收到；&lt;/li&gt;
      &lt;li&gt;保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TIME_WAIT 过多有什么危害？
    &lt;ul&gt;
      &lt;li&gt;第一是内存资源占用；&lt;/li&gt;
      &lt;li&gt;第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如何优化 TIME_WAIT？
    &lt;ul&gt;
      &lt;li&gt;net.ipv4.tcp_tw_reuse = 1 ; net.ipv4.tcp_timstamps=1;这个时间戳的字段是在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。
  由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。
  温馨提醒：net.ipv4.tcp_tw_reuse要慎用，因为使用了它就必然要打开时间戳的支持 net.ipv4.tcp_timestamps，当客户端与服务端主机时间不同步时，客户端的发送的消息会被直接拒绝掉。小林在工作中就遇到过。。。排查了非常的久&lt;/li&gt;
      &lt;li&gt;net.ipv4.tcp_max_tw_buckets ; 这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。&lt;/li&gt;
      &lt;li&gt;程序中使用 SO_LINGER ,如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。但这为跨越TIME_WAIT状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;保活机制
    &lt;ul&gt;
      &lt;li&gt;tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制&lt;/li&gt;
      &lt;li&gt;tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；&lt;/li&gt;
      &lt;li&gt;tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。&lt;/li&gt;
      &lt;li&gt;高效保活长连接：手把手教你实现 自适应的心跳保活机制 &lt;a href=&quot;https://mp.weixin.qq.com/s/BsLAXegZOE6B9CzW31xIdA&quot;&gt;https://mp.weixin.qq.com/s/BsLAXegZOE6B9CzW31xIdA&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;聊聊 TCP 长连接和心跳那些事 &lt;a href=&quot;https://mp.weixin.qq.com/s/cwqAMPku-LwXAGM3Cqztig&quot;&gt;https://mp.weixin.qq.com/s/cwqAMPku-LwXAGM3Cqztig&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;listen 时候参数 backlog 的意义？
    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int listen &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;int socketfd, int backlog&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
参数一 socketfd 为 socketfd 文件描述符
参数二 backlog，这参数在历史有一定的变化
在早期 Linux 内核 backlog 是 SYN 队列大小，也就是未完成的队列大小。
在 Linux 内核 2.2 之后，backlog 变成 accept 队列，也就是已完成连接建立的队列长度，所以现在通常认为 backlog 是 accept 队列。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;粘包拆包，应用层拆包？
    &lt;ul&gt;
      &lt;li&gt;如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这就是TCP协议中经常会遇到的粘包以及拆包的问题。
我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能&lt;/li&gt;
      &lt;li&gt;SO_TCPNODELAY:NAGLE 算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量 小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法。&lt;/li&gt;
      &lt;li&gt;拆包方案
        &lt;ul&gt;
          &lt;li&gt;客户端在发送数据包的时候，每个包都固定长度，比如1024个字节大小，如果客户端发送的数据长度不足1024个字节，则通过补充空格的方式补全到指定长度；&lt;/li&gt;
          &lt;li&gt;客户端在每个包的末尾使用固定的分隔符，例如\r\n，如果一个包被拆分了，则等待下一个包发送过来之后找到其中的\r\n，然后对其拆分后的头部部分与前一个包的剩余部分进行合并，这样就得到了一个完整的包；&lt;/li&gt;
          &lt;li&gt;将消息分为头部和消息体，在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息；&lt;/li&gt;
          &lt;li&gt;通过自定义协议进行粘包和拆包的处理。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用了哪些算法？
    &lt;ul&gt;
      &lt;li&gt;重传算法&lt;/li&gt;
      &lt;li&gt;RTO计算&lt;/li&gt;
      &lt;li&gt;Nagle算法，累计够数据再发送&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;netty 高性能
    &lt;ul&gt;
      &lt;li&gt;无锁设计、线程绑定，类似偏向锁读写操作会判断是否是之前绑定的线程&lt;/li&gt;
      &lt;li&gt;用户可以实现其它的高性能序列化框架，例如 Thrift 的压缩二进制编解码框架。&lt;/li&gt;
      &lt;li&gt;小包封大包，防止网络阻塞&lt;/li&gt;
      &lt;li&gt;软中断 Hash 值和 CPU 绑定，也就是说将每个连接和 cpu 绑定，并通过这个 hash 值，来均衡软中断在多个 cpu 上，提升 网络并行处理性能。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;reactor和proactor模型
    &lt;ul&gt;
      &lt;li&gt;reactor：基于NIO技术，可读可写时通知应用；await阻塞等待&lt;/li&gt;
      &lt;li&gt;proactor：基于AIO技术，读完成时通知应用，写操作应用通知内核。真正的异步。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Java nio 空轮询bug到底是什么，异常情况导致的fd集合为空时，selector仍然会轮训 &lt;a href=&quot;https://mp.weixin.qq.com/s/-SoUVFB5DhaUZg_novolkg&quot;&gt;https://mp.weixin.qq.com/s/-SoUVFB5DhaUZg_novolkg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;zookeeper的observer&quot;&gt;ZooKeeper的observer&lt;/h4&gt;
&lt;p&gt;当ZooKeeper集群中follower的数量很多时，投票过程会成为一个性能瓶颈，为了解决投票造成的压力，于是出现了observer角色。
observer角色不参与投票，它只是投票结果的”听众”，除此之外，它和follower完全一样，例如能接受读、写请求。就这一个特点，让整个ZooKeeper集群性能大大改善。
和follower一样，当observer收到客户端的读请求时，会直接从内存数据库中取出数据返回给客户端。
对于写请求，当写请求发送到某server上后，无论这个节点是follower还是observer，都会将它发送给leader。然后leader组织投票过程，所有server都收到这个proposal(包括observer，因为proposal是广播出去的)，但是leader和follower以及observer通过配置文件，都知道自己是不是observer以及谁是observer。自己是observer的server不参与投票。当leader收集完投票后，将那些observer的server去掉，在剩下的server中计算大多数，如果投票结果达到了大多数，这次写事务就成功，于是leader通知所有的节点(包括observer)，让它们将事务写入事务日志，并提交。&lt;/p&gt;

&lt;p&gt;Pojo(plian ordinary普通的; 平常的; java object)&lt;/p&gt;

&lt;h4 id=&quot;jvm&quot;&gt;JVM&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;-Xms2g&lt;/span&gt;：初始化推大小为 2g；
&lt;span class=&quot;nt&quot;&gt;-Xmx2g&lt;/span&gt;：堆最大内存为 2g；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:NewRatio&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4：设置年轻的和老年代的内存比例为 1:4；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:SurvivorRatio&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8：设置新生代 Eden 和 Survivor 比例为 8:2；
–XX:+UseParNewGC：指定使用 ParNew + Serial Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+UseParallelOldGC：指定使用 ParNew + ParNew Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+UseConcMarkSweepGC：指定使用 CMS + Serial Old 垃圾回收器组合；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+PrintGC：开启打印 gc 信息；
&lt;span class=&quot;nt&quot;&gt;-XX&lt;/span&gt;:+PrintGCDetails：打印 gc 详细信息。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;分代垃圾回收器是怎么工作的&quot;&gt;分代垃圾回收器是怎么工作的？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分代回收器有两个分区：老生代和新生代，新生代默认的空间占比总空间的 1/3，老生代的默认占比是 2/3。&lt;/li&gt;
  &lt;li&gt;新生代使用的是复制算法，新生代里有 3 个分区：Eden、To Survivor、From Survivor，它们的默认占比是  8:1:1，它的执行流程如下：&lt;/li&gt;
  &lt;li&gt;把 Eden + From Survivor 存活的对象放入 To Survivor 区；
清空 Eden 和 From Survivor 分区；
From Survivor 和 To Survivor 分区交换，From Survivor 变 To Survivor，To Survivor 变 From Survivor。
每次在 From Survivor 到 To Survivor 移动时都存活的对象，年龄就 +1，当年龄到达 15（默认配置是 15）时，升级为老生代。大对象也会直接进入老生代。&lt;/li&gt;
  &lt;li&gt;老生代当空间占用到达某个值之后就会触发全局垃圾收回，一般使用标记整理的执行算法。以上这些循环往复就构成了整个分代垃圾回收的整体执行流程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;垃圾回收器&quot;&gt;垃圾回收器&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；&lt;/li&gt;
  &lt;li&gt;ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着比Serial更好的表现；&lt;/li&gt;
  &lt;li&gt;Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景；&lt;/li&gt;
  &lt;li&gt;Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；&lt;/li&gt;
  &lt;li&gt;Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本；&lt;/li&gt;
  &lt;li&gt;CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。&lt;/li&gt;
  &lt;li&gt;G1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7提供的一个新收集器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bionioaio-有什么区别&quot;&gt;BIO,NIO,AIO 有什么区别?&lt;/h4&gt;
&lt;p&gt;BIO：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。
NIO：Non IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。
AIO：Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。&lt;/p&gt;

&lt;p&gt;BIO (Blocking I/O): 同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。
NIO (New I/O): NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发
AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。&lt;/p&gt;

&lt;h4 id=&quot;kafka数据存储&quot;&gt;kafka数据存储&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Kafka和RocketMQ存储区别 &lt;a href=&quot;https://mp.weixin.qq.com/s/_hJcEqTMASpeDkavcdtDsw&quot;&gt;https://mp.weixin.qq.com/s/_hJcEqTMASpeDkavcdtDsw&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;partition升级为ConsumerQueue，并且只存储消息的地址，由单独的commitLog记录消息文件&lt;/li&gt;
      &lt;li&gt;consumerQueue消息格式大小固定（20字节），写入pagecache之后被触发刷盘频率相对较低。就是因为每次写入的消息小，造成他占用的pagecache少，主要占用方一旦被清理，那么他就可以不用清理了。&lt;/li&gt;
      &lt;li&gt;kafka中多partition会存在随机写的可能性，partition之间刷盘的冲撞率会高，但是rocketmq中commitLog都是顺序写。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;partition：topic 的分区，一个 topic 可以包含多个 partition，topic 消息保存在各个partition 上
    &lt;ul&gt;
      &lt;li&gt;每个partition是一个有序的队列也是一个目录。&lt;/li&gt;
      &lt;li&gt;partition 内消息是有序的，Consumer 通过 pull 方式消费消息。Kafka 不删除已消费的消息.。对于 partition，顺序读写磁盘数据，以时间复杂度 O(1)方式提供消息持久化能力。&lt;/li&gt;
      &lt;li&gt;每个partition(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;segment：partition物理上由多个segment文件组成，每个segment大小相等，顺序读写。
    &lt;ul&gt;
      &lt;li&gt;每个 segment 数据文件以该段中最小的 offset 命名，文件扩展名为.log。这样在查找指定 offset 的 Message 的 时候，用二分查找就可以定位到该 Message 在哪个 segment 数据文件中。&lt;/li&gt;
      &lt;li&gt;segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kafka 为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩 展名为.index。index 文件中并没有为数据文件中的每条 Message 建立索引，而是采用了稀疏存 储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以 将索引文件保留在内存中。&lt;/li&gt;
  &lt;li&gt;由于消息 topic 由多个 partition 组成，且 partition 会均衡分布到不同 broker 上，因此，为了有 效利用 broker 集群的性能，提高消息的吞吐量，producer 可以通过随机或者 hash 等方式，将消 息平均发送到多个 partition 上，以实现负载均衡。&lt;/li&gt;
  &lt;li&gt;是提高消息吞吐量重要的方式，Producer 端可以在内存中合并多条消息后，以一次请求的方式发 送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响 了消息的实时性，相当于以时延代价，换取更好的吞吐量。&lt;/li&gt;
  &lt;li&gt;Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后，在 Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大 数据处理上，瓶颈往往体现在网络上而不是 CPU(压缩和解压会耗掉部分 CPU 资源)。&lt;/li&gt;
  &lt;li&gt;Current Offset是针对Consumer的poll过程的，它可以保证每次poll都返回不重复的消息；而Committed Offset是用于Consumer Rebalance过程的，它能够保证新的Consumer能够从正确的位置开始消费一个partition，从而避免重复消费。&lt;/li&gt;
  &lt;li&gt;Zookeeper：保存着集群 broker、topic、partition 等 meta 数据;另外，还负责 broker 故障发现，partition leader 选举，负载均衡等功能。&lt;/li&gt;
  &lt;li&gt;auto.offset.reset表示如果Kafka中没有存储对应的offset信息的话（有可能offset信息被删除），消费者从何处开始消费消息。它拥有三个可选值：earliest：从最早的offset开始消费、latest：从最后的offset开始消费、none：直接抛出exception给consumer&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;hashmap-为啥size是2的倍数18比17做了哪些优化&quot;&gt;HashMap 为啥size是2的倍数，1.8比1.7做了哪些优化？&lt;/h4&gt;
&lt;p&gt;JDK1.7 VS JDK1.8 比较
JDK1.8主要解决或优化了一下问题：
resize 扩容优化
引入了红黑树，目的是避免单条链表过长而影响查询效率，红黑树算法请参考
解决了多线程死循环问题，但仍是非线程安全的，多线程时可能会造成数据丢失问题。&lt;/p&gt;

&lt;h4 id=&quot;spring&quot;&gt;Spring&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；&lt;/li&gt;
  &lt;li&gt;Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；&lt;/li&gt;
  &lt;li&gt;Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；&lt;/li&gt;
  &lt;li&gt;Feign：基于Ribbon和Hystrix的声明式服务调用组件；&lt;/li&gt;
  &lt;li&gt;Zuul：API网关组件，对请求提供路由及过滤功能。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Bus
用于传播集群状态变化的消息总线，使用轻量级消息代理链接分布式系统中的节点，可以用来动态刷新集群中的服务配置。
Spring Cloud Bus 提供了跨多个实例刷新配置的功能。因此，在上面的示例中，如果我们刷新 Employee Producer1，则会自动刷新所有其他必需的模块。如果我们有多个微服务启动并运行，这特别有用。这是通过将所有微服务连接到单个消息代理来实现的。无论何时刷新实例，此事件都会订阅到侦听此代理的所有微服务，并且它们也会刷新。可以通过使用端点/总线/刷新来实现对任何单个实例的刷新。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Consul
基于Hashicorp Consul的服务治理组件。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Security
安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Sleuth
Spring Cloud应用程序的分布式请求链路跟踪，支持使用Zipkin、HTrace和基于日志（例如ELK）的跟踪。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Stream
轻量级事件驱动微服务框架，可以使用简单的声明式模型来发送及接收消息，主要实现为Apache Kafka及RabbitMQ。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Task
用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Zookeeper
基于Apache Zookeeper的服务治理组件。&lt;/li&gt;
  &lt;li&gt;Spring Cloud Gateway
API网关组件，对请求提供路由及过滤功能。Spring Cloud Gateway是Spring Cloud官方推出的第二代网关框架，取代Zuul网关。网关作为流量的，在微服务系统中有着非常作用，网关常见的功能有路由转发、权限校验、限流控制等作用。
使用了一个RouteLocatorBuilder的bean去创建路由，除了创建路由RouteLocatorBuilder可以让你添加各种predicates和filters，predicates断言的意思，顾名思义就是根据具体的请求的规则，由具体的route去处理，filters是各种过滤器，用来对请求做各种判断和修改。&lt;/li&gt;
  &lt;li&gt;Spring Cloud OpenFeign
基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。&lt;/li&gt;
  &lt;li&gt;什么是Spring Cloud Config?
在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件spring cloud config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在spring cloud config 组件中，分两个角色，一是config server，二是config client。
使用：（1）添加pom依赖（2）配置文件添加相关配置（3）启动类添加注解@EnableConfigServer&lt;/li&gt;
  &lt;li&gt;Spring中使用@Autowired注解静态实例对象 &lt;a href=&quot;https://blog.csdn.net/RogueFist/article/details/79575665&quot;&gt;https://blog.csdn.net/RogueFist/article/details/79575665&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多个ApplicationRunner，可以用@Order指定优先级串行执行的，如果优先级高的block了，后面的需要等着&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;protocol-buffer-的序列化--反序列化简单--速度快的原因是&quot;&gt;Protocol Buffer 的序列化 &amp;amp; 反序列化简单 &amp;amp; 速度快的原因是:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;编码 / 解码 方式简单(只需要简单的数学运算 = 位移等等)&lt;/li&gt;
  &lt;li&gt;采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;protocol-buffer-的数据压缩效果好即序列化后的数据量体积小的原因是&quot;&gt;Protocol Buffer 的数据压缩效果好(即序列化后的数据量体积小)的原因是:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;a. 采用了独特的编码方式，如 Varint、Zigzag 编码方式等等&lt;/li&gt;
  &lt;li&gt;b. 采用 T - L - V 的数据存储方式:减少了分隔符的使用 &amp;amp; 数据存储得紧凑&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;hbase-cassandra-mongodb&quot;&gt;HBase Cassandra MongoDB&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;与RDBMS的区别
    &lt;ul&gt;
      &lt;li&gt;关系数据库，磁盘存储是一行接一行，而列式存储是一列接一列&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;存储结构
    &lt;ul&gt;
      &lt;li&gt;MongoDB：GridFS、JSON/BSON&lt;/li&gt;
      &lt;li&gt;HBase：HRegionServer：【HLog、HRegion：【Store MemStore、StoreFile、HFile】】、HDFS。
        &lt;ul&gt;
          &lt;li&gt;HBase的数据分片按表进行，以行为粒度，基于rowkey范围进行拆分，每个分片称为一个region。一个集群有多张表，每张表划分为多个region，每台服务器服务很多region。所以，HBase的服务器称为RegionServer，简称RS。RS与表是正交的，即一张表的region会分布到多台RS上，一台RS也会调度多张表的region&lt;/li&gt;
          &lt;li&gt;HBase是水平拆分,意思是行是region划分的最小单位，即一行数据要么属于A region，要么属于Bregion，不会被拆到两个region中去。&lt;/li&gt;
          &lt;li&gt;浅谈HBase的数据分布 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/47074785&quot;&gt;https://zhuanlan.zhihu.com/p/47074785&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;hbase.regionserver.global.memstore.upperLimit、hbase.regionserver.global.memstore.lowerLimit、hbase.hregion.memstore.flush.size&lt;/li&gt;
          &lt;li&gt;HLog限制，hase.regionserver.max.logs&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cassandra：LSM、HashNode（一致性Hash的虚拟节点）、CommitLog、memtable、SSTable
        &lt;ul&gt;
          &lt;li&gt;Durable_writes，默认情况下，表的durable_writes属性设置为true，但可以将其设置为false。durable_writes参数用于设置写数据时是否写入commit log,如果设置为false,则写请求不会写commit log，会有丢失数据的风险。此参数默认为true,即要写commit log,生产系统应该将该参数设置为true。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;HBase、Cassandra都是基于类似的LSM机制&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;存储形式
    &lt;ul&gt;
      &lt;li&gt;MongoDB：Collection JSON&lt;/li&gt;
      &lt;li&gt;Cassandra：Column family ，Row，Name/Value/Timestamp&lt;/li&gt;
      &lt;li&gt;HBase：put ‘t_user’,’1001’,’st1:age’,’18’&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;范围分页查询
    &lt;ul&gt;
      &lt;li&gt;MongoDB：利用skip().limit()实现&lt;/li&gt;
      &lt;li&gt;HBase：scan  ‘stu2’,{COLUMNS =&amp;gt; ‘cf1:age’, LIMMIT 10, STARTROW =&amp;gt; ‘xx’}&lt;/li&gt;
      &lt;li&gt;Cassandra：select * from teacher where token(id)&amp;gt;token(1) limit 1;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;数据类型
    &lt;ul&gt;
      &lt;li&gt;MongoDB丰富，类似SQL&lt;/li&gt;
      &lt;li&gt;HBase只支持字符串&lt;/li&gt;
      &lt;li&gt;Cassandra多种&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;索引、二级索引、辅助索引
    &lt;ul&gt;
      &lt;li&gt;MongoDB：支持全索引，实现高性能。单一索引、复合、哈希、地址位置、文本等索引。BTree&lt;/li&gt;
      &lt;li&gt;HBase：主要是设计二级索引。二级索引的本质就是建立各列值与行键之间的映射关系。简单的可以借助RowKey
        &lt;ol&gt;
          &lt;li&gt;RowKey也是基于B+树&lt;/li&gt;
          &lt;li&gt;MapReduce方案&lt;/li&gt;
          &lt;li&gt;ITHBASE（Indexed-Transanctional HBase）方案&lt;/li&gt;
          &lt;li&gt;IHBASE（Index HBase）方案&lt;/li&gt;
          &lt;li&gt;Hbase Coprocessor(协处理器)方案&lt;/li&gt;
          &lt;li&gt;Solr+HBase方案&lt;/li&gt;
          &lt;li&gt;CCIndex（complemental clustering index）方案&lt;/li&gt;
          &lt;li&gt;Phoenix&lt;/li&gt;
          &lt;li&gt;HBase RowKey与索引设计 &lt;a href=&quot;https://www.cnblogs.com/swordfall/p/10597802.html&quot;&gt;https://www.cnblogs.com/swordfall/p/10597802.html&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Cassandra
        &lt;ul&gt;
          &lt;li&gt;第一主键 只能用=号查询&lt;/li&gt;
          &lt;li&gt;第二主键 支持= &amp;gt; &amp;lt; &amp;gt;= &amp;lt;= 但是必须后面加 ALLOW FILTERING&lt;/li&gt;
          &lt;li&gt;索引列 只支持=号&lt;/li&gt;
          &lt;li&gt;索引列 支持 like，只有主键支持 group by&lt;/li&gt;
          &lt;li&gt;PRIMARY KEY (user_id, uploaded_date, article_id)，第一列仍然是数据的partition key。其后所跟的所有的列都称为clustering column&lt;/li&gt;
          &lt;li&gt;CQL查询语句的特殊规则 &lt;a href=&quot;https://blog.csdn.net/ZZQHELLO2018/article/details/106302161&quot;&gt;https://blog.csdn.net/ZZQHELLO2018/article/details/106302161&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;事务
    &lt;ul&gt;
      &lt;li&gt;HBase的事务是行级事务，可以保证行级数据的原子性、一致性、隔离性以及持久性&lt;/li&gt;
      &lt;li&gt;MongoDB不支持事务&lt;/li&gt;
      &lt;li&gt;Cassandra支持行一级的原子性和隔离性，但与之交换的是高度的可用性和快速的读写性能。Cassandra写入具有持久性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;一致性和CAP
    &lt;ul&gt;
      &lt;li&gt;MongoDB、HBase强一致性，CP，0 数据丢失&lt;/li&gt;
      &lt;li&gt;Cassandra最终一致性（可调一致性），数据可能丢失，AP
        &lt;ul&gt;
          &lt;li&gt;Consistency，此命令显示当前的一致性级别，或设置新的一致性级别。Consistency可以理解读和写操作的Consistency Level。
写操作的consistency level指定了写操作在通知客户端请求成功之前，必须确保已经成功完成写操作的replica的数量。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Join支持
    &lt;ul&gt;
      &lt;li&gt;MongoDB不支持多表连接&lt;/li&gt;
      &lt;li&gt;Cassandra不支持多表连接，用数据冗余解决问题hotels_by_poi&lt;/li&gt;
      &lt;li&gt;HBase不支持Join，需要借助其他工具或者算法实现&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;读写
    &lt;ul&gt;
      &lt;li&gt;HBase快速读取和写入，具有可扩展性。读写性能数据读写定位可能要通过最多 6 次的网络RPC，性能较低。&lt;/li&gt;
      &lt;li&gt;Cassandra快速随机性读取/写入，写多读少。数据读写定位非常快。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MongoDB、HBase、Cassandra比较&lt;a href=&quot;https://www.cnblogs.com/yanduanduan/p/10563678.html&quot;&gt;https://www.cnblogs.com/yanduanduan/p/10563678.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Hbase和Cassandra &lt;a href=&quot;https://blog.csdn.net/aa5305123/article/details/83142514&quot;&gt;https://blog.csdn.net/aa5305123/article/details/83142514&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;
1.强一致性的读写：HBase不是一个最终一致性的存储。
2.自动sharding：HBase的table在集群种被分布在各个region，region可以做自动切分。
3.regionserver的failover；
4.Hadoop/HDFS的集成；
5.MapReduce：支持大数据的并行处理；
6.JAVA Client 以及Thrift/RESR API 访问；
7.Block Cache 以及Bloom filter；
8.操作管理。

1.C*借鉴Dynamo的架构思想，把自己叫做一个最终一致性的系统，如果使用至少是QUORUM 读写，还算是一个强一致的系统。
2.C*的sharding方式：一致性hash，有2种：
（1）人为配置好initial_token；
2.使用vnode，集群初始化以及节点bootstrap的时候会计算token，基于这些token做数据sharding。
3.可以容忍：replicator_number - (read/write level sufficient nodes)个节点挂了，比如3个副本，读写级别QUORUM（sufficient nodes是2），能容忍1节点挂；
4.支持MapReduce;
5.Thrift、CQL访问;
6.大数据处理的bloom filter 必备；
7.自己有jmx等常见管理，且datastax 公司有提供ops center；
&lt;/pre&gt;

&lt;h4 id=&quot;seata-的-demo&quot;&gt;Seata 的 Demo&lt;/h4&gt;

&lt;h4 id=&quot;垃圾回收器组合-7种&quot;&gt;垃圾回收器组合 7种&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Parallel Old &amp;amp; Parallel Scavenge New 高吞吐量 （1种）&lt;/li&gt;
  &lt;li&gt;G1 （1种）&lt;/li&gt;
  &lt;li&gt;Serial Old （5种）
    &lt;ul&gt;
      &lt;li&gt;
        &lt;table&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;&amp;amp; CMS Old &amp;amp; (Serial&lt;/td&gt;
              &lt;td&gt; &lt;/td&gt;
              &lt;td&gt;ParNew 2种)&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
      &lt;li&gt;&amp;amp; Serial&lt;/li&gt;
      &lt;li&gt;&amp;amp; ParNew&lt;/li&gt;
      &lt;li&gt;&amp;amp; Parallel Scavenge New&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;CMS短停顿 与 Scavenge 高吞吐不可一组&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 16 Jun 2020 12:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/16/DotDot.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/16/DotDot.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>经典算法思想</title>
        <description>&lt;p&gt;数据结构算法，问题TOP10 &lt;a href=&quot;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&quot;&gt;https://mp.weixin.qq.com/s/rqzCvFWira204eJ1HA22yg&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;贪心算法&quot;&gt;贪心算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;贪心的意思在于在作出选择时，每次都要选择对自身最为有利的结果，保证自身利益的最大化。贪心算法就是利用这种贪心思想而得出一种算法。&lt;/li&gt;
  &lt;li&gt;例：小明手中有 1，5，10，50，100 五种面额的纸币，每种纸币对应张数分别为 5，2，2，3，5 张。若小明需要支付 456 元，则需要多少张纸币？&lt;/li&gt;
  &lt;li&gt;最小生成树 Kruskal算法&lt;/li&gt;
  &lt;li&gt;最小生成树 prim算法&lt;/li&gt;
  &lt;li&gt;分发饼干、跳跃游戏、无重叠区间、摆动序列 &lt;a href=&quot;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&quot;&gt;https://mp.weixin.qq.com/s/4GKIwV34Zp4W1VFTwhx-uw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;分糖果、无重叠区间 &lt;a href=&quot;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&quot;&gt;https://mp.weixin.qq.com/s/YhFGBAXhv8c-Rfs6Fuciow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分治算法&quot;&gt;分治算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;快速排序算法、大整数乘法、残缺棋盘游戏 &lt;a href=&quot;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&quot;&gt;https://mp.weixin.qq.com/s/2rnEhHcJEGSEmlAK18B2VQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;汉诺塔、快速排序、归并排序 &lt;a href=&quot;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&quot;&gt;https://mp.weixin.qq.com/s/paOrlfpdMwvCUDywda0EvQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;动态规划算法-dynamic-programming&quot;&gt;动态规划算法 Dynamic Programming&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 2&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;+F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;（n&amp;gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3）

F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;9&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;8&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#最优子结构&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#边界&lt;/span&gt;
F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; + F&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;n-2&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#状态转移方程&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;斐波那契 &lt;a href=&quot;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&quot;&gt;https://mp.weixin.qq.com/s/3LR-iVC4zgj0tGhZ780PcQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;上台阶与挖黄金 &lt;a href=&quot;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&quot;&gt;https://mp.weixin.qq.com/s/3h9iqU4rdH3EIy5m6AzXsg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;高楼扔鸡蛋 &lt;a href=&quot;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&quot;&gt;https://mp.weixin.qq.com/s/ncrvbpiZauXAGnUZTh5qtA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;回溯法&quot;&gt;回溯法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&quot;&gt;https://mp.weixin.qq.com/s/UCTjKA7olFb00C6CLlqHAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题 &lt;a href=&quot;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&quot;&gt;https://mp.weixin.qq.com/s/puk7IAZkSe6FCkZnt0jnSA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;八皇后问题与数独 &lt;a href=&quot;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&quot;&gt;https://mp.weixin.qq.com/s/vfItwB2GpXCy-s2dQJnkIg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;A*寻路算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;分支定界法&quot;&gt;分支定界法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;广度优先遍历 &lt;a href=&quot;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&quot;&gt;https://mp.weixin.qq.com/s/Rdg14IPL4Czx4J5obgbqEQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;字符串匹配算法&quot;&gt;字符串匹配算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;BF算法，是Brute Force（暴力算法，按位比较 O(m*n)）&lt;a href=&quot;https://mp.weixin.qq.com/s/2RlyDBo-Ql-1Ofh8tMyikg&quot;&gt;https://mp.weixin.qq.com/s/2RlyDBo-Ql-1Ofh8tMyikg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;RK算法，是Rabin-Karp (计算hash值进行比较 O(n)) &lt;a href=&quot;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&quot;&gt;https://mp.weixin.qq.com/s/EVkV1AQC9GBI29zNiWDH6g&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Knuth-Morris-Pratt算法（简称KMP）是最常用的之一 &lt;a href=&quot;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&quot;&gt;https://mp.weixin.qq.com/s/xr5rgSF3dOV9XH0gC5oO0w&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;字符串匹配算法综述:BF、RK、KMP、BM、Sunday &lt;a href=&quot;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&quot;&gt;https://mp.weixin.qq.com/s/RSnFzrmitwCCgDuB73I2QA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考&quot;&gt;参考&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;小灰算法2017 &lt;a href=&quot;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&quot;&gt;https://mp.weixin.qq.com/s/4kTtn_gLYQrX7JFlEJdsZg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2018 &lt;a href=&quot;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&quot;&gt;https://mp.weixin.qq.com/s/oFQHrCZvItgc8McrZSaovw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2019 &lt;a href=&quot;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&quot;&gt;https://mp.weixin.qq.com/s/Ok5SjqhiQkG5sLUPNY02Mw&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;小灰算法2020 &lt;a href=&quot;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&quot;&gt;https://mp.weixin.qq.com/s/dpWZ6qOvU1T9sdOzMNVyAA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;二十世纪最伟大的10大算法 &lt;a href=&quot;https://blog.csdn.net/v_JULY_v/article/details/6127953&quot;&gt;https://blog.csdn.net/v_JULY_v/article/details/6127953&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/ClassicalAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>BitMap-BloomFilter</title>
        <description>&lt;h4 id=&quot;bitmap&quot;&gt;BitMap&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;近似的理解为用一个大数组的索引来表示数字本身，用0或1表示该数字是否存在&lt;/li&gt;
  &lt;li&gt;一个32位的int，只用一个标志位来表示是否存在&lt;/li&gt;
  &lt;li&gt;但是数字如果重复只会保留一个，主要用于去重类似的场景&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bloomfilter&quot;&gt;BloomFilter&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;判断短连接是否重复、垃圾邮件等场景&lt;/li&gt;
  &lt;li&gt;把url，3次不同hash，得到3个不同的hashcode，存入bitmap&lt;/li&gt;
  &lt;li&gt;多次hash是为了降低hash重复的概率&lt;/li&gt;
  &lt;li&gt;由于以上特性，bloomFilter算法计算出不存在的一定就是不存在，如果计算出来存在有一定几率重复（因为hash的特性）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;参考链接&quot;&gt;参考链接&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Bitmap算法 整合版 &lt;a href=&quot;https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg&quot;&gt;https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;什么是布隆算法？&lt;a href=&quot;https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ&quot;&gt;https://mp.weixin.qq.com/s/RmR5XmLeMvk35vgjwxANFQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 13:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BitMap-BloomFilter.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>大数据常用算法概述</title>
        <description>&lt;h4 id=&quot;决策树算法&quot;&gt;决策树算法&lt;/h4&gt;
&lt;h4 id=&quot;回归算法&quot;&gt;回归算法&lt;/h4&gt;
&lt;h4 id=&quot;朴素贝叶斯算法&quot;&gt;朴素贝叶斯算法&lt;/h4&gt;
&lt;h4 id=&quot;聚类-knn算法&quot;&gt;聚类-KNN算法&lt;/h4&gt;
&lt;h4 id=&quot;svm支持向量机&quot;&gt;SVM支持向量机&lt;/h4&gt;
&lt;h4 id=&quot;推荐算法&quot;&gt;推荐算法&lt;/h4&gt;
</description>
        <pubDate>Sun, 07 Jun 2020 12:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/07/BigDataAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        <category>BigData</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>ZooKeeper</title>
        <description>&lt;h4 id=&quot;使用场景&quot;&gt;使用场景&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;注册中心&lt;/li&gt;
  &lt;li&gt;配置中心&lt;/li&gt;
  &lt;li&gt;HBase之MetaData存储&lt;/li&gt;
  &lt;li&gt;分布式锁&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;常用命令&quot;&gt;常用命令&lt;/h4&gt;
&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./zkServer.sh start | stop 
./zkServer.sh status
./zkCli.sh 

&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;stat&lt;/span&gt; /
ls2 /

create /node1 /node1-content
create &lt;span class=&quot;nt&quot;&gt;-e&lt;/span&gt; /node1-temp /node1-content-temp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/dandandeshangni/article/details/80558383&quot;&gt;https://blog.csdn.net/dandandeshangni/article/details/80558383&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;阿里为什么不用-zookeeper-做服务发现&quot;&gt;阿里为什么不用 ZooKeeper 做服务发现？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;基于CP而非AP&lt;/li&gt;
  &lt;li&gt;自身仅仅是主从的集群，而非分布式集群&lt;/li&gt;
  &lt;li&gt;The King Of Coordination for Big Data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&quot;&gt;https://mp.weixin.qq.com/s/ouayPydKCWc0FfGlaSnCrg&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 12:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/Zookeeper.html</guid>
        
        <category>微服务</category>
        
        <category>分布式</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>'图'相关算法</title>
        <description>&lt;h4 id=&quot;什么时图&quot;&gt;什么时”图”&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;可以简单理解我存储关系的数据结构，比如好友关系&lt;/li&gt;
  &lt;li&gt;分为有向图、无向图&lt;/li&gt;
  &lt;li&gt;存储结构
    &lt;ul&gt;
      &lt;li&gt;邻接矩阵（类似多维数组）&lt;/li&gt;
      &lt;li&gt;邻接表  （类似”正”索引）&lt;/li&gt;
      &lt;li&gt;逆邻接表 （类似倒排索引）&lt;/li&gt;
      &lt;li&gt;十字链表  （正倒索引联合）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;深度优先遍历-和-广度优先遍历&quot;&gt;深度优先遍历 和 广度优先遍历&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;深度优先遍历，沿着当前分支，直到最后一个节点，然后遍历相邻节点（二叉树的前中后序遍历就是深度优先遍历），重点在回溯&lt;/li&gt;
  &lt;li&gt;广度优先遍历，遍历完当前节点的所有子节点，然后切换到下级节点（类似二叉树的层级遍历），重点在重放&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图的-最短路径&quot;&gt;图的 “最短路径”&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;迪杰斯特拉算法 Dijkstra，解决带权重的A-&amp;gt;G最短路径 &lt;a href=&quot;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&quot;&gt;https://mp.weixin.qq.com/s/ALQntqQJkdWf4RbPaGOOhg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;多源最短路径，解决多个带权重节点间的最短路径，弗洛伊德算法 Floyd-Warshall &lt;a href=&quot;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&quot;&gt;https://mp.weixin.qq.com/s/qnPSzv_xWSZN0VpdUgwvMg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;路径规划之 A* 算法 &lt;a href=&quot;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&quot;&gt;https://mp.weixin.qq.com/s/FYKR_1yBKR4GJTn0fFIuAA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;最小生成树&quot;&gt;最小生成树&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;把所有点在没有回路的情况下，连接起来，并且权重相加最小（权重可以理解为城市见的距离）&lt;/li&gt;
  &lt;li&gt;Kruskal算法，克鲁斯卡尔算法的基本思想是以边为主导地位，始终选择当前可用的最小边权的边（可以直接快排或者algorithm的sort）。每次选择边权最小的边链接两个端点是kruskal的规则，并实时判断两个点之间有没有间接联通。
（也算是贪心算法思想）&lt;a href=&quot;https://blog.csdn.net/qq_41754350/article/details/81460643&quot;&gt;https://blog.csdn.net/qq_41754350/article/details/81460643&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;prim算法，这个算法是以图的顶点为基础，从一个初始顶点开始，寻找触达其他顶点权值最小的边，并把该顶点加入到已触达顶点的集合中。当全部顶点都加入到集合时，算法的工作就完成了。Prim算法的本质，是基于贪心算法。
&lt;a href=&quot;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&quot;&gt;https://mp.weixin.qq.com/s/x7JT7re7W7IgNCgMf1kJTA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ford-fulkerson-最大流算法&quot;&gt;Ford-Fulkerson 最大流算法&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;解决的问题：在一个流里，有着每条边的运载能力限制，我最多能从源头运输多少数量到目的地。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/DarrenChan/p/9563511.html&quot;&gt;https://www.cnblogs.com/DarrenChan/p/9563511.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/sinat_41613352/article/details/84481115&quot;&gt;https://blog.csdn.net/sinat_41613352/article/details/84481115&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sat, 06 Jun 2020 09:17:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/06/06/GraphAlgorithm.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title> 数据结构 </title>
        <description>&lt;h4 id=&quot;数组&quot;&gt;数组&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;链表&quot;&gt;链表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。&lt;/li&gt;
  &lt;li&gt;这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。&lt;/li&gt;
  &lt;li&gt;一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;跳表&quot;&gt;跳表&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从O(n)提升至O(logn)。&lt;/li&gt;
  &lt;li&gt;跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前redis和levelDB都有用到跳表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;栈&quot;&gt;栈&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;后进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;队列&quot;&gt;队列&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;先进先出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;树&quot;&gt;树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将“链表”竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。&lt;/li&gt;
  &lt;li&gt;树遍历
    &lt;ul&gt;
      &lt;li&gt;前序遍历：根结点 —&amp;gt; 左子树 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;中序遍历：左子树—&amp;gt; 根结点 —&amp;gt; 右子树&lt;/li&gt;
      &lt;li&gt;后序遍历：左子树 —&amp;gt; 右子树 —&amp;gt; 根结点&lt;/li&gt;
      &lt;li&gt;层次遍历：仅仅需按层次遍历就可以&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;平衡二叉树&quot;&gt;平衡二叉树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;平衡二叉树又被称为AVL树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;红黑树&quot;&gt;红黑树&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;每个结点要么是红的要么是黑的。&lt;/li&gt;
  &lt;li&gt;根结点是黑的。&lt;/li&gt;
  &lt;li&gt;每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。&lt;/li&gt;
  &lt;li&gt;如果一个结点是红的，那么它的两个儿子都是黑的。&lt;/li&gt;
  &lt;li&gt;对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。&lt;/li&gt;
  &lt;li&gt;Map、Set、epoll/select中句柄集&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;堆&quot;&gt;堆&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。&lt;/li&gt;
  &lt;li&gt;堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;散列表-hash&quot;&gt;散列表 Hash&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;通过某种算法确定唯一（有些算法会出现不同的value算出相同的Hash值）&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;图&quot;&gt;图&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;多维数据存储,实际应用中是通过图这种模式建立索引与关联关系&lt;/li&gt;
  &lt;li&gt;图数据库？
    &lt;ul&gt;
      &lt;li&gt;图数据库(Graph database)并非指存储图片的数据库，而是以图这种数据结构存储和查询数据。&lt;/li&gt;
      &lt;li&gt;图形数据库是一种在线数据库管理系统，具有处理图形数据模型的创建，读取，更新和删除（CRUD）操作。&lt;/li&gt;
      &lt;li&gt;与其他数据库不同，关系在图数据库中占首要地位。这意味着应用程序不必使用外键或带外处理（如MapReduce）来推断数据连接。&lt;/li&gt;
      &lt;li&gt;与关系数据库或其他NoSQL数据库相比，图数据库的数据模型也更加简单，更具表现力。&lt;/li&gt;
      &lt;li&gt;图形数据库是为与事务（OLTP）系统一起使用而构建的，并且在设计时考虑了事务完整性和操作可用性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&quot;&gt;https://mp.weixin.qq.com/s/TFG7bWo1BFzjusQ2fEvVSA&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 31 May 2020 19:25:00 +0800</pubDate>
        <link>http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</link>
        <guid isPermaLink="true">http://localhost:4000/%E6%8A%80%E6%9C%AF/2020/05/31/DataStructure.html</guid>
        
        <category>数据结构与算法</category>
        
        
        <category>技术</category>
        
      </item>
    
  </channel>
</rss>
